<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Plato - /Users/ashipunova/BPC/vamps-node.js/routes/routes_user_data.js</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link href="../../assets/css/vendor/morris.css" rel="stylesheet">
  <link href="../../assets/css/vendor/bootstrap.css" rel="stylesheet">
  <link href="../../assets/css/vendor/font-awesome.css" rel="stylesheet">
  <link href="../../assets/css/vendor/codemirror.css" rel="stylesheet">
  <link href="../../assets/css/plato.css" rel="stylesheet">
  <link href="../../assets/css/plato-file.css" rel="stylesheet">

</head>

<body>

<div class="navbar navbar-fixed-top">
  <div class="container">
    <a class="navbar-brand" href="http://github.com/es-analysis/plato">Plato on Github</a>
    <ul class="nav navbar-nav">
      <li>
        <a href="../../index.html">Report Home</a>
      </li>
    </ul>
  </div>
</div>

<div class="jumbotron">
  <div class="container">
    <h1>/Users/ashipunova/BPC/vamps-node.js/routes/routes_user_data.js</h1>
  </div>
</div>

<div class="container aggregate-stats">
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Maintainability <a href="http://blogs.msdn.com/b/codeanalysis/archive/2007/11/20/maintainability-index-range-and-meaning.aspx"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="A value between 0 and 100 that represents the relative ease of maintaining the code. A high value means better maintainability." data-original-title="Maintainability Index"  data-container="body"></i></a></h2>
      <p class="stat">54.15</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Lines of code <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h2>
      <p class="stat">2966</p>
    </div>
  </div>
  <div class="row historical">
    <div class="col-md-6">
      <p id="chart_historical_maint" class="chart"></p>
    </div>
    <div class="col-md-6">
      <p id="chart_historical_sloc" class="chart"></p>
    </div>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Difficulty  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="The difficulty measure is related to the difficulty of the program to write or understand." data-original-title="Difficulty" data-container="body"></i></a></h2>
      <p class="stat">106.23</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Estimated Errors  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Halstead's delivered bugs is an estimate for the number of errors in the implementation." data-original-title="Delivered Bugs" data-container="body"></i></a></h2>
      <p class="stat">41.80</p>
    </div>
  </div>
</div>

<div class="container charts">
  <div class="row">
    <h2 class="header">Function weight</h2>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h3 class="chart-header">By Complexity <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="This metric counts the number of distinct paths through a block of code. Lower values are better." data-original-title="Cyclomatic Complexity" data-container="body"></i></a></h3>
      <div id="fn-by-complexity" class="stat"></div>
    </div>
    <div class="col-md-6">
      <h3 class="chart-header">By SLOC  <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h3>
      <div id="fn-by-sloc" class="stat"></div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <textarea id="file-source" class="col-md-12">/*jslint node: true */
// &quot;use strict&quot; ;

var express = require(&#039;express&#039;);
var router = express.Router();
var passport = require(&#039;passport&#039;);
var helpers = require(&#039;./helpers/helpers&#039;);
var path = require(&#039;path&#039;);
var fs = require(&#039;fs-extra&#039;);
var url = require(&#039;url&#039;);
var ini = require(&#039;ini&#039;);
var queries = require(&#039;./queries&#039;);
var iniparser = require(&#039;iniparser&#039;);
//var PythonShell = require(&#039;python-shell&#039;);
var zlib = require(&#039;zlib&#039;);
var config = require(&#039;../config/config&#039;);
var multer = require(&#039;multer&#039;);
var util = require(&#039;util&#039;);

//var progress = require(&#039;progress-stream&#039;);
var upload = multer({ dest: config.TMP,   limits: { fileSize: config.UPLOAD_FILE_SIZE.bytes }  });

var Readable = require(&#039;readable-stream&#039;).Readable;
var COMMON = require(&#039;./visuals/routes_common&#039;);
// router.use(multer({ dest: &#039;tmp&#039;,
// rename: function (fieldname, filename) {
// return filename+Date.now();
// },
// onFileUploadStart: function (file) {
// console.log(file.originalname + &#039; is starting ...&#039;)
// },
// onFileUploadComplete: function (file) {
// console.log(file.fieldname + &#039; uploaded to &#039; + file.path)
// done=true;
// }
// }));
var spawn = require(&#039;child_process&#039;).spawn;
//
// YOUR DATA
//
router.get(&#039;/your_data&#039;, function (req, res) {
  console.log(&#039;in your data&#039;);
  console.log(req.user);
  res.render(&#039;user_data/your_data&#039;, {
    title: &#039;VAMPS:Data Administration&#039;,
    user: req.user, hostname: req.CONFIG.hostname,
    message: req.flash(&#039;message&#039;),
  });
});

//
// FILE RETRIEVAL
//
/* GET Export Data page. */
router.get(&#039;/file_retrieval&#039;,  helpers.isLoggedIn,  function (req,  res) {

    var export_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    var file_formats = req.CONSTS.download_file_formats;
    var file_info = [];

    fs.readdir(export_dir,  function (err,  files) {
      for (var f in files) {
        var pts = files[f].split(&#039;-&#039;);
        if (file_formats.indexOf(pts[0]) != -1) {
          stat = fs.statSync(export_dir+&#039;/&#039;+files[f]);
          file_info.push({ &#039;filename&#039;:files[f],  &#039;size&#039;:stat.size,  &#039;time&#039;:stat.mtime});
        }
      }
      file_info.sort(function (a,  b) {
          //reverse sort: recent--&gt;oldest
          return helpers.compareStrings_int(b.time.getTime(),  a.time.getTime());
      });
      //console.log(file_info)
      res.render(&#039;user_data/file_retrieval&#039;,  { title: &#039;VAMPS:Export Data&#039;,
              user: req.user,  hostname: req.CONFIG.hostname,
              finfo: JSON.stringify(file_info),
              message : req.flash(&#039;message&#039;),
            });
    });
});

//
//  EXPORT CONFIRM
//
router.post(&#039;/export_confirm&#039;,  helpers.isLoggedIn,  function (req,  res) {
    console.log(&#039;req.body: export_confirm--&gt;&gt;&#039;);
    console.log(req.body);
    console.log(&#039;req.body: &lt;&lt;--export_confirm&#039;);
    if (req.body.fasta === undefined
        &amp;&amp; req.body.taxbyseq === undefined
        &amp;&amp; req.body.taxbyref === undefined
        &amp;&amp; req.body.matrix === undefined
        &amp;&amp; req.body.metadata === undefined
        &amp;&amp; req.body.biom === undefined ) {
        req.flash(&#039;failMessage&#039;,  &#039;Select one or more file formats&#039;);
        res.render(&#039;user_data/export_selection&#039;,  {
          title: &#039;VAMPS: Export Choices&#039;,
          referer: &#039;export_data&#039;,
          chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
          constants: JSON.stringify(req.CONSTS),
          selected_rank:req.body.tax_depth,
              selected_domains:JSON.stringify(req.body.domains),
          message: &#039;Select one or more file formats&#039;,
          user: req.user,  hostname: req.CONFIG.hostname
        });
        return;
    }
    var dids = req.body.dids.split(&#039;, &#039;);
    var requested_files = [];

    if (req.body.fasta) {

    }
    var timestamp = +new Date();  // millisecs since the epoch!
    var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    helpers.mkdirSync(req.CONFIG.USER_FILES_BASE); // create dir if not exists
    helpers.mkdirSync(user_dir);

    for (var key in req.body) {
      if (key === &#039;fasta&#039;) {
        requested_files.push(&#039;-fasta_file&#039;);
      }
      if (key === &#039;matrix&#039;) {
        requested_files.push(&#039;-matrix_file&#039;);
      }
      //if (key === &#039;taxbyref&#039;) {
      //  requested_files.push(&#039;-taxbyref_file&#039;);
      //}
      if (key === &#039;taxbyseq&#039;) {
        requested_files.push(&#039;-taxbyseq_file&#039;);
      }
      if (key === &#039;metadata&#039;) {
        requested_files.push(&#039;-metadata_file&#039;);
      }
      if (key === &#039;biom&#039;) {
        requested_files.push(&#039;-biom_file&#039;);
      }


    }
    if (requested_files.length &gt;0) {
      if (req.body.tax_depth==&#039;class&#039;) {var td=&#039;klass&#039;;}
      else {var td=req.body.tax_depth;}
      create_export_files(req,  user_dir,  timestamp,  dids,  requested_files,  req.body.normalization, td, req.body.domains );
    }
    //console.log(requested_files);

    res.render(&#039;user_data/export_selection&#039;,  {
          title: &#039;VAMPS: Export Choices&#039;,
          referer: &#039;export_data&#039;,
          chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
          constants: JSON.stringify(req.CONSTS),
          selected_rank:req.body.tax_depth,
              selected_domains:JSON.stringify(req.body.domains),
          message: &quot;Your file(s) are being created -- &lt;a href=&#039;/user_data/file_retrieval&#039; &gt;when ready they will be accessible here&lt;/a&gt;&quot;,
          user: req.user,  hostname: req.CONFIG.hostname
    });


});
//
//
//
router.get(&#039;/get_projects_only_tree&#039;,  helpers.isLoggedIn,  function (req,  res) {
    console.log(&#039;in get_projects_only_tree&#039;);  // for export data
    var html = &#039;&#039;;

    html += &#039;&lt;ul&gt;&#039;;
    for (var id in PROJECT_INFORMATION_BY_PID) {
      //console.log(id)
      name = PROJECT_INFORMATION_BY_PID[id].project;
      html += &quot;&lt;li&gt;&lt;input type=&#039;checkbox&#039; name=&#039;project_ids&#039; value=&#039;&quot;+id+&quot;&#039;&gt; &quot;+name+&quot;&lt;/li&gt;&quot;;

    }
    html += &#039;&lt;ul&gt;&#039;;
    res.send(html);
});
//
//  EXPORT SELECTION
//
/* GET Import Choices page. */
router.post(&#039;/export_selection&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(&#039;in routes_user_data.js /export_selection&#039;);
  console.log(&#039;req.body: export_selection--&gt;&gt;&#039;);
  console.log(req.body);
  console.log(&#039;req.body: &lt;&lt;--export_selection&#039;);


  if (req.body.retain_data === &#039;1&#039;) {
    dataset_ids = JSON.parse(req.body.dataset_ids);
  } else {
    dataset_ids = req.body.dataset_ids;
  }
  console.log(&#039;dataset_ids &#039;+dataset_ids);
  if (dataset_ids === undefined || dataset_ids.length === 0) {
      console.log(&#039;redirecting back -- no data selected&#039;);
      req.flash(&#039;nodataMessage&#039;,  &#039;Select Some Datasets&#039;);
      res.redirect(&#039;export_data&#039;);
     return;
  } else {
   // GLOBAL Variable
  chosen_id_name_hash           = COMMON.create_chosen_id_name_hash(dataset_ids);
    console.log(&#039;chosen_id_name_hash--&gt;&#039;);
  console.log(chosen_id_name_hash);
  console.log(chosen_id_name_hash.ids.length);
  console.log(&#039;&lt;--chosen_id_name_hash&#039;);

    res.render(&#039;user_data/export_selection&#039;,  {
          title: &#039;VAMPS: Export Choices&#039;,
          referer: &#039;export_data&#039;,
          constants: JSON.stringify(req.CONSTS),
          chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
          selected_rank:&#039;phylum&#039;,   // initial condition
          selected_domains:JSON.stringify(req.CONSTS.DOMAINS.domains),  // initial condition
          message: req.flash(&#039;successMessage&#039;),
          failmessage: req.flash(&#039;failMessage&#039;),
          user: req.user,  hostname: req.CONFIG.hostname
        });
  }
});
//
//  EXPORT DATA
//
router.post(&#039;/export_data&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(&#039;req.body export_data&#039;);
  console.log(req.body);
  // GLOBAL
  DATA_TO_OPEN = {};
  SHOW_DATA = ALL_DATASETS;
  if (req.body.data_to_open) {
    // open many projects
    obj = JSON.parse(req.body.data_to_open);
    for (var pj in obj) {
      pid = PROJECT_INFORMATION_BY_PNAME[pj].pid;
      DATA_TO_OPEN[pid] = obj[pj];
    }
    //console.log(&#039;got data to open &#039;+data_to_open)
  } else if (req.body.project) {
    // open whole project
    DATA_TO_OPEN[req.body.project_id] = DATASET_IDS_BY_PID[req.body.project_id];
  }
  console.log(&#039;DATA_TO_OPEN-exports&#039;);
  console.log(DATA_TO_OPEN);

    res.render(&#039;user_data/export_data&#039;,  { title: &#039;VAMPS:Export Data&#039;,
                rows     : JSON.stringify(ALL_DATASETS),
                proj_info: JSON.stringify(PROJECT_INFORMATION_BY_PID),
                constants: JSON.stringify(req.CONSTS),
                md_names    : AllMetadataNames,
                data_to_open: JSON.stringify(DATA_TO_OPEN),
                message  : req.flash(&#039;nodataMessage&#039;),
                user: req.user,  hostname: req.CONFIG.hostname
          });
});


//
// IMPORT_CHOICES
//
/* GET Import Choices page. */
router.get(&#039;/import_choices&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(&#039;import_choices&#039;);
   if (req.user.username == &#039;guest&#039;) {
       req.flash(&#039;message&#039;,  &quot;The &#039;guest&#039; user is not permitted to import data&quot;);
       res.redirect(&#039;/user_data/your_data&#039;);
   } else {
      res.render(&#039;user_data/import_choices&#039;,  {
          title: &#039;VAMPS:Import Choices&#039;,
          message: req.flash(&#039;successMessage&#039;),
          failmessage: req.flash(&#039;failMessage&#039;),
          user: req.user,  hostname: req.CONFIG.hostname
          });
  }
});
//
// IMPORT DATA
//
/* GET Import Data page. */
router.get(&#039;/import_data&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(&#039;import_data&#039;);
  console.log(req.url);
  var myurl = url.parse(req.url,  true);


  var user_projects_base_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);

  var my_projects = [];
  var import_type    = myurl.query.import_type;

    fs.readdir(user_projects_base_dir,  function (err,  items) {
        if (err) {

          fs.ensureDir(user_projects_base_dir,  function (err) {
            console.log(err); // =&gt; null
            // dir has now been created,  including the directory it is to be placed in
          });


        } else {
          console.log(user_projects_base_dir);
          for (var d in items) {
            var pts = items[d].split(&#039;-&#039;);
            if (pts[0] === &#039;project&#039;) {

              var project_name = pts[1];
              my_projects.push(project_name);

            }
          }

          res.render(&#039;user_data/import_data&#039;,  {
            title: &#039;VAMPS:Import Data&#039;,
            message: req.flash(&#039;successMessage&#039;),
            failmessage: req.flash(&#039;failMessage&#039;),
            import_type: import_type,
            my_projects: my_projects,
            user: req.user,
            hostname: req.CONFIG.hostname
          });

        } // end else
      });


});
//
// VALIDATE FORMAT
//
/* GET Validate page. */
router.get(&#039;/validate_format&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(&#039;validate_format&#039;);
  console.log(JSON.stringify(req.url));
  var myurl = url.parse(req.url,  true);
  console.log(myurl.query);
  var file_type    = myurl.query.file_type;
  res.render(&#039;user_data/validate_format&#039;,  {
    title: &#039;VAMPS:Import Data&#039;,
    message: req.flash(&#039;successMessage&#039;),
      file_type: file_type,
      file_style:&#039;&#039;,
      result:&#039;&#039;,
      original_fname:&#039;&#039;,
      user: req.user,  hostname: req.CONFIG.hostname
                        });
});
//
//  VALIDATE FILE
//
router.post(&#039;/validate_file&#039;,  [helpers.isLoggedIn,  upload.single(&#039;upload_file&#039;,  12)],  function (req,  res) {
    console.log(&#039;POST validate_file&#039;);

    console.log(req.body);
    console.log(req.file);
    var file_type    = req.body.file_type;
    var file_style   = req.body.file_style;
    console.log(&#039;file_type &#039;+ file_type);
    console.log(&#039;file_style &#039;+ file_style);
    var file_path = path.join(process.env.PWD, req.file.path);
    console.log(&#039;file_path &#039;+ file_path);

    var options = { scriptPath : req.CONFIG.PATH_TO_NODE_SCRIPTS,
                  args : [ &#039;-i&#039;,  file_path,  &#039;-ft&#039;, file_type, &#039;-s&#039;,  file_style, &#039;-process_dir&#039;, process.env.PWD, ]
              };

    console.log(options.scriptPath+&#039;/vamps_script_validate.py &#039;+options.args.join(&#039; &#039;));

    var log = fs.openSync(path.join(process.env.PWD, &#039;logs&#039;, &#039;validate.log&#039;),  &#039;a&#039;);
    var validate_process = spawn( options.scriptPath+&#039;/vamps_script_validate.py&#039;,  options.args,  {detached: true,  stdio: [ &#039;ignore&#039;,  null,  log ]} );  // stdin,  stdout,  stderr
    var output = &#039;&#039;;
    validate_process.stdout.on(&#039;data&#039;,  function (data) {
      //console.log(&#039;stdout: &#039; + data);
      data = data.toString().replace(/^\s+|\s+$/g,  &#039;&#039;);
      output += data;


    });
    validate_process.on(&#039;close&#039;,  function (code) {
        console.log(&#039;validate_process exited with code &#039; + code);
        console.log(output);

        var ary = output.substring(2, output.length-2).split(&quot;&#039;,  &#039;&quot;);
        var result = ary.shift();
        console.log(ary);
        //var last_line = ary[ary.length - 1];
        if (code === 0) {
          //console.log(&#039;OK &#039;+code)
          console.log(typeof ary);

          if (result == &#039;OK&#039;) {
            req.flash(&#039;message&#039;,  &#039;Validates&#039;);
          } else {
            req.flash(&#039;message&#039;,  &#039;Failed Validation&#039;);
          }
          res.render(&#039;user_data/validate_format&#039;,  {
               title: &#039;VAMPS:Import Data&#039;,
               message: req.flash(&#039;message&#039;),

               file_type: file_type,
               //result:    JSON.stringify(ary),
               file_style: file_style,
               result_ary:    ary,
               original_fname: req.file.originalname,
               result : result,
               user: req.user,  hostname: req.CONFIG.hostname
             });

        } else {
          console.log(&#039;ERROR &#039;+code);
          req.flash(&#039;message&#039;,  &#039;Failed Validation&#039;);
          res.render(&#039;user_data/validate_format&#039;,  {
              title: &#039;VAMPS:Import Data&#039;,
              message: req.flash(&#039;message&#039;),
              file_type: file_type,
              user: req.user,  hostname: req.CONFIG.hostname
                          });
        }

    });


});
//
// USER PROJECT INFO:ID
//
router.get(&#039;/user_project_info/:id&#039;,  helpers.isLoggedIn,  function (req,  res) {
  console.log(req.params.id);
  var project = req.params.id;
  var config_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project, &#039;config.ini&#039;);

  var config = ini.parse(fs.readFileSync(config_file,  &#039;utf-8&#039;));
  console.log(config);
  res.render(&#039;user_data/profile&#039;,  {
      project : project,
      pinfo   : JSON.stringify(config),
      title   : project,
      user: req.user,  hostname: req.CONFIG.hostname
         });
});
//
// USER PROJECT METADATA:ID
//
router.get(&#039;/user_project_metadata/:id&#039;,  helpers.isLoggedIn,  function (req,  res) {
  var parse = require(&#039;csv-parse&#039;);
  var async = require(&#039;async&#039;);
  console.log(req.params.id);
  var project = req.params.id;
  var config_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project, &#039;config.ini&#039;);

  stats = fs.statSync(config_file);
  if (stats.isFile()) {
     console.log(&#039;config found&#039;);
     var config = ini.parse(fs.readFileSync(config_file,  &#039;utf-8&#039;));
  } else {
    //console.log(&#039;config NOT found&#039;)
     config = {&#039;config file NOT AVAILABLE&#039;:1};
  }
  var metadata_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project, &#039;metadata_clean.csv&#039;);

  var parser = parse({delimiter: &#039;\t&#039;},  function (err,  data) {
      json_data = {};
      console.log(data);

      res.render(&#039;user_data/metadata&#039;,  {
        project : project,
        pinfo   : JSON.stringify(config),
        mdata   : data,
        title   : project,
        message : req.flash(&#039;successMessage&#039;),
        user: req.user,  hostname: req.CONFIG.hostname
      });

  });
  try{
    console.log(&#039;looking for meta&#039;);
    stats = fs.lstatSync(metadata_file);
    if (stats.isFile()) {
      console.log(&#039;meta found&#039;);
      fs.createReadStream(metadata_file).pipe(parser);
    }
  }
  catch(e) {
    console.log(&#039;meta NOT found&#039;);
    res.render(&#039;user_data/metadata&#039;,  {
      project : project,
      pinfo   : JSON.stringify(config),
      mdata   : [],
      title   : project,
      message : req.flash(&#039;successMessage&#039;),
      user: req.user,  hostname: req.CONFIG.hostname
    });
  }

});
router.get(&#039;/user_project_validation/:id&#039;,  helpers.isLoggedIn,  function (req,  res) {
        // THIS IS FOR UNLOADED PROJECTS (After upload and before tax assignment)
        //will only show up if config.ini is present
        // check that metadata file is present
        // check that sequence file(s) are present
        // check config variables
        // grep Traceback project-*/cluster.log
        var config_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project, &#039;config.ini&#039;);
        var metadata_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project, &#039;metadata_clean.csv&#039;);

        stats = fs.statSync(config_file);
        if (stats.isFile()) {
           console.log(&#039;config found&#039;);
           var config = ini.parse(fs.readFileSync(config_file,  &#039;utf-8&#039;));
        } else {
            console.log(&#039;config NOT found&#039;);
            config = {&#039;config file NOT AVAILABLE&#039;:1};
        }
        res.redirect(&quot;/user_data/your_projects&quot;);
});
//
//  DELETE PROJECT:PROJECT:KIND
//
router.get(&#039;/delete_project/:project/:kind&#039;,  helpers.isLoggedIn,   function (req, res) {

  var delete_kind = req.params.kind;
  var project = req.params.project;
  var timestamp = +new Date();  // millisecs since the epoch!
  console.log(&#039;in delete_project1: &#039;+project+&#039; - &#039;+delete_kind);
  //console.log(JSON.stringify(PROJECT_INFORMATION_BY_PNAME));

  if (project in PROJECT_INFORMATION_BY_PNAME) {
    var pid = PROJECT_INFORMATION_BY_PNAME[project].pid;
    helpers.update_global_variables(pid, &#039;del&#039;);
  } else {
    // project not in db?
    console.log(&#039;project was not found in db: PROJECT_INFORMATION_BY_PNAME&#039;);
    var pid = 0;
  }

    console.log(&#039;in delete_project2: &#039;+project+&#039; - &#039;+pid);
    var options = {
        scriptPath : req.CONFIG.PATH_TO_NODE_SCRIPTS,
        args :       [ &#039;-pid&#039;,  pid,  &#039;-db&#039;,  NODE_DATABASE,  &#039;--user&#039;, req.user.username, &#039;--project&#039;, project, &#039;-pdir&#039;, process.env.PWD ],
        };
    if (delete_kind == &#039;all&#039;) {
      // must delete pid data from mysql ()
      // and all datasets files
      options.args = options.args.concat([&#039;--action&#039;,  &#039;delete_whole_project&#039;]);
    } else if (delete_kind == &#039;tax&#039; &amp;&amp; pid !== 0) {
      options.args = options.args.concat([&#039;--action&#039;,  &#039;delete_tax_only&#039; ]);

    } else if (delete_kind == &#039;meta&#039; &amp;&amp; pid !== 0) {
      options.args = options.args.concat([&#039;--action&#039;,   &#039;delete_metadata_only&#039; ]);

    } else {
      req.flash(&#039;message&#039;,  &#039;ERROR nothing deleted&#039;);
      res.redirect(&quot;/user_data/your_projects&quot;);
      return;
    }
    console.log(options.args.join(&#039; &#039;));

    var log = fs.openSync(path.join(process.env.PWD, &#039;logs&#039;, &#039;delete.log&#039;),  &#039;a&#039;);
      // script will remove data from mysql and datset taxfile

    console.log(options.scriptPath+&#039;/vamps_script_utils.py &#039;+options.args.join(&#039; &#039;));
      var delete_process = spawn( options.scriptPath+&#039;/vamps_script_utils.py&#039;,  options.args,  {detached: true,  stdio: [ &#039;ignore&#039;,  null,  log ]} );  // stdin,  stdout,  stderr


      var output = &#039;&#039;;
      delete_process.stdout.on(&#039;data&#039;,  function (data) {
        //console.log(&#039;stdout: &#039; + data);
        data = data.toString().replace(/^\s+|\s+$/g,  &#039;&#039;);
        output += data;
        var lines = data.split(&#039;\n&#039;);
        for (var n in lines) {
          //console.log(&#039;line: &#039; + lines[n]);
        if (lines[n].substring(0, 4) == &#039;PID=&#039;) {
          console.log(&#039;pid line &#039;+lines[n]);
        }
        }
      });

      delete_process.on(&#039;close&#039;,  function (code) {
          console.log(&#039;delete_process process exited with code &#039; + code);
          var ary = output.split(&quot;\n&quot;);
          var last_line = ary[ary.length - 1];
          if (code === 0) {
           //console.log(&#039;PID last line: &#039;+last_line)
              status_params = {&#039;type&#039;:&#039;delete&#039;,  &#039;user_id&#039;:req.user.user_id,
                                &#039;project&#039;:project,  &#039;status&#039;:&#039;delete&#039;,   &#039;msg&#039;:&#039;delete&#039; };
              helpers.update_status(status_params );
          } else {
             // python script error
          }
      });
      // called imediately
      var msg = &quot;&quot;;
      if (delete_kind == &#039;all&#039;) {
        msg = &quot;Deletion in progress: &#039;&quot;+project+&quot;&#039;&quot;;
      } else if (delete_kind == &#039;tax&#039;) {
        msg = &quot;Deletion in progress: taxonomy from &#039;&quot;+project+&quot;&#039;&quot;;
      } else if (delete_kind == &#039;meta&#039;) {
        msg = &quot;Deletion in progress: metadata from &#039;&quot;+project+&quot;&#039;&quot;;
      } else {
        req.flash(&#039;message&#039;,  &#039;ERROR nothing deleted&#039;);
        res.redirect(&quot;/user_data/your_projects&quot;);
        return;
      }
      if (delete_kind == &#039;all&#039;) {
          // MOVE file dir to DELETED path (so it won&#039;t show in &#039;your_projects&#039; list)
          var data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project);
          var deleted_data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;DELETED_project&#039;+timestamp+&#039;-&#039;+project);

          fs.move(data_dir,  deleted_data_dir,  function (err) {
            if (err) {
              console.log(err);
              res.send(err);
            } else {
              console.log(&#039;moved project_dir to DELETED_project_dir&#039;);
              req.flash(&#039;successMessage&#039;,  msg);
              res.redirect(&quot;/user_data/your_projects&quot;);
              return;
            }

          });

      } else {
        req.flash(&#039;successMessage&#039;,  msg);
        res.redirect(&quot;/user_data/your_projects&quot;);
      }


});
//
// DUPLICATE_PROJECT
//
router.get(&#039;/duplicate_project/:project&#039;,  helpers.isLoggedIn,   function (req, res) {
   var project = req.params.project;
   var data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project);
   var new_data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project+&#039;_dupe&#039;);


   try{
      stats = fs.lstatSync(new_data_dir);
      if (stats.isDirectory()) {
              console.log(&#039;dir exists - returning&#039;);
              req.flash(&#039;failMessage&#039;,  &quot;Error: Could not duplicate: &#039;&quot;+project+&quot;&#039; to &#039;&quot;+project+&quot;_dupe&#039;. Does it already exist?&quot;);
            res.redirect(&quot;/user_data/your_projects&quot;);
            return;
          }
    }catch(err) {
      console.log(&#039;dir doesnt exist -good- continuing on&#039;);
    }

    fs.copy(data_dir,  new_data_dir,  function (err) {
      if (err) {
        console.log(err);
      } else {
        // need to change config file of new project to include new name:
        console.log(&#039;duplicate copy success!&#039;);
        var config_file = path.join(new_data_dir, &#039;config.ini&#039;);
        var project_info = {};
        project_info.config = iniparser.parseSync(config_file);
        var config_info = project_info.config.GENERAL;
        config_info.project = project+&#039;_dupe&#039;;
        config_info.baseoutputdir = new_data_dir;
        config_info.configPath = path.join(new_data_dir, &#039;config.ini&#039;);
        config_info.fasta_file = path.join(new_data_dir, &#039;infile.fna&#039;);
        config_info.datasets = [];
        for (var ds in project_info.config.DATASETS) {
          config_info.datasets.push({ &quot;dsname&quot;:ds,  &quot;count&quot;:project_info.config.DATASETS[ds],  &quot;oldname&quot;:ds });
        }
        update_config(res, req,  config_file,  config_info,  false,  &#039;Duplicated &#039;+project+&#039; to: &#039;+config_info.project);
      }
    }); // copies directory,  even if it has subdirectories or files

});
//
//
//
router.get(&#039;/assign_taxonomy/:project/&#039;,  helpers.isLoggedIn,   function (req, res) {
    var project = req.params.project;
    var data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project);


    var config_file = path.join(data_dir, &#039;config.ini&#039;);

    res.render(&#039;user_data/assign_taxonomy&#039;,  {
      project : project,
      title   : project,
      message : req.flash(&#039;successMessage&#039;),
      tax_choices : JSON.stringify(req.CONSTS.UNIT_ASSIGNMENT_CHOICES),
      user: req.user,  hostname: req.CONFIG.hostname
     });

});
//
// START_ASSIGNMENT
//
function ProjectNameExists(project_name) {
  if (PROJECT_INFORMATION_BY_PNAME.hasOwnProperty(project_name))
  {
    console.log(&#039;This project name is already taken AAA&#039;);
    return true;
  }
  else
  {
    console.log(&#039;Project name validated&#039;);
    return false;
  }

}

//router.get(&#039;/start_assignment/:project/:classifier/:ref_db&#039;, helpers.isLoggedIn, function (req, res) {
router.get(&#039;/start_assignment/:project/:classifier_id&#039;, helpers.isLoggedIn, function (req, res) {
  var scriptlog = &quot;&quot;;
  var cmd_list = [];
  var exec = require(&#039;child_process&#039;).exec;
  console.log(&#039;in start_assignment---&gt;&#039;);
  console.log(req.params);
  console.log(&#039;&lt;--- in start_assignment&#039;);
  var project = req.params.project;
  var classifier_id = req.params.classifier_id;
  // /GAST/SILVA108_FULL_LENGTH&quot;&gt;Assign Taxonomy - GAST (Silva108)&lt;/a&gt;&lt;/li&gt;
  // /GAST/GG_MAY2013&quot;&gt;Assign Taxonomy - GAST (GreenGenes May2013)&lt;/a&gt;&lt;/li&gt;
  // /RDP/2.10.1&quot;&gt;Assign Taxonomy - RDP (2.10.1)&lt;/a&gt;&lt;/li&gt;
  // /RDP/GG_MAY2013&quot;&gt;Assign Taxonomy - RDP (GreenGenes May2013)&lt;/a&gt;&lt;/li&gt;
  // /RDP/ITS1&quot;

  // if (PROJECT_INFORMATION_BY_PNAME.hasOwnProperty(project))
  // {
  //   console.log(&#039;This project name is already taken&#039;);
  //   return;
  // }
  // else
  // {
  //   console.log(&#039;Project name validated&#039;);
  // }
  //var classifier = req.params.classifier;
  var classifier = req.CONSTS.UNIT_ASSIGNMENT_CHOICES[classifier_id].method;
  //var ref_db_dir = req.params.ref_db;
  var ref_db_dir = req.CONSTS.UNIT_ASSIGNMENT_CHOICES[classifier_id].refdb;
  console.log(&#039;start: &#039; + project + &#039; - &#039; + classifier + &#039; - &#039; + ref_db_dir);
  status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user_id&#039;:req.user.user_id, &#039;project&#039;:project, &#039;status&#039;:&#039;&#039;, &#039;msg&#039;:&#039;&#039; };
  var data_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039; + project);
  var qsub_script_path = req.CONFIG.PATH_TO_NODE_SCRIPTS;

  var config_file = path.join(data_dir, &#039;config.ini&#039;);
  try
  {
    //var stat_config = fs.statSync(config_file);
    // console.log(&#039;1 &#039;, config_file)
    var project_config = iniparser.parseSync(config_file);
    console.log(&#039;project_config&#039;, project_config);
    console.log(&#039;project_config2&#039;, project_config[&#039;GENERAL&#039;].fasta_type);
  }
  catch (err)
  {
    console.log(&#039;no read config file &#039;, err);
  }

  var options = {
    scriptPath : qsub_script_path,
    gast_run_args : [ &#039;-c&#039;, config_file, &#039;-process_dir&#039;, process.env.PWD,
    &#039;-project_dir&#039;, data_dir, &#039;-db&#039;, NODE_DATABASE, &#039;-ref_db_dir&#039;, ref_db_dir, &#039;-site&#039;, req.CONFIG.site ],
    rdp_run_args :  [ &#039;-c&#039;, config_file, &#039;-process_dir&#039;, process.env.PWD, &#039;-site&#039;, req.CONFIG.site,
    &#039;-project_dir&#039;, data_dir, &#039;-ref_db&#039;, ref_db_dir, &#039;-path_to_classifier&#039;, req.CONFIG.PATH_TO_CLASSIFIER ],
    database_loader_args : [ &#039;-class&#039;, classifier, &#039;-host&#039;, req.CONFIG.dbhost, &#039;-process_dir&#039;, process.env.PWD, &#039;-project_dir&#039;, data_dir, &#039;-db&#039;, NODE_DATABASE, &#039;-ref_db_dir&#039;, ref_db_dir],
    upload_metadata_args : [ &#039;-project_dir&#039;, data_dir, &#039;-host&#039;, req.CONFIG.dbhost, &#039;-db&#039;, NODE_DATABASE ],
    create_json_args : [ &#039;-process_dir&#039;, process.env.PWD, &#039;-host&#039;, req.CONFIG.dbhost, &#039;-project_dir&#039;, data_dir, &#039;-db&#039;, NODE_DATABASE ]
 };

  if (classifier.toUpperCase() == &#039;GAST&#039;)
  {
    if (project_config[&#039;GENERAL&#039;].fasta_type == &#039;multi&#039;)
    {
      //unique_cmd = options.scriptPath + &#039;1-demultiplex_fna.sh &#039; + data_dir + &#039; infile.fna&#039;
    }
    else
    {
      var single_dataset_name = Object.keys(project_config.DATASETS)[0];
    //unique_cmd = options.scriptPath + &#039;1-single_fna.sh &#039; + data_dir + &#039; infile.fna &#039; + single_dataset_name
    }
    // try: check project name and enter empty project (just to create pid)
    project_init = options.scriptPath + &#039;project_initialization.py -site &#039; + req.CONFIG.site + &#039; -indir &#039; + data_dir + &#039; -p &#039; + project + &#039; -uid &#039; + req.user.user_id;

    // metadata must go in after the projects and datasets:
    // Should go into db after we have project and datasets in the db
    // Should go in as entire project (w all datasets) -- not dataset by dataset
    // PROBLEM: Here we dont have datasets yet in db
    metadata_cmd = options.scriptPath + &#039;metadata_loader.py -site &#039; + req.CONFIG.site + &#039; -indir &#039; + data_dir + &#039; -p &#039; + project;

    // Command is split to run once for each dataset on the cluster:
    run_gast_cmd = options.scriptPath + &#039;2-vamps_nodejs_gast.sh -x &#039; + data_dir + &#039; -s &#039; + project + &#039; -d gast -v -e fa.unique -r &#039; + classifier_id + &#039; -f -p both -w &#039; + req.CONFIG.site;
    //run_cmd2 = &quot;/bioware/seqinfo/bin/gast_ill -saveuc -nodup -full -ignoregaps -in &quot; + data_dir + &quot;/fasta.fa.unique -db /groups/g454/blastdbs/gast_distributions/&quot; + classifier_id + &quot;.fa -rtax /groups/g454/blastdbs/gast_distributions/&quot; + classifier_id + &quot;.tax -out &quot; + data_dir + &quot;/gast/fasta_out.gast -uc &quot; + data_dir + &quot;/gast/fasta_out.uc -threads 0 -strand both&quot;

    //run_cmd3 = options.scriptPath + &#039;3-vamps_nodejs_database_loader.py -site &#039; + req.CONFIG.site + &#039; -indir &#039; + data_dir + &#039; -ds &#039; + single_dataset_name

    //run_cmd = options.scriptPath + &#039;/vamps_script_gast_run.py &#039; + options.gast_run_args.join(&#039; &#039;),
    script_name = &#039;gast_script.sh&#039;;
    status_params.statusOK = &#039;OK-GAST&#039;;status_params.statusSUCCESS = &#039;GAST-SUCCESS&#039;;
    status_params.msgOK = &#039;Finished GAST&#039;;status_params.msgSUCCESS = &#039;GAST -Tax assignments&#039;;
    cmd_list = [
        //unique_cmd,
        project_init,
        metadata_cmd,
        run_gast_cmd

        //options.scriptPath + &#039;/vamps_script_database_loader.py &#039; + options.database_loader_args.join(&#039; &#039;),
        //  &quot;pid=$(head -n 1 &quot; + data_dir + &quot;/pid.txt)&quot;, // pid is in a file pid.txt written by database loader
        //options.scriptPath + &#039;/vamps_script_load_metadata.py &#039; + options.upload_metadata_args.join(&#039; &#039;),
        //options.scriptPath + &#039;/vamps_script_create_json_dataset_files.py &#039; + options.create_json_args.join(&#039; &#039;)
      ];
    }
    else if (classifier.toUpperCase() == &#039;RDP&#039; )
    {
      // These are from the RDP README
      var gene = &#039;16srrna&#039;; // default
      if (classifier_id == &#039;refRDP_2.12-ITS&#039;)
      {
        gene = &#039;fungalits_unite&#039;;
      }
      var path2classifier = req.CONFIG.PATH_TO_CLASSIFIER + &#039;_&#039; + ref_db_dir;
      rdp_cmd1 = options.scriptPath + &#039;/vamps_script_rdp_run.py -project_dir &#039; + data_dir + &#039; -p &#039; + project + &#039; -site &#039; + req.CONFIG.site + &#039; -path_to_classifier &#039; + path2classifier + &#039; -gene &#039; + gene;
      rdp_cmd2 = options.scriptPath + &#039;/vamps_script_rdp_database_loader.py -project_dir &#039; + data_dir + &#039; -p &#039; + project + &#039; -site &#039; + req.CONFIG.site + &#039; --classifier RDP&#039;;
      rdp_cmd3 = options.scriptPath + &#039;/vamps_script_upload_metadata.py -project_dir &#039; + data_dir + &#039; -p &#039; + project + &#039; -site &#039; + req.CONFIG.site;
      rdp_cmd4 = options.scriptPath + &#039;/vamps_script_create_json_dataset_files.py -project_dir &#039; + data_dir + &#039; -p &#039; + project + &#039; -site &#039; + req.CONFIG.site + &#039; --jsonfile_dir &#039; + req.CONFIG.JSON_FILES_BASE;

      script_name = &#039;rdp_script.sh&#039;;
      status_params.statusOK = &#039;OK-RDP&#039;;status_params.statusSUCCESS = &#039;RDP-SUCCESS&#039;;
      status_params.msgOK = &#039;Finished RDP&#039;;status_params.msgSUCCESS = &#039;RDP -Tax assignments&#039;;
      cmd_list = [ rdp_cmd1, rdp_cmd2, rdp_cmd3, rdp_cmd4 ];
  }

  var script_text = &quot;&quot;;
  if (req.CONFIG.dbhost == &#039;vampsdev&#039; || req.CONFIG.dbhost == &#039;vampsdb&#039;)
  {
   scriptlog = path.join(data_dir, &#039;cluster.log&#039;);
   //var script_text = get_qsub_script_text(scriptlog, data_dir, req.CONFIG.dbhost, classifier, cmd_list)
   script_text = get_qsub_script_text(scriptlog, data_dir, req.CONFIG.dbhost, classifier, cmd_list);
  }
  else
  {
   scriptlog = path.join(data_dir, &#039;script.log&#039;);
   script_text = get_local_script_text(scriptlog, &#039;local&#039;, classifier, cmd_list);
  }
  var script_path = path.join(data_dir, script_name);

  fs.writeFile(script_path, script_text, function (err) {
    if (err) return console.log(err);
    // Make script executable
    child = exec( &#039;chmod ug + rwx &#039; + script_path,
    function (error, stdout, stderr) {
      console.log(&#039;1stdout: &#039; + stdout);
      console.log(&#039;1stderr: &#039; + stderr);
      if (error !== null)
      {
        console.log(&#039;1exec error: &#039; + error);
      }
      else
      {
        // run script
        var nodelog = fs.openSync(path.join(data_dir, &#039;assignment.log&#039;), &#039;a&#039;);

        console.log(&#039;RUNNING: &#039; + script_path);
        var run_process = spawn( script_path, [], {
          // env:{&#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH,
          // &#039;PATH&#039;:req.CONFIG.PATH,
          // &#039;PERL5LIB&#039;:req.CONFIG.PERL5LIB,
          // &#039;SGE_ROOT&#039;:req.CONFIG.SGE_ROOT, &#039;SGE_CELL&#039;:req.CONFIG.SGE_CELL, &#039;SGE_ARCH&#039;:req.CONFIG.SGE_ARCH
          // },
          detached: true, stdio: [ &#039;ignore&#039;, null, nodelog ]
        }); // stdin, s
        var output = &#039;&#039;;
        run_process.stdout.on(&#039;data&#039;, function (data) {
          //console.log(&#039;stdout: &#039; + data);
          data = data.toString().replace(/^\s + |\s + $/g, &#039;&#039;);
          output += data;
          var lines = data.split(&#039;\n&#039;);
          for (var n in lines)
          {
            //console.log(&#039;line: &#039; + lines[n]);
            if (lines[n].substring(0, 4) == &#039;PID=&#039;)
            {
              console.log(&#039;pid line &#039; + lines[n]);
            }
          }
        });
        run_process.on(&#039;close&#039;, function (code) {
          console.log(&#039;run_process process exited with code &#039; + code);
          var ary = output.split(&quot;\n&quot;);
          var last_line = ary[ary.length - 1];
          console.log(&#039;last_line:&#039;, last_line);
          if (code === 0)
          {
            console.log(classifier.toUpperCase() + &#039; Success&#039;);
            //console.log(&#039;PID last line: &#039; + last_line)
            var ll = last_line.split(&#039;=&#039;);
            var pid = ll[1];
            console.log(&#039;NEW PID=: &#039; + pid);
            //console.log(&#039;ALL_DATASETS: &#039; + JSON.stringify(ALL_DATASETS));
            if (helpers.isInt(pid))
            {
              connection.query(queries.get_select_datasets_queryPID(pid), function (err, rows1, fields) {
                if (err)
                {
                  console.log(&#039;1-GAST/RDP-Query error: &#039; + err);
                }
                else
                {
                  connection.query(queries.get_select_sequences_queryPID(pid), function (err, rows2, fields) {
                  if (err)
                  {
                    console.log(&#039;2-GAST/RDP-Query error: &#039; + err);
                  }
                  else
                  {
                    helpers.assignment_finish_request(res, rows1, rows2, status_params);
                    status_params.status = status_params.statusOK;
                    status_params.msg = status_params.msgOK;
                    helpers.update_status(status_params);

                    ALL_CLASSIFIERS_BY_PID[pid] = classifier + &#039;_&#039; + ref_db_dir;
                    console.log(&#039;FROM func. ALL_CLASSIFIERS_BY_PID: &#039; + ALL_CLASSIFIERS_BY_PID);
                    console.log(&#039;FROM func. ALL_CLASSIFIERS_BY_PID[pid]: &#039; + ALL_CLASSIFIERS_BY_PID[pid]);

                  }

                });
                } // end else

              });

            }
            else
            { // end if int
              console.log(&#039;ERROR pid is not an integer: &#039;, pid);
            }
          }
          else
          {
            // ERROR
            console.log(&#039;ERROR last line: &#039; + last_line);
            //req.flash(&#039;message&#039;, &#039;Script Error&#039;);
            //res.redirect(&quot;/user_data/your_projects&quot;);
          }
        }); // end gast_process ON Close
      }
    });

  });

  status_params.status = status_params.statusSUCCESS;
  status_params.msg = status_params.msgSUCCESS;
  helpers.update_status(status_params);
  req.flash(&#039;successMessage&#039;, classifier + &quot; has been started for project: &#039;&quot; + project + &quot;&#039;&quot;);
  res.redirect(&quot;/user_data/your_projects&quot;);

});
//
// YOUR PROJECTS
//
router.get(&#039;/your_projects&#039;,  helpers.isLoggedIn,   function (req, res) {
    //console.log(PROJECT_INFORMATION_BY_PNAME);
    var user_projects_base_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    // if (req.CONFIG.hostname.substring(0, 7) == &#039;bpcweb7&#039;) {
    //     var user_projects_base_dir = path.join(&#039;/groups/vampsweb/vampsdev_user_data/&#039;, req.user.username);
    // } else if (req.CONFIG.hostname.substring(0, 7) == &#039;bpcweb8&#039;) {
    //     var user_projects_base_dir = path.join(&#039;/groups/vampsweb/vamps_user_data/&#039;, req.user.username);
    // } else {
    //     var user_projects_base_dir = path.join(process.env.PWD, &#039;user_data&#039;, NODE_DATABASE, req.user.username);
    // }
  project_info = {};
  pnames = [];
    fs.readdir(user_projects_base_dir,  function (err,  items) {
    if (err) {

      fs.ensureDir(user_projects_base_dir,  function (err) {
        console.log(err); // =&gt; null
        // dir has now been created,  including the directory it is to be placed in
      });


    } else {
        for (var d in items) {
                var pts = items[d].split(&#039;-&#039;);
                if (pts[0] === &#039;project&#039;) {

          var project_name = pts[1];
          var stat_dir = fs.statSync(path.join(user_projects_base_dir, items[d]));

          if (stat_dir.isDirectory()) {
            // stat.mtime.getTime() is for sorting to list in oreder

            // need to read config file
            // check status?? dir strcture: analisis/gast/&lt;ds&gt;
            var config_file = path.join(user_projects_base_dir, items[d], &#039;config.ini&#039;);

            try {
              //var stat_config = fs.statSync(config_file);
               // console.log(&#039;1 &#039;, config_file)
              var config = iniparser.parseSync(config_file);
              var list_of_datasets = Object.keys(config.DATASETS);
              project_info[project_name] = {};
              project_info[project_name].validation = {};
              pnames.push(project_name);

              //new_status = helpers.get_status(req.user.username, project_name);
              //console.log(new_status); // Async only -- doesn&#039;t work
              //console.log(ALL_CLASSIFIERS_BY_PID);
              // console.log(&#039;2 &#039;, config_file)
              if (project_name in PROJECT_INFORMATION_BY_PNAME) {
                      project_info[project_name].pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
                      project_info[project_name].tax_status = &#039;Taxonomic Data Available&#039;;
                      project_info[project_name].classified_by = ALL_CLASSIFIERS_BY_PID[PROJECT_INFORMATION_BY_PNAME[project_name].pid];
              } else {
                  var metadata_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project_name, &#039;metadata_clean.csv&#039;);
                  var fasta_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project_name, &#039;metadata_clean.csv&#039;);
                  //console.log(&#039;config.DATASETS&#039;, config.DATASETS)
                  project_info[project_name].validation[&#039;metadata_clean.csv&#039;] = helpers.fileExists(metadata_file);  // true or false

                  for (var i in list_of_datasets) {
                      var dsname = list_of_datasets[i];
                      var unique_file = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project_name, dsname+&#039;.fa.unique&#039;);
                      project_info[project_name].validation[dsname+&#039;.fa.unique&#039;] = helpers.fileExists(unique_file);  // true or false
                  }
                  project_info[project_name].pid = 0;
                  project_info[project_name].tax_status = &#039;No Taxonomic Assignments Yet&#039;;
                  project_info[project_name].classified_by = &#039;none&#039;;
              }
              //project_info[project_name].config = config;
              project_info[project_name].directory = items[d];
              project_info[project_name].mtime = stat_dir.mtime;
              project_info[project_name].project = project_name;
              project_info[project_name].number_of_datasets = config.GENERAL.number_of_datasets;
              project_info[project_name].project_sequence_count = config.GENERAL.project_sequence_count;
              project_info[project_name].public = config.GENERAL.public;
              project_info[project_name].env_source_id = config.GENERAL.env_source_id;
              project_info[project_name].DATASETS = config.DATASETS;
            }
            catch (err) {
              //console.log(&#039;nofile &#039;, err);
            }

          }

        }
      }

      pnames.sort();
      //console.log(pnames);
      console.log(JSON.stringify(project_info));

    }  // readdir/err

      res.render(&#039;user_data/your_projects&#039;,
          { title: &#039;User Projects&#039;,
            pinfo: JSON.stringify(project_info),
            pnames: pnames,
            env_sources :   JSON.stringify(req.CONSTS.ENV_SOURCE),
            failmessage : req.flash(&#039;failMessage&#039;),
            successmessage : req.flash(&#039;successMessage&#039;),
            user: req.user,  hostname: req.CONFIG.hostname
        });

    });  // readdir

});
//
//   GET -- EDIT_PROJECT: When first enter the page.
//
router.get(&#039;/edit_project/:project&#039;,  helpers.isLoggedIn,  function (req, res) {
  console.log(&#039;in edit project:GET&#039;);
  var project_name = req.params.project;
  var user_projects_base_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);


  var config_file = path.join(user_projects_base_dir, &#039;project-&#039;+project_name, &#039;config.ini&#039;);

  //console.log(config_file);

  var project_info = {};
    //var stat_config = fs.statSync(config_file);
   project_info.config = iniparser.parseSync(config_file);

  if (project_name in PROJECT_INFORMATION_BY_PNAME) {   // these projects have tax assignments
    console.log(PROJECT_INFORMATION_BY_PNAME[project_name]);
    project_info.pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
    project_info.status = &#039;Taxonomic Data Available&#039;;
    project_info.tax = &#039;GAST&#039;;
    project_info.title = PROJECT_INFORMATION_BY_PNAME[project_name].title;
    project_info.pdesc = PROJECT_INFORMATION_BY_PNAME[project_name].description;
    project_info.public = PROJECT_INFORMATION_BY_PNAME[project_name].public;


    //console.log(&#039;datasets with dids&#039;)
    //project_info.dids = DATASET_IDS_BY_PID[project_info.pid]
    //console.log(PROJECT_INFORMATION_BY_PID[project_info.pid]);
    //console.log(DATASET_IDS_BY_PID[project_info.pid]);

    project_info.dsets = [];
    for (var i = 0; i &lt; ALL_DATASETS.projects.length; i++) {
      if (ALL_DATASETS.projects[i].pid == project_info.pid) {
        for (var d = 0; d &lt; ALL_DATASETS.projects[i].datasets.length; d++) {
          var did = ALL_DATASETS.projects[i].datasets[d].did;
          var ds  = ALL_DATASETS.projects[i].datasets[d].dname;
          var ddesc = ALL_DATASETS.projects[i].datasets[d].ddesc;

          project_info.dsets.push({ &quot;did&quot;:did,  &quot;name&quot;:ds,  &quot;ddesc&quot;:ddesc });
        }
      }
    }


  } else {
    project_info.pid =0;
    project_info.status = &#039;No Taxonomic Assignments Yet&#039;;
    project_info.tax = 0;
    project_info.dsets = [];
    project_info.title = project_info.config.GENERAL.project_title;
    project_info.pdesc = project_info.config.GENERAL.project_description;
    if (project_info.config.GENERAL.public == &#039;True&#039; || project_info.config.GENERAL.public == 1) {
      project_info.public = 1;
    } else {
      project_info.public = 0;
    }

    for (var ds in project_info.config.DATASETS) {
      project_info.dsets.push({ &quot;did&quot;:&#039;&#039;,  &quot;name&quot;:ds,  &quot;ddesc&quot;:&#039;&#039; });
    }

  }

  res.render(&#039;user_data/edit_project&#039;,  {
        title       : &#039;Edit Project&#039;,
        project     : project_name,
        pinfo       : JSON.stringify(project_info),
        env_sources : JSON.stringify(req.CONSTS.ENV_SOURCE),
        message     : req.flash(&#039;message&#039;),
        user: req.user,  hostname: req.CONFIG.hostname,
    });
});

//
//   POST -- EDIT_PROJECT:  for accepting changes and re-showing the page
//

router.post(&#039;/edit_project&#039;,  helpers.isLoggedIn,  function (req, res) {
  console.log(&#039;in edit project:POST&#039;);
  console.log(req.body);


  if (req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name) {
    if (req.body.new_project_name in PROJECT_INFORMATION_BY_PNAME) {
      console.log(&#039;ERROR&#039;);
      req.flash(&#039;message&#039;,  &#039;That project name is taken -- choose another.&#039;);
      res.redirect(&#039;/user_data/edit_project/&#039;+req.body.old_project_name);
      return;
    }
  }


  // UPDATE DB ONLY if TAX ASSIGNMENTS PRESENT
  if (req.body.project_pid !== 0 &amp;&amp; req.body.project_pid !== &#039;0&#039;) {
    //sql call to projects,  datasets
    var p_sql = &quot;UPDATE project set project=&#039;&quot;+req.body.new_project_name+&quot;&#039;, \n&quot;;
    p_sql += &quot; title=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_project_title)+&quot;&#039;, \n&quot;;
    p_sql += &quot; rev_project_name=&#039;&quot;+helpers.reverse(req.body.new_project_name)+&quot;&#039;, \n&quot;;
    p_sql += &quot; project_description=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_project_description)+&quot;&#039;, \n&quot;;
    if (req.body.new_privacy == &#039;False&#039;) {
      p_sql += &quot; public=&#039;0&#039;\n&quot;;
    } else {
      p_sql += &quot; public=&#039;1&#039;\n&quot;;
    }
    p_sql += &quot; WHERE project_id=&#039;&quot;+req.body.project_pid+&quot;&#039; &quot;;
    console.log(p_sql);
    connection.query(p_sql,  function (err,  rows,  fields) {
       if (err) {
         console.log(&#039;ERROR-in project update: &#039;+err);
       } else {
         console.log(&#039;OK- project info updated: &#039;+req.body.project_pid);
       }
    });

    // TODO  needed updates to data objects:
    //1- PROJECT_INFORMATION_BY_PNAME
    //console.log(&#039;PROJECT_INFORMATION_BY_PNAME&#039;)
    var tmp = PROJECT_INFORMATION_BY_PNAME[req.body.old_project_name];
    delete PROJECT_INFORMATION_BY_PNAME[req.body.old_project_name];
    PROJECT_INFORMATION_BY_PNAME[req.body.new_project_name] = tmp;
    //console.log(PROJECT_INFORMATION_BY_PNAME);

    //2- PROJECT_INFORMATION_BY_PID
    //console.log(&#039;PROJECT_INFORMATION_BY_PID&#039;)
    //console.log(req.body.project_pid);

    PROJECT_INFORMATION_BY_PID[req.body.project_pid].project         = req.body.new_project_name;
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].env_source_name = req.CONSTS.ENV_SOURCE[req.body.new_env_source_id];
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].title           = req.body.new_project_title;
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].description     = req.body.new_project_description;
    if (req.body.new_privacy == &#039;False&#039;) {
      PROJECT_INFORMATION_BY_PID[req.body.project_pid].public = 0;
    } else {
      PROJECT_INFORMATION_BY_PID[req.body.project_pid].public = 1;
    }

    //console.log(PROJECT_INFORMATION_BY_PID[req.body.project_pid]);

    for (var d in req.body.new_dataset_names) {
      var d_sql = &quot;UPDATE dataset set dataset=&#039;&quot;+req.body.new_dataset_names[d]+&quot;&#039;, \n&quot;;
      d_sql += &quot; env_sample_source_id=&#039;&quot;+req.body.new_env_source_id+&quot;&#039;, \n&quot;;
      d_sql += &quot; dataset_description=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_dataset_descriptions[d])+&quot;&#039;\n&quot;;
      d_sql += &quot; WHERE dataset_id=&#039;&quot;+req.body.dataset_ids[d]+&quot;&#039; &quot;;
      d_sql += &quot; AND project_id=&#039;&quot;+req.body.project_pid+&quot;&#039; &quot;;
      //console.log(d_sql);
      // TODO: Don&#039;t make functions within a loop.
      connection.query(d_sql,  function (err,  rows,  fields) {
        if (err) {
          console.log(&#039;ERROR - in dataset update: &#039;+err);
        } else {
          console.log(&#039;OK - dataset info updated: &#039;+req.body.dataset_ids[d]);
        }
      });
      //3- DATASET_NAME_BY_DID
      //console.log(&#039;DATASET_NAME_BY_DID&#039;)
      //console.log(DATASET_NAME_BY_DID[req.body.dataset_ids[d]]);
      DATASET_NAME_BY_DID[req.body.dataset_ids[d]] = req.body.new_dataset_names[d];
      //console.log(DATASET_NAME_BY_DID[req.body.dataset_ids[d]]);
    }



    //4- ALL_DATASETS
    //console.log(&#039;ALL_DATASETS&#039;)
    //console.log(ALL_DATASETS.projects[0]);
    for (var i = 0; i &lt; ALL_DATASETS.projects.length; i++) {
      if (ALL_DATASETS.projects[i].pid == req.body.project_pid) {
        ALL_DATASETS.projects[i].name = req.body.new_project_name;
        ALL_DATASETS.projects[i].title = req.body.new_project_title;

        for (var d = 0; d &lt; ALL_DATASETS.projects[i].datasets.length; d++) {
          var did = ALL_DATASETS.projects[i].datasets[d].did;
          var idx = req.body.dataset_ids.indexOf(did.toString());
          ALL_DATASETS.projects[i].datasets[d].dname = req.body.new_dataset_names[idx];
          ALL_DATASETS.projects[i].datasets[d].ddesc = req.body.new_dataset_descriptions[idx];

        }
      }
    }

  }


  var project_info = {};
  var project_name = req.body.old_project_name;
  var user_projects_base_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);

  var project_dir = path.join(user_projects_base_dir, &#039;project-&#039;+project_name);
  var config_file = path.join(project_dir, &#039;config.ini&#039;);
  var timestamp = +new Date();  // millisecs since the epoch!
  var config_file_bu = path.join(project_dir, &#039;config&#039;+timestamp+&#039;.ini&#039;);
  fs.copy(config_file,  config_file_bu,  function (err) {
        if (err) {
          console.log(err);
        } else {
          console.log(&quot;copy success!&quot;);
        }
  }); // copies fi
  //console.log(config_file);

  project_info.config = iniparser.parseSync(config_file);

  //console.log(&#039;config:&#039;);
  //console.log(JSON.stringify(project_info.config));
  // HAS NO ASSIGNMENTS: NEED CHANGE FILES ONLY
  // changing data on the system must take this into account:
  // if the project has no assignments yet then it has no data in the database (ie no pid).
  // So just (1)alter the config.ini and the (2)directory name where it is located in user_data/NODE_DATABASE/&lt;user&gt;/project:*
  // Also the dataset (3)directories need to be updated.

  config_info = {};

  if (req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name) {
    console.log(&#039;updating project name&#039;);
    var new_project_name = req.body.new_project_name.replace(/[\s+, ;:]/g, &#039;_&#039;);
    config_info.project = new_project_name;
    project_info.config.GENERAL.project=new_project_name;
    new_base_dir = path.join(user_projects_base_dir, &#039;project-&#039;+new_project_name);
    new_config_file = path.join(new_base_dir, &#039;config.ini&#039;);
    new_fasta_file = path.join(new_base_dir, &#039;infile.fna&#039;);
    config_info.baseoutputdir = new_base_dir;
    config_info.configPath = new_config_file;
    config_info.fasta_file = new_fasta_file;
    project_name = new_project_name;

  } else {
    config_info.project = project_name;
    config_info.baseoutputdir = project_info.config.GENERAL.baseoutputdir;
    config_info.configPath = project_info.config.GENERAL.configPath;
    config_info.fasta_file = project_info.config.GENERAL.fasta_file;
  }

  if (req.body.new_project_title) {
    console.log(&#039;updating project title&#039;);

    config_info.project_title = req.body.new_project_title;
    project_info.config.GENERAL.project_title = req.body.new_project_title;
  } else {
    config_info.project_title = project_info.config.GENERAL.project_title;
  }
  if (req.body.new_project_description) {
    console.log(&#039;updating project description&#039;);
    config_info.project_description = req.body.new_project_description;
    project_info.config.GENERAL.project_description = req.body.new_project_description;
  } else {
    config_info.project_description = project_info.config.GENERAL.project_description;
  }

  config_info.platform = project_info.config.GENERAL.platform;
  config_info.owner = project_info.config.GENERAL.owner;
  config_info.config_file_type = project_info.config.GENERAL.config_file_type;
  if (req.body.new_privacy != project_info.config.GENERAL.public) {
    console.log(&#039;updating privacy&#039;);
    config_info.public = req.body.new_privacy;
    project_info.config.GENERAL.public =req.body.new_privacy;
  } else {
    config_info.public = project_info.config.GENERAL.public;
  }

  config_info.fasta_type = project_info.config.GENERAL.fasta_type;
  config_info.dna_region = project_info.config.GENERAL.dna_region;
  config_info.project_sequence_count = project_info.config.GENERAL.project_sequence_count;
  config_info.domain = project_info.config.GENERAL.domain;
  config_info.number_of_datasets = project_info.config.GENERAL.number_of_datasets;
  config_info.sequence_counts = project_info.config.GENERAL.sequence_counts;

  if (req.body.new_env_source_id != project_info.config.GENERAL.env_source_id) {
    console.log(&#039;updating env id&#039;);
    config_info.env_source_id = req.body.new_env_source_id;
    project_info.config.GENERAL.env_source_id = req.body.new_env_source_id;
  } else {
    config_info.env_source_id = project_info.config.GENERAL.env_source_id;
  }

  config_info.has_tax = project_info.config.GENERAL.has_tax;

  var old_dataset_array = Object.keys(project_info.config.DATASETS).map(function (k) { return k; });
  var counts_array = Object.keys(project_info.config.DATASETS).map(function (k) { return project_info.config.DATASETS[k]; });
  console.log(old_dataset_array);
  project_info.config.DATASETS={};
  config_info.datasets = [];
  for (var n in req.body.dataset_ids) {
    new_dataset_name = req.body.new_dataset_names[n].replace(/[\s+, ;:]/g, &#039;_&#039;);
    config_info.datasets.push({&quot;oldname&quot;:old_dataset_array[n], &quot;dsname&quot;:new_dataset_name, &quot;did&quot;:req.body.dataset_ids[n], &quot;count&quot;:counts_array[n]});
  }

  //console.log(config_info.datasets);
  if (req.body.project_pid &gt; 0) {
    // TODO: HAS ASSIGNMENTS: NEED CHANGE DB &amp; FILES
    // If the project has assignments:
    // change the three places on the file system as above but also:
    // the project_name, title, description and public in NODE_DATABASE.project
    // and the dataset_name, description and env_id in NODE_DATABASE.dataset
    // Also need to update PROJECT_INFORMATION_BY_PNAME
  }


  if (project_name in PROJECT_INFORMATION_BY_PNAME) {
    project_info.pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
    project_info.status = &#039;Taxonomic Data Available&#039;;
    project_info.tax = &#039;GAST&#039;;
  } else {
    project_info.pid = 0;
    project_info.status = &#039;No Taxonomic Assignments Yet&#039;;
    project_info.tax = 0;
  }


  if (req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name) {
    config_info.old_base_name = project_info.config.GENERAL.baseoutputdir;
    update_config(res, req,  config_file,  config_info,  true,  &#039;Updated project: &#039;+config_info.project);
  } else {
    update_config(res, req,  config_file,  config_info,   false,  &#039;Updated project: &#039;+config_info.project);
  }


});
//
//  UPLOAD  METADATA
//
router.post(&#039;/upload_metadata&#039;,  [helpers.isLoggedIn,  upload.single(&#039;upload_file&#039;,  12)],  function (req, res) {
  var project = req.body.project_name;
  var file_format = req.body.metadata_file_format;
  var original_metafile = path.join(process.env.PWD, req.file.path);
  var username = req.user.username;
  console.log(&#039;1-req.body upload_metadata&#039;);
  console.log(req.body);
  console.log(req.file);
  console.log(&#039;2-req.body upload_metadata&#039;);
  var has_tax = false;
  if (project in PROJECT_INFORMATION_BY_PNAME) {
    has_tax = true;

  }

  var timestamp = +new Date();  // millisecs since the epoch!
  var data_repository = path.join(req.CONFIG.USER_FILES_BASE,req.user.username,&#039;project-&#039;+project);

					var options = { scriptPath : req.CONFIG.PATH_TO_NODE_SCRIPTS,
		        			args : [ &#039;-i&#039;, original_metafile, &#039;-t&#039;,file_format,&#039;-o&#039;, username, &#039;-p&#039;, project, &#039;-db&#039;, NODE_DATABASE, &#039;-add&#039;,&#039;-pdir&#039;,process.env.PWD,]
		    			};
					if(has_tax){
						options.args = options.args.concat([&#039;--has_tax&#039;]);
					}
					console.log(options.scriptPath+&#039;/metadata_utils.py &#039;+options.args.join(&#039; &#039;));
					
					var log = fs.openSync(path.join(process.env.PWD,&#039;logs&#039;,&#039;upload.log&#039;), &#039;a&#039;);
					var upload_metadata_process = spawn( options.scriptPath+&#039;/metadata_utils.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr
					var output = &#039;&#039;;
					console.log(&#039;py process pid=&#039;+upload_metadata_process.pid);
					upload_metadata_process.stdout.on(&#039;data&#039;, function (data) {
					  console.log(&#039;stdout: &#039; + data);
					  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
					  output += data;

					  // var lines = data.split(&#039;\n&#039;)
					  // for(var n in lines){
					  // 	//console.log(&#039;line: &#039; + lines[n]);
							// if(lines[n].substring(0,4) == &#039;PID=&#039;){
							// 	console.log(&#039;pid line &#039;+lines[n]);
							// }
					  // }
					});
					upload_metadata_process.on(&#039;close&#039;, function (code) {
				   console.log(&#039;upload_metadata_process exited with code &#039; + code);
				   var ary = output.split(&quot;\n&quot;);
				   var last_line = ary[ary.length - 1];
				   if(code === 0){
					   		console.log(&#039;Upload METADATA Success&#039;);
					   		//console.log(&#039;PID last line: &#039;+last_line)
					   		//var ll = last_line.split(&#039;=&#039;);
					   		// possible multiple pids
					    	if(has_tax){
					   			console.log(PROJECT_INFORMATION_BY_PNAME[project]);
					   			pid = PROJECT_INFORMATION_BY_PNAME[project].pid;
									connection.query(queries.get_select_datasets_queryPID(pid), function (err, rows1, fields){
								    if (err)  {
							 		  	console.log(&#039;1-Upload METADATA-Query error: &#039; + err);				 		  			
							      } else {
			        				   	connection.query(queries.get_select_sequences_queryPID(pid), function (err, rows2, fields){
			        				   		if (err)  {
			        				 		  	console.log(&#039;2-Upload METADATA-Query error: &#039; + err);        				 		
			        				    	} else {

			                      												
															//helpers.update_metadata_from_file();  // need to update to hdf5 file??

															req.flash(&#039;successMessage&#039;, &#039;Metadata Upload in Progress&#039;);
			       									res.redirect(&quot;/user_data/import_choices&quot;);
			        				    	}

			        				   	});
								   	} // end else

							   	});
								}else{  // end if(has_tax)
									req.flash(&#039;successMessage&#039;, &#039;Metadata Upload in Progress&#039;);
			       			res.redirect(&quot;/user_data/import_choices&quot;);
								}

				   }else{
				   		// ERROR
				   		//console.log(last_line);
					    console.log(&#039;ERROR last line: &#039;+last_line);

			   	  	// NO REDIRECT here
			   	  	req.flash(&#039;failMessage&#039;, &#039;Script Error: &#039;+last_line);
			        res.redirect(&quot;/user_data/import_choices&quot;);
				   }
				});  // end upload_metadata_process ON Close

//	});

});

//
//  UPLOAD DATA
//
// TODO: Andy, how to make it fail? For testing?
function ProjectNameGiven(project, req, res)
{
  if (project === &#039;&#039; || req.body.project === undefined) {
    req.flash(&#039;failMessage&#039;,  &#039;A project name is required.&#039;);
    res.redirect(&quot;/user_data/import_data?import_type=&quot; + req.body.type);
    return;
  }
}

function ProjectNameExists(project, req, res)
{
  // console.log(&#039;BBB: ProjectNameExists: PROJECT_INFORMATION_BY_PNAME &#039;);
  // console.log(util.inspect(PROJECT_INFORMATION_BY_PNAME, false, null));
  // 
  // console.log(&#039;BBB: ProjectNameExists: project: &#039; + project);

  if (project in PROJECT_INFORMATION_BY_PNAME) {
      req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
      res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
    return;
  }
}

function FastaExists(req, res)
{
  if (req.files[0].filename === undefined || req.files[0].size === 0) {
    req.flash(&#039;failMessage&#039;,  &#039;A fasta file is required.&#039;);
    res.redirect(&quot;/user_data/import_data?import_type=&quot; + req.body.type);
    return;
  }
}

function FilePathExists(req, data_repository, res)
{
  if (helpers.fileExists(data_repository)) {
    req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
    res.redirect(&quot;/user_data/import_data?import_type=&quot; + req.body.type);
    return;
  }
}

function MetadataFileExists(req, res)
{
  console.log(&quot;DDD55 MetadataFileExists: &quot;);
  console.log(&quot;===&quot;);
 
  if (req.files[1].filename === undefined || req.files[1].size === 0) {
    req.flash(&#039;failMessage&#039;,  &#039;A metadata csv file is required.&#039;);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  }
}



function ProjectValidation(req, project, data_repository, res)
{
  console.log(&quot;AAA2 data_repository&quot;);
  console.log(data_repository);
  
  
  console.log(&#039;EEE: req.flash: &#039; + req.flash);
  console.log(&#039;EEE: req.body.project: &#039; + req.body.project);

  console.log(&#039;EEE: req.body.type: &#039; + req.body.type);
  console.log(&#039;EEE: project: &#039; + project);
  ProjectNameGiven(project, req, res);
  ProjectNameExists(project, req, res);
  FastaExists(req, res);
  FilePathExists(req, data_repository, res);
  MetadataFileExists(req, res);
  
// if (project === &#039;&#039; || req.body.project === undefined) {
//   req.flash(&#039;failMessage&#039;,  &#039;A project name is required.&#039;);
//   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
//   return;
// } else if (project in PROJECT_INFORMATION_BY_PNAME) {
//   req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
//   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
//   return;
// } else if (req.files[0].filename === undefined || req.files[0].size === 0) {
//   req.flash(&#039;failMessage&#039;,  &#039;A fasta file is required.&#039;);
//   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
//   return;
// } else if (helpers.fileExists(data_repository)) {
//   req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
//   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
//   return;
// }
// else if (req.files[1].filename === undefined || req.files[1].size === 0) {
//   req.flash(&#039;failMessage&#039;,  &#039;A metadata csv file is required.&#039;);
  // res.redirect(&quot;/user_data/import_data&quot;);
  // return;
}

router.post(&#039;/upload_data&#039;,  [helpers.isLoggedIn,  upload.array(&#039;upload_files&#039;,  12)],  function (req, res) {
    var exec = require(&#039;child_process&#039;).exec;
  var project = helpers.clean_string(req.body.project);
  var username = req.user.username;
  console.log(&#039;1-req.body upload_data&#039;);
  console.log(req.body);
  console.log(req.files);
  console.log(&#039;2-req.body upload_data&#039;);
  //console.log(project);

  //console.log(PROJECT_INFORMATION_BY_PNAME);
  var data_repository = path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;project-&#039;+project);

  var fs_old   = require(&#039;fs&#039;);
  
  console.log(&quot;AAA1 data_repository&quot;);
  console.log(data_repository);
  
  if (ProjectValidation(req, project, data_repository, res) === false)
  {
    return;
  // if (project === &#039;&#039; || req.body.project === undefined) {
  //   req.flash(&#039;failMessage&#039;,  &#039;A project name is required.&#039;);
  //   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
  //   return;
  // } else if (project in PROJECT_INFORMATION_BY_PNAME) {
  //   req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
  //   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
  //   return;
  // } else if (req.files[0].filename === undefined || req.files[0].size === 0) {
  //   req.flash(&#039;failMessage&#039;,  &#039;A fasta file is required.&#039;);
  //   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
  //   return;
  // } else if (helpers.fileExists(data_repository)) {
  //   req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
  //   res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);
  //   return;
  // }
  // else if (req.files[1].filename === undefined || req.files[1].size === 0) {
  //   req.flash(&#039;failMessage&#039;,  &#039;A metadata csv file is required.&#039;);
    // res.redirect(&quot;/user_data/import_data&quot;);
    // return;
  }
  else {
      console.log(data_repository);

      var original_fastafile = path.join(req.CONFIG.TMP,  req.files[0].filename);
      fasta_compressed = metadata_compressed = false;
      if (req.files[0].mimetype === &#039;application/x-gzip&#039;) {
        fasta_compressed = true;
      }
      status_params = {&#039;type&#039;:&#039;new&#039;,  &#039;user_id&#039;:req.user.user_id,
                      &#039;project&#039;:project,  &#039;status&#039;:&#039;OK&#039;,   &#039;msg&#039;:&#039;Upload Started&#039;  };
      //helpers.update_status(status_params);
      var options = { scriptPath : req.CONFIG.PATH_TO_NODE_SCRIPTS,
                  args :       [ &#039;-project_dir&#039;,  data_repository,  &#039;-owner&#039;,  username,  &#039;-p&#039;,  project,  &#039;-site&#039;,  req.CONFIG.site,  &#039;-infile&#039;, original_fastafile]
              };
      if (req.files[0].mimetype === &#039;application/x-gzip&#039;) {
        options.args = options.args.concat([&#039;-fa_comp&#039; ]);
      }
      var original_metafile  = &#039;&#039;;
      try{
        //original_metafile  = path.join(process.env.PWD,  &#039;tmp&#039;, req.files[1].filename);
        original_metafile  = path.join(req.CONFIG.TMP, req.files[1].filename);
        options.args = options.args.concat([&#039;-mdfile&#039;,  original_metafile ]);
        if (req.files[1].mimetype === &#039;application/x-gzip&#039;) {
          metadata_compressed = true;
          options.args = options.args.concat([&#039;-md_comp&#039; ]);
        }
      }
      catch(err) {
        console.log(&#039;No Metadata file: &#039;+err+&#039;; Continuing on&#039;);
        original_metafile  = &#039;&#039;;
      }

      if (req.body.type == &#039;simple_fasta&#039;) {
          if (req.body.dataset === &#039;&#039; || req.body.dataset === undefined) {
            req.flash(&#039;failMessage&#039;,  &#039;A dataset name is required.&#039;);
            res.redirect(&quot;/user_data/import_data&quot;);
            return;
          }
          options.args = options.args.concat([&#039;-upload_type&#039;,  &#039;single&#039;,  &#039;-d&#039;,  req.body.dataset ]);
      } else if (req.body.type == &#039;multi_fasta&#039;) {
          options.args = options.args.concat([&#039;-upload_type&#039;,  &#039;multi&#039; ]);
      } else {
          req.flash(&#039;failMessage&#039;,  &#039;No file type info found&#039;);
          res.redirect(&quot;/user_data/import_data&quot;);
          return;
      }

      options.args = options.args.concat([&#039;-q&#039; ]);   // QUIET

      //console.log(original_fastafile);
      //console.log(original_metafile);
       // move files to user_data/&lt;username&gt;/ and rename
      var LoadDataFinishRequest = function () {
          // START STATUS //
          req.flash(&#039;successMessage&#039;,  &quot;Upload in Progress: &#039;&quot;+ project+&quot;&#039;&quot;);

          // type,  user,  project,  status,  msg

          res.render(&#039;success&#039;,  {  title   : &#039;VAMPS: Import Success&#039;,
                            message : req.flash(&#039;successMessage&#039;),
                                  display : &quot;Import_Success&quot;,
                                user    : req.user,  hostname: req.CONFIG.hostname
                    });
      };
      // MOVE FILES: Using python to move files rather than node.js:::

      fs.ensureDir(data_repository,  function (err) {
            if (err) {console.log(&#039;ensureDir err:&#039;, err);} // =&gt; null
            else {
                    fs.chmod(data_repository,  0775,  function (err) {
                        if (err) {
                          console.log(&#039;chmod err:&#039;, err);
                          return;
                        }

                        console.log(options.scriptPath+&#039;/vamps_script_load_trimmed_data.py &#039;+options.args.join(&#039; &#039;));
                        var load_cmd = options.scriptPath+&#039;/vamps_script_load_trimmed_data.py &#039;+options.args.join(&#039; &#039;);
                        var cmd_list = [load_cmd];
                        if (req.body.type == &#039;multi_fasta&#039;) {
                            var new_fasta_file_name = &#039;infile.fna&#039;;
                            var demultiplex_cmd = options.scriptPath +&#039;/vamps_script_demultiplex.sh &#039; + data_repository + &#039; &#039; + new_fasta_file_name;
                            cmd_list.push(demultiplex_cmd);
                        }
                        var fnaunique_cmd = options.scriptPath +&#039;/vamps_script_fnaunique.sh &#039; + req.CONFIG.PATH + &quot; &quot; + data_repository;
                        cmd_list.push(fnaunique_cmd);
                        //var log = fs.openSync(path.join(data_repository, &#039;upload.log&#039;),  &#039;a&#039;);

                        //////////////////////////////


                        script_name = &#039;load_script.sh&#039;;
                        var nodelog = fs.openSync(path.join(data_repository, &#039;assignment.log&#039;),  &#039;a&#039;);
 if (req.CONFIG.dbhost == &#039;vampsdev&#039; || req.CONFIG.dbhost == &#039;vampsdb&#039;)
 {
   var scriptlog = path.join(data_repository,  &#039;cluster.log&#039;);
   //var script_text = get_qsub_script_text(scriptlog,  data_dir,  req.CONFIG.dbhost,  classifier,  cmd_list)
   var script_text = get_qsub_script_text(scriptlog,  data_repository,  req.CONFIG.dbhost,  &#039;vampsupld&#039;,  cmd_list);
 }
 else
 {
   var scriptlog = path.join(data_repository,  &#039;script.log&#039;);
   var script_text = get_local_script_text(scriptlog,  &#039;local&#039;,  &#039;vampsupld&#039;,  cmd_list);
 }


                        var script_path = path.join(data_repository,  script_name);






                        fs.writeFile(script_path,  script_text,  function (err) {
                            if (err) return console.log(err);
                            child = exec( &#039;chmod ug+rwx &#039;+script_path,  function (error,  stdout,  stderr) {
                                if (error !== null) {
                                  console.log(&#039;1exec chmod error: &#039; + error);
                                } else {
                                    var run_process = spawn( script_path,  [],  {
                                       //  env:{&#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH,
    //                                             &#039;PATH&#039;:req.CONFIG.PATH,
    //                                             &#039;PERL5LIB&#039;:req.CONFIG.PERL5LIB,
    //                                             &#039;SGE_ROOT&#039;:req.CONFIG.SGE_ROOT,  &#039;SGE_CELL&#039;:req.CONFIG.SGE_CELL,  &#039;SGE_ARCH&#039;:req.CONFIG.SGE_ARCH
    //                                             },
                                        detached: true,  stdio: [ &#039;ignore&#039;,  null,  nodelog ]
                                    } );  // stdin,  s
                                    var output = &#039;&#039;;
                                    run_process.stdout.on(&#039;data&#039;,  function (data) {
                                              //console.log(&#039;stdout: &#039; + data);
                                              data = data.toString().replace(/^\s+|\s+$/g,  &#039;&#039;);
                                              output += data;
                                              var lines = data.split(&#039;\n&#039;);
                                              for (var n in lines) {
                                                //console.log(&#039;line: &#039; + lines[n]);
                                                    if (lines[n].substring(0, 4) == &#039;PID=&#039;) {
                                                        console.log(&#039;pid line &#039;+lines[n]);
                                                    }
                                              }
                                    });
                                    run_process.on(&#039;close&#039;,  function (code) {
                                           console.log(&#039;run_process process exited with code &#039; + code);
                                           var ary = output.split(&quot;\n&quot;);
                                           var last_line = ary[ary.length - 1];
                                           console.log(&#039;last_line:&#039;, last_line);
                                           if (code === 0) {
                                                status_params = {&#039;type&#039;:&#039;update&#039;,  &#039;user_id&#039;:req.user.user_id,
                                                    &#039;project&#039;:project,  &#039;status&#039;:&#039;LOADED&#039;,   &#039;msg&#039;:&#039;Project is loaded --without tax assignments&#039;
                                                  };
                                                //helpers.update_status(status_params);
                                                console.log(&#039;Finished loading &#039;+project);
                                                LoadDataFinishRequest();
                                           } else {
                                            fs.move(data_repository,   path.join(req.CONFIG.USER_FILES_BASE, req.user.username, &#039;FAILED-project-&#039;+project),  function (err) {
                                                if (err) { console.log(err);  }
                                                else {
                                                    req.flash(&#039;failMessage&#039;,  &#039;Script Failure: &#039;+last_line);
                                                    status_params = {&#039;type&#039;:&#039;update&#039;,  &#039;user_id&#039;:req.user.user_id,
                                                        &#039;project&#039;:project,  &#039;status&#039;:&#039;Script Failure&#039;,   &#039;msg&#039;:&#039;Script Failure&#039;
                                                    };
                                                        //helpers.update_status(status_params);
                                                    res.redirect(&quot;/user_data/import_data?import_type=&quot;+req.body.type);  // for now we&#039;ll send errors to the browser
                                                    return;
                                                }
                                            });
                                           }
                                    });
                                } // end if/else
                            }); // end exec
                        });  // end writeFile

          });     //   END chmod
        }         // end else
      });         //   END ensuredir
//      }); //       END move 2
//      });  //     END move 1

  }


});

//
// UPLOAD DATA TAX-BY-SEQ
//
router.post(&#039;/upload_data_tax_by_seq&#039;,   [helpers.isLoggedIn,  upload.array(&#039;upload_files&#039;,  12)],  function (req, res) {

  console.log(&#039;upload_data_tax_by_seq&#039;);
  var project = req.body.project || &#039;&#039;;
  var use_original_names = req.body.use_original_names || &#039;off&#039;;
  var username = req.user.username;
  var use_file_taxonomy = req.body.use_tax_from_file;

  //var p = progress()
  //req.pipe(p)
  //p.headers = req.headers
  //p.on(&#039;progress&#039;,  function (progress) {
  //  console.log(progress);

    /*
    {
      percentage: 9.05,
      transferred: 949624,
      length: 10485760,
      remaining: 9536136,
      eta: 42,
      runtime: 3,
      delta: 295396,
      speed: 949624
    }
    */
  //});
  console.log(&#039;1req.body upload_data_tax_by_seq&#039;);
  console.log(req.body);
  console.log(req.files);  // array
  console.log(&#039;project: &#039;+project || &#039;none&#039;);
  console.log(&#039;use_original_names: &#039;+use_original_names);
  console.log(&#039;2req.body upload_data_tax_by_seq&#039;);
  //console.log(project);
  //console.log(PROJECT_INFORMATION_BY_PNAME);
  if (req.files.length === 0 ) {
    req.flash(&#039;failMessage&#039;,  &#039;Make sure you are choosing a file to upload and that it is smaller than &#039;+ req.CONFIG.UPLOAD_FILE_SIZE+&#039; bytes&#039;);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  }

  if (req.files[0] &amp;&amp; req.files[0].size &gt; config.UPLOAD_FILE_SIZE.bytes) {  // 1155240026
    req.flash(&#039;failMessage&#039;,  &#039;The file &#039;+req.files[0].originalname+&#039; exceeds the limit of &#039;+config.UPLOAD_FILE_SIZE.MB);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  }
  if (req.files[1] &amp;&amp; req.files[1].size &gt; config.UPLOAD_FILE_SIZE.bytes) {
    req.flash(&#039;failMessage&#039;,  &#039;The file &#039;+req.files[1].originalname+&#039; exceeds the limit of &#039;+config.UPLOAD_FILE_SIZE.MB);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  }
  if ((project === &#039;&#039; || req.body.project === undefined) &amp;&amp; req.body.use_original_names != &#039;on&#039;) {
    req.flash(&#039;failMessage&#039;,  &#039;A project name is required.&#039;);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  } else if (project in PROJECT_INFORMATION_BY_PNAME) {
    req.flash(&#039;failMessage&#039;,  &#039;That project name is already taken.&#039;);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  } else if (req.files[0].filename === undefined || req.files[0].size === 0) {
    req.flash(&#039;failMessage&#039;,  &#039;A tax_by_seq file is required.&#039;);
    res.redirect(&quot;/user_data/import_data&quot;);
    return;
  } else {



      //var file_path = path.join(process.env.PWD, req.file.path);
      //var original_taxbyseqfile = path.join(&#039;./user_data&#039;,  NODE_DATABASE,  &#039;tmp&#039;,  req.files[0].filename);
      //var original_metafile  = path.join(&#039;./user_data&#039;,  NODE_DATABASE,  &#039;tmp&#039;,  req.files[1].filename);
      //var original_taxbyseqfile = path.join(process.env.PWD,  &#039;tmp&#039;, req.files[0].filename);
      var original_taxbyseqfile = path.join(&#039;/tmp&#039;, req.files[0].filename);
      console.log(original_taxbyseqfile);
      taxbyseq_compressed = metadata_compressed = false;
      if (req.files[0].mimetype === &#039;application/x-gzip&#039;) {
        taxbyseq_compressed = true;
      }
      var original_metafile  = &#039;&#039;;
      try{
        //original_metafile  = path.join(process.env.PWD,  &#039;tmp&#039;, req.files[1].filename);
        original_metafile  = path.join(&#039;/tmp&#039;, req.files[1].filename);

        if (req.files[1].mimetype === &#039;application/x-gzip&#039;) {
          metadata_compressed = true;
        }
      }
      catch(err) {
        console.log(&#039;No Metadata file: &#039;+err+&#039;; Continuing on&#039;);
        original_metafile  = &#039;&#039;;
      }
    //console.log(&#039;file &#039;+req.files[0].originalname)
    //console.log(req.files[0])
    //console.log(taxbyseq_compressed)
    //console.log(taxbyseq_compressed)
    // { fieldname: &#039;upload_files&#039;,
    //   originalname: &#039;avoorhis_21190707TaxBySeq.txt.gz&#039;,
    //   encoding: &#039;7bit&#039;,
    //   mimetype: &#039;application/x-gzip&#039;,
    //   destination: &#039;/tmp&#039;,
    //   filename: &#039;c903a589970b36746c1bf22503270713&#039;,
    //   path: &#039;/tmp/c903a589970b36746c1bf22503270713&#039;,
    //   size: 234197
    // }
    // { fieldname: &#039;upload_files&#039;,
    //   originalname: &#039;CNE_TaxBySeq.txt&#039;,
    //   encoding: &#039;7bit&#039;,
    //   mimetype: &#039;text/plain&#039;,
    //   destination: &#039;/tmp&#039;,
    //   filename: &#039;3fdba8fdb25390c38e511149f459ee96&#039;,
    //   path: &#039;/tmp/3fdba8fdb25390c38e511149f459ee96&#039;,
    //   size: 1668848
    // }

      var options = { scriptPath : req.CONFIG.PATH_TO_NODE_SCRIPTS,
                  args :       [ &#039;-infile&#039;,  original_taxbyseqfile,  &#039;-o&#039;,  username,  &#039;--upload_type&#039;,  &#039;multi&#039;,
                                  &#039;--process_dir&#039;,  process.env.PWD, &#039;-db&#039;,  NODE_DATABASE,  &#039;-host&#039;,  req.CONFIG.dbhost ]
      };
      if (taxbyseq_compressed) {
        options.args = options.args.concat([&#039;-tax_comp&#039;]);
      }
      if (original_metafile) {
        options.args = options.args.concat([&#039;-md_file&#039;, original_metafile]);
        if (metadata_compressed) {
          options.args = options.args.concat([&#039;-md_comp&#039;]);
        }
      }
      if (use_file_taxonomy === &#039;1&#039;) {
        options.args = options.args.concat([&#039;-use_tax&#039;]);
      }
      if (use_original_names == &#039;on&#039;) {
          options.args = options.args.concat([&#039;-orig_names&#039;]);
      } else if (use_original_names == &#039;off&#039;) {
          options.args = options.args.concat([&#039;-p&#039;,  project]);
      } else {
          req.flash(&#039;failMessage&#039;,  &#039;No file type info found:  &#039;);
          res.redirect(&quot;/user_data/import_data&quot;);
          return;
      }

      //console.log(original_fastafile);
      //console.log(original_metafile);
       // move files to user_data/&lt;username&gt;/ and rename
      var LoadDataFinishRequest = function () {
          // START STATUS //
          req.flash(&#039;successMessage&#039;,  &quot;Upload in Progress&quot;);

          // type,  user,  project,  status,  msg

          res.render(&#039;success&#039;,  {  title   : &#039;VAMPS: Import Success&#039;,
                          message : req.flash(&#039;successMessage&#039;),
                          display : &quot;TaxBySeq_Import_Success&quot;,
                          user    : req.user,  hostname: req.CONFIG.hostname
              });
      };

        //console.log(&#039;Moved file &#039;+req.file.filename+ &#039; to &#039;+path.join(data_dir, &#039;tax_by_seq.txt&#039;))

        console.log(options.scriptPath+&#039;/vamps_load_tax_by_seq.py &#039;+options.args.join(&#039; &#039;));

        var log = fs.openSync(path.join(process.env.PWD, &#039;logs&#039;, &#039;upload_taxbyseq.log&#039;),  &#039;a&#039;);


        var tax_by_seq_process = spawn( options.scriptPath+&#039;/vamps_load_tax_by_seq.py&#039;,  options.args,  {
                              env:{ &#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH,  &#039;PATH&#039;:req.CONFIG.PATH },
                              detached: true,  stdio: [ &#039;ignore&#039;,  null,  log ]
                            });  // stdin,  stdout,  stderr
        console.log(&#039;py process pid=&#039;+tax_by_seq_process.pid);
        var output = &#039;&#039;;
        // communicating with an external python process
        // all the print statements in the py script are printed to stdout
        // so you can grab the projectID here at the end of the process.
        // use looging in the script to log to a file.
        tax_by_seq_process.stdout.on(&#039;data&#039;,  function (data) {
            //console.log(&#039;Processing data&#039;);
            data = data.toString().replace(/^\s+|\s+$/g,  &#039;&#039;);
            output += data;
            var lines = data.split(&#039;\n&#039;);
            for (var n in lines) {
              //console.log(&#039;line: &#039; + lines[n]);
              if (lines[n].substring(0, 4) == &#039;PID=&#039;) {
                console.log(&#039;pid line &#039;+lines[n]);
              }
            }
        });
        tax_by_seq_process.on(&#039;close&#039;,  function (code) {
           console.log(&#039;tax_by_seq_process exited with code &#039; + code);
           //console.log(&#039;output&#039;, output);
           var ary = output.split(&quot;\n&quot;);
           var last_line = ary[ary.length - 1];
           if (code === 0) {
             console.log(&#039;TAXBYSEQ Success&#039;);
             //console.log(&#039;PID last line: &#039;+last_line)
             if (use_file_taxonomy) {
                 var ll = last_line.split(&#039;=&#039;);
                 // possibly multiple pids
                 pid_list = ll[1].split(&#039;-&#039;);
                 for (var i in pid_list) {
                   //var pid = ll[1];
                   var pid = pid_list[i];
                   console.log(&#039;NEW PID=: &#039;+pid);
                   //console.log(&#039;ALL_DATASETS: &#039;+JSON.stringify(ALL_DATASETS));
                   if (helpers.isInt(pid)) {
                     // TODO: Don&#039;t make functions within a loop.
                      connection.query(queries.get_select_datasets_queryPID(pid),  function (err,  rows1,  fields) {
                        if (err)  {
                           console.log(&#039;1-TAXBYSEQ-Query error: &#039; + err);
                        } else {
                               connection.query(queries.get_select_sequences_queryPID(pid),  function (err,  rows2,  fields) {
                                 if (err)  {
                                   console.log(&#039;2-TAXBYSEQ-Query error: &#039; + err);
                                } else {
                                  status_params = {&#039;type&#039;:&#039;update&#039;,  &#039;user_id&#039;:req.user.user_id,
                                                  &#039;pid&#039;:pid, &#039;status&#039;:&#039;TAXBYSEQ-SUCCESS&#039;, &#039;msg&#039;:&#039;TAXBYSEQ -Tax assignments&#039; };

                                  helpers.assignment_finish_request(res, rows1, rows2, status_params);
                                  helpers.update_status(status_params);
                                  ALL_CLASSIFIERS_BY_PID[pid] = &#039;unknown&#039;;


                                }

                               });
                         } // end else

                     });

                       } else { // end if int
                             console.log(&#039;ERROR pid is not an integer: &#039;+pid.toString());
                   }
                 } // end for pid in pid_list
              }
           } else {
               // ERROR
               console.log(output);
              console.log(&#039;ERROR last line: &#039;+code);
               // NO REDIRECT here
               //req.flash(&#039;message&#039;,  &#039;Script Error&#039;+last_line);
              //res.redirect(&quot;/user_data/your_projects&quot;);
           }
        });  // end tax_by_seq_process ON Close

      // }); //   END chmod
      // }); //       END move 2
      // });  //     END move 1

  }
  LoadDataFinishRequest();


});

//
//  FILE UTILS
//
router.get(&#039;/file_utils&#039;,  helpers.isLoggedIn,  function (req,  res) {

  console.log(&#039;in file_utils&#039;);
  //console.log(req.query.filename);
  var user = req.query.user;

  console.log(file);
  //// DOWNLOAD //////
  if (req.query.fxn == &#039;download&#039; &amp;&amp; req.query.template == &#039;1&#039;) {
      var file = path.join(process.env.PWD, req.query.filename);
      res.setHeader(&#039;Content-Type&#039;,  &#039;text&#039;);
      res.download(file); // Set disposition and send it.
  } else if (req.query.fxn == &#039;download&#039; &amp;&amp;  req.query.type==&#039;pcoa&#039;) {
      var file = path.join(process.env.PWD, &#039;tmp&#039;, req.query.filename);
      res.setHeader(&#039;Content-Type&#039;,  &#039;text&#039;);
      res.download(file); // Set disposition and send it.
  } else if (req.query.fxn == &#039;download&#039;) {
        var file = path.join(req.CONFIG.USER_FILES_BASE, user, req.query.filename);

      res.setHeader(&#039;Content-Type&#039;,  &#039;text&#039;);
      res.download(file); // Set disposition and send it.
  ///// DELETE /////
  } else if (req.query.fxn == &#039;delete&#039;) {
      var file = path.join(req.CONFIG.USER_FILES_BASE, user, req.query.filename);

    if (req.query.type == &#039;elements&#039;) {
      fs.unlink(file,  function (err) {
        if (err) {
          console.log(err);
        } else {
          req.flash(&#039;message&#039;,  &#039;Deleted: &#039;+req.query.filename);
          res.redirect(&quot;/visuals/saved_elements&quot;);
        }
      }); //
    } else {
      fs.unlink(file,  function (err) {
        if (err) {
          console.log(err);
        } else {
          req.flash(&#039;message&#039;,  &#039;Deleted: &#039;+req.query.filename);
          res.redirect(&quot;/user_data/file_retrieval&quot;);
        }
      });
    }

  }

});

//
// DOWNLOAD SEQUENCES
//
router.post(&#039;/download_selected_seqs&#039;,  helpers.isLoggedIn,  function (req,  res) {
  var db = req.db;
  console.log(&#039;seqs req.body--&gt;&gt;&#039;);
  console.log(req.body);
  console.log(&#039;&lt;&lt;--req.body&#039;);
  console.log(&#039;in DOWNLOAD SELECTED SEQS&#039;);
  var referer = req.body.referer;
  var qSelect = &quot;SELECT UNCOMPRESS(sequence_comp) as seq,  sequence_id,  seq_count,  project,  dataset from sequence_pdr_info\n&quot;;
  //var qSelect = &quot;select sequence_comp as seq,  sequence_id,  seq_count,  dataset from sequence_pdr_info\n&quot;;
  qSelect += &quot; JOIN sequence using (sequence_id)\n&quot;;
  qSelect += &quot; JOIN dataset using (dataset_id)\n&quot;;
  qSelect += &quot; JOIN project using (project_id)\n&quot;;
  var seq,  seqid,  seq_count,  pjds;
  var timestamp = +new Date();  // millisecs since the epoch!
  var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
  // if (req.CONFIG.hostname.substring(0, 7) == &#039;bpcweb7&#039;) {
  //       var user_dir = path.join(&#039;/groups/vampsweb/vampsdev_user_data/&#039;, req.user.username);
  // } else if (req.CONFIG.hostname.substring(0, 7) == &#039;bpcweb8&#039;) {
  //       var user_dir = path.join(&#039;/groups/vampsweb/vamps_user_data/&#039;, req.user.username);
  // } else {
  //       var user_dir = path.join(process.env.PWD, &#039;user_data&#039;, NODE_DATABASE, req.user.username);
  // }
  helpers.mkdirSync(req.CONFIG.USER_FILES_BASE);
  helpers.mkdirSync(user_dir);  // create dir if not exists
  var file_name;
  var out_file_path;

  if (req.body.download_type == &#039;whole_project&#039;) {

    var pid = req.body.pid;
    var project = req.body.project;
    file_name = &#039;fasta-&#039;+timestamp+&#039;_&#039;+project+&#039;.fa.gz&#039;;
    out_file_path = path.join(user_dir, file_name);
    qSelect += &quot; where project_id = &#039;&quot;+pid+&quot;&#039;&quot;;

  } else if (req.body.download_type == &#039;partial_project&#039;) {

    //var pids = JSON.parse(req.body.datasets).ids;
    var dids = chosen_id_name_hash.ids;
    file_name = &#039;fasta-&#039;+timestamp+&#039;_custom.fa.gz&#039;;
    out_file_path = path.join(user_dir, file_name);
    qSelect += &quot; where dataset_id in (&quot;+dids+&quot;)&quot;;
    console.log(dids);

  } else if (req.body.download_type == &#039;custom_taxonomy&#039;) {

      req.flash(&#039;tax_message&#039;,  &#039;Fasta being created&#039;);
      file_name = &#039;fasta-&#039;+timestamp+&#039;_custom_taxonomy.fa.gz&#039;;
      out_file_path = path.join(user_dir, file_name);
      var tax_string = req.body.tax_string;
      tax_items = tax_string.split(&#039;;&#039;);
      qSelect += &quot; JOIN silva_taxonomy_info_per_seq using (sequence_id)\n&quot;;
      qSelect += &quot; JOIN silva_taxonomy using (silva_taxonomy_id)\n&quot;;
      add_where = &#039; WHERE &#039;;
      for (var n in tax_items) {
        rank = req.CONSTS.RANKS[n];
        qSelect += &#039; JOIN `&#039;+rank+ &#039;` using (&#039;+rank+&#039;_id)\n&#039;;
        add_where += &#039;`&#039;+rank+&quot;`=&#039;&quot;+tax_items[n]+&quot;&#039; and &quot;;
      }
      qSelect = qSelect + add_where.substring(0,  add_where.length - 5);

  }
  //qSelect += &quot; limit 100 &quot;;                     // &lt;&lt;&lt;&lt;-----  for testing

  var gzip = zlib.createGzip();
  console.log(qSelect);

  var wstream = fs.createWriteStream(out_file_path);
  var rs = new Readable();
  var collection = db.query(qSelect,  function (err,  rows,  fields) {
    if (err) {
        throw err;
    } else {
      for (var i in rows) {
        seq = rows[i].seq.toString();
        //var buffer = new Buffer(rows[i].seq,  &#039;base64&#039;);
        //console.log(seq);
        seq_id = rows[i].sequence_id.toString();
        seq_count = rows[i].seq_count.toString();
        //project = rows[i].project;
        pjds = rows[i].project+&#039;--&#039;+rows[i].dataset;
        entry = &#039;&gt;&#039;+seq_id+&#039;|&#039;+pjds+&#039;|&#039;+seq_count+&quot;\n&quot;+seq+&quot;\n&quot;;
        //console.log(entry);
        rs.push(entry);
      }

      rs.push(null);
    }
    rs
      .pipe(gzip)
      .pipe(wstream)
      .on(&#039;finish&#039;,  function () {  // finished
        console.log(&#039;done compressing and writing file&#039;);
        console.log(JSON.stringify(req.user));
        var info = {
              to : req.user.email,
              from : &quot;vamps@mbl.edu&quot;,
              subject : &quot;fasta file is ready&quot;,
              text : &quot;Your fasta file is ready here:https://vamps.mbl.edu:8124\n\nAfter you log in go to the &#039;Your Data/File Retrieval&#039; Page.&quot;
            };
        helpers.send_mail(info);


      });

  });

  res.send(file_name);


});

//
// DOWNLOAD METADATA
//
router.post(&#039;/download_selected_metadata&#039;,  helpers.isLoggedIn,  function (req,  res) {
  var db = req.db;
  console.log(&#039;meta req.body--&gt;&gt;&#039;);
  console.log(req.body);
  var timestamp = +new Date();  // millisecs since the epoch!

  var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
  helpers.mkdirSync(req.CONFIG.USER_FILES_BASE);
  helpers.mkdirSync(user_dir);  // create dir if not exists
  var dids;
  var header,  project;
  var file_name;
  var out_file_path;

  if (req.body.download_type == &#039;whole_project&#039;) {
    var pid  = req.body.pid;
    dids = DATASET_IDS_BY_PID[pid];
    project = req.body.project;
    file_name = &#039;metadata-&#039;+timestamp+&#039;_&#039;+project+&#039;.csv.gz&#039;;
    out_file_path = path.join(user_dir, file_name);
    header = &#039;Project: &#039;+project+&quot;\n\t&quot;;
  } else {   // partial projects
    dids = chosen_id_name_hash.ids;
    file_name = &#039;metadata-&#039;+timestamp+&#039;.csv.gz&#039;;
    out_file_path = path.join(user_dir,  file_name);
    header = &#039;Project: various&#039;+&quot;\n\t&quot;;
  }
    console.log(&#039;dids&#039;);
    console.log(dids);


    var gzip = zlib.createGzip();
    var myrows = {}; // myrows[mdname] == [] list of values

    var wstream = fs.createWriteStream(out_file_path);
    var rs = new Readable();
    var filetxt;

      for (var i in dids) {
        did = dids[i];
        dname = DATASET_NAME_BY_DID[did];
        if (req.body.download_type == &#039;whole_project&#039;) {
          header += dname+&quot;\t&quot;;

        } else {
          pname = PROJECT_INFORMATION_BY_PID[PROJECT_ID_BY_DID[did]].project;
          header += pname+&#039;--&#039;+dname+&quot;\t&quot;;
        }

        if(HDF5_MDATA == &#039;&#039;){
            for (var k in AllMetadata[did]){
              nm = k;
              val = AllMetadata[did][k];
              if(nm in myrows){
                myrows[nm].push(val);
              }else{
                myrows[nm] = [];
                myrows[nm].push(val);
              }
            }
        }else{
            var mdgroup = HDF5_MDATA.openGroup(did+&quot;/metadata&quot;);
            mdgroup.refresh();
            Object.getOwnPropertyNames(mdgroup).forEach(function(mdname, idx, array) {
                if(mdname != &#039;id&#039;){
                    val = mdgroup[mdname];
                    if(mdname in myrows){
                        myrows[mdname].push(val);
                      }else{
                        myrows[mdname] = [];
                        myrows[mdname].push(val);
                      }
                }
            });
        }



      }

    // print
    header += &quot;\n&quot;;
    rs.push(header);
    if (Object.keys(myrows).length === 0) {
      rs.push(&quot;NO METADATA FOUND\n&quot;);
    } else {
      for (var mdname in myrows) {
        filetxt = mdname+&quot;\t&quot;;  // restart sting
        for (i in myrows[mdname]) {
          filetxt += myrows[mdname][i]+&quot;\t&quot;;
        }
        filetxt += &quot;\n&quot;;
        rs.push(filetxt);
      }
    }
    rs.push(null);
    rs
      .pipe(gzip)
      .pipe(wstream)
      .on(&#039;finish&#039;,  function () {  // finished
        console.log(&#039;done compressing and writing file&#039;);
        //console.log(JSON.stringify(req.user))
        var info = {
              to : req.user.email,
              from : &quot;vamps@mbl.edu&quot;,
              subject : &quot;metadata is ready&quot;,
              text : &quot;Your metadata file is ready here:\n\nhttps://vamps.mbl.edu:8124\n\nAfter you log in go to the &#039;Your Data/File Retrieval&#039; Page.&quot;
        };
        helpers.send_mail(info);
        //req.flash(&#039;Done&#039;)



      });

    res.send(file_name);
});

//
// DOWNLOAD MATRIX
//
router.post(&#039;/download_selected_matrix&#039;,  helpers.isLoggedIn,  function (req,  res) {
    var db = req.db;
    console.log(&#039;matrix req.body--&gt;&gt;&#039;);
    console.log(req.body);
    //var timestamp = +new Date();  // millisecs since the epoch!

     var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    //var user_dir = path.join(&#039;user_data&#039;, NODE_DATABASE, req.user.username);
    helpers.mkdirSync(req.CONFIG.USER_FILES_BASE);
    helpers.mkdirSync(user_dir);  // create dir if not exists

    //console.log(biom_matrix)
    dids = chosen_id_name_hash.ids;
    var timestamp = +new Date();
    var file_name = &#039;matrix-&#039;+timestamp+&#039;.csv&#039;;
    //out_file_path = path.join(user_dir,  file_name);


    var out_file = path.join(user_dir, file_name);
    var wstream = fs.createWriteStream(out_file);
    var gzip = zlib.createGzip();
    var rs = new Readable();

    header_txt = &quot;Taxonomy (&quot;+visual_post_items.tax_depth+&quot; level)&quot;;
    for (var y in biom_matrix.columns) {
      header_txt += &#039;, &#039;+biom_matrix.columns[y].id;
    }
    header_txt += &#039;\n\r&#039;;
    rs.push(header_txt);
    for (var i in biom_matrix.rows) {
      row_txt = &#039;&#039;;
      row_txt += biom_matrix.rows[i].id;
      for (var k in biom_matrix.data[i]) {
        row_txt += &#039;, &#039;+biom_matrix.data[i][k];
      }
      row_txt += &#039;\n\r&#039;;
      rs.push(row_txt);
    }
    rs.push(&#039;\n\r&#039;);
    rs.push(null);
    rs
    //.pipe(gzip)
    .pipe(wstream)
    .on(&#039;finish&#039;,  function () {  // finished
      console.log(&#039;done compressing and writing file&#039;);
    });


    console.log(&#039;dids&#039;);
    console.log(dids);
    res.send(file_name);

});
//
//
//
router.post(&#039;/download_file&#039;,  helpers.isLoggedIn,  function (req,  res) {
    console.log(&#039;in download_file&#039;);
    // file_type - fasta,  metadata,  or matrix
    console.log(req.body);
    var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    var timestamp = +new Date();  // millisecs since the epoch!
    var file_tag = [&#039;-&#039;+req.body.file_type+&#039;_file&#039;];

    create_export_files(req,  user_dir,  timestamp,  chosen_id_name_hash.ids,  file_tag,  visual_post_items.normalization, visual_post_items.tax_depth, visual_post_items.domains);
    res.send(req.body.file_type);
});
//
// DOWNLOAD PHYLOSEQ FILES
//
router.post(&#039;/download_phyloseq_file&#039;,  helpers.isLoggedIn,  function (req,  res) {
    console.log(&#039;phyloseq req.body--&gt;&gt;&#039;);

    console.log(req.body);
    old_ts = req.body.ts;
    file_type = req.body.file_type;
    var timestamp = +new Date();
    if (file_type == &#039;phyloseq-biom&#039;) {
      old_file_name = old_ts+&#039;_count_matrix.biom&#039;;
      file_path = path.join(process.env.PWD,  &#039;tmp&#039;,  old_file_name);
    } else if (file_type == &#039;phyloseq-tax&#039;) {
      old_file_name = old_ts+&#039;_taxonomy.txt&#039;;
      file_path = path.join(process.env.PWD,  &#039;tmp&#039;,  old_file_name);
    } else if (file_type == &#039;phyloseq-meta&#039;) {
      old_file_name = old_ts+&#039;_metadata.txt&#039;;
      file_path = path.join(process.env.PWD,  &#039;tmp&#039;,  old_file_name);
    }
    var user_dir = path.join(req.CONFIG.USER_FILES_BASE, req.user.username);
    helpers.mkdirSync(req.CONFIG.USER_FILES_BASE);
  helpers.mkdirSync(user_dir);  // create dir if not exists
    var new_file_name = file_type+&#039;_&#039;+timestamp+&#039;.txt&#039;;
    var destination = path.join( user_dir,  new_file_name );
    fs.copy(file_path,  destination,  function (err) {
        if (err) return console.error(err);
        console.log(&quot;copy success!&quot;);
    });

    res.send(new_file_name);
});

//
// &lt;&lt;&lt;&lt; FUNCTIONS &gt;&gt;&gt;&gt;
//
function update_config(res, req,  config_file,  config_info,  has_new_pname,  msg) {
  console.log(config_info);
  var new_config_txt = &quot;[GENERAL]\n&quot;;
  new_config_txt += &quot;project=&quot;+config_info.project+&quot;\n&quot;;
  new_config_txt += &quot;baseoutputdir=&quot;+config_info.baseoutputdir+&quot;\n&quot;;
  new_config_txt += &quot;configPath=&quot;+config_info.configPath+&quot;\n&quot;;
  new_config_txt += &quot;fasta_file=&quot;+config_info.fasta_file+&quot;\n&quot;;


  new_config_txt += &quot;project_title=&quot;+helpers.mysql_real_escape_string(config_info.project_title)+&quot;\n&quot;;
  new_config_txt += &quot;project_description=&quot;+helpers.mysql_real_escape_string(config_info.project_description)+&quot;\n&quot;;


  new_config_txt += &quot;platform=&quot;+config_info.platform+&quot;\n&quot;;
  new_config_txt += &quot;owner=&quot;+config_info.owner+&quot;\n&quot;;
  new_config_txt += &quot;config_file_type=&quot;+config_info.config_file_type+&quot;\n&quot;;
  new_config_txt += &quot;public=&quot;+config_info.public+&quot;\n&quot;;
  new_config_txt += &quot;fasta_type=&quot;+config_info.fasta_type+&quot;\n&quot;;
  new_config_txt += &quot;dna_region=&quot;+config_info.dna_region+&quot;\n&quot;;
  new_config_txt += &quot;project_sequence_count=&quot;+config_info.project_sequence_count+&quot;\n&quot;;
  new_config_txt += &quot;domain=&quot;+config_info.domain+&quot;\n&quot;;
  new_config_txt += &quot;number_of_datasets=&quot;+config_info.number_of_datasets+&quot;\n&quot;;
  new_config_txt += &quot;sequence_counts=&quot;+config_info.sequence_counts+&quot;\n&quot;;
  new_config_txt += &quot;env_source_id=&quot;+config_info.env_source_id+&quot;\n&quot;;
  new_config_txt += &quot;has_tax=&quot;+config_info.has_tax+&quot;\n\n&quot;;
  new_config_txt += &quot;[DATASETS]\n&quot;;

  for (var n in config_info.datasets) {
      new_config_txt += config_info.datasets[n].dsname+&quot;=&quot;+config_info.datasets[n].count+&quot;\n&quot;;
  }

  console.log(new_config_txt);

  fs.writeFile(config_file,  new_config_txt,  function (err) {
        if (err) {
          console.log(err);
          res.send(err);
        } else {
          console.log(&#039;write new config file success&#039;);
            if (has_new_pname) {
            // now change the directory name if the project_name is being updated
              old_base_dir = config_info.old_base_name;
              new_base_name = config_info.baseoutputdir;
              fs.move(old_base_dir,  new_base_dir,  function (err) {
                if (err) {
                  console.log(err);
                  res.send(err);
                } else {

                  update_dataset_names(config_info);
                  req.flash(&#039;successMessage&#039;,  msg);
                  res.redirect(&#039;/user_data/your_projects&#039;);

                }

              });
          } else {

            update_dataset_names(config_info);
            req.flash(&#039;successMessage&#039;,  msg);
            res.redirect(&#039;/user_data/your_projects&#039;);

          }

        }
    });


}
function update_dataset_names(config_info) {

    for (var n in config_info.datasets) {

          old_name_path = path.join(config_info.baseoutputdir, &#039;analysis&#039;, config_info.datasets[n].oldname);
          new_name_path = path.join(config_info.baseoutputdir, &#039;analysis&#039;, config_info.datasets[n].dsname);
          console.log(old_name_path);
          console.log(new_name_path);
          // TODO: Don&#039;t make functions within a loop.
          fs.move(old_name_path,  new_name_path,  function (err) {
            if (err) {
              console.log(&#039;WARNING failed to move dataset name &#039;+err.toString());
            } else {
              console.log(&#039;moving &#039;+config_info.datasets[n].oldname+&#039; to &#039;+config_info.datasets[n].dsname);
            }
          });


    }
}

/////////////////// EXPORTS ///////////////////////////////////////////////////////////////////////
function create_export_files(req,  user_dir,  ts,  dids,  file_tags,  normalization, rank, domains) {
      var db = req.db;
    //file_name = &#039;fasta-&#039;+ts+&#039;_custom.fa.gz&#039;;
    var log = path.join(req.CONFIG.SYSTEM_FILES_BASE, &#039;export_log.txt&#039;);
    //var log = path.join(user_dir, &#039;export_log.txt&#039;);
    if (normalization == &#039;max&#039; || normalization == &#039;maximum&#039; || normalization == &#039;normalized_to_maximum&#039;) {
        norm = &#039;normalized_to_maximum&#039;;
    } else if (normalization == &#039;percent&#039;) {
        norm = &#039;normailzed_by_percent&#039;;
    } else {
        norm = &#039;not_normalized&#039;;
    }

    var site = req.CONFIG.site;
    var code = &#039;NVexport&#039;;
    var pid_lookup = {};
    console.log(&#039;dids&#039;, dids);
    export_cmd = &#039;vamps_export_data.py&#039;;
    for (n=0;n&lt;dids.length;n++) {
        console.log(&#039;did&#039;, dids[n]);
        pid_lookup[PROJECT_ID_BY_DID[dids[n]]] = 1;
    }

    var dids_str = JSON.stringify(dids.join(&#039;, &#039;));
    var pids_str = JSON.stringify((Object.keys(pid_lookup)).join(&#039;, &#039;));
    var domain_str = JSON.stringify(domains.join(&#039;, &#039;));
    console.log(&#039;pids&#039;, pids_str);
    //var file_tags = file_tags.join(&#039; &#039;)
    var export_cmd_options = {

                         scriptPath : path.join(req.CONFIG.PATH_TO_NODE_SCRIPTS),
                         args :       [&#039;-s&#039;, site,
                                         &#039;-u&#039;, req.user.username,
                                         &#039;-r&#039;, ts,
                                         &#039;-base&#039;, user_dir,
                                         &#039;-dids&#039;,  dids_str,
                                         &#039;-pids&#039;, pids_str,
                                         &#039;-compress&#039;,
                                         &#039;-norm&#039;,  norm,
                                         &#039;-rank&#039;, rank,
                                         &#039;-domains&#039;, domain_str,
                                         &#039;-db&#039;, NODE_DATABASE
                                         ] // &#039;-compress&#039;

                     };
    for (var t in file_tags) {
        export_cmd_options.args.push(file_tags[t]);
    }
    var cmd_list = [];
    cmd_list.push(path.join(export_cmd_options.scriptPath,  export_cmd)+&#039; &#039;+export_cmd_options.args.join(&#039; &#039;));

    if (req.CONFIG.cluster_available === true) {
            qsub_script_text = get_qsub_script_text(log,  req.CONFIG.TMP,  site,  code,  cmd_list);
            qsub_file_name = req.user.username+&#039;_qsub_export_&#039;+ts+&#039;.sh&#039;;
            qsub_file_path = path.join(req.CONFIG.SYSTEM_FILES_BASE,  &#039;tmp&#039;,  qsub_file_name);

            fs.writeFile(qsub_file_path,  qsub_script_text,  function (err) {
                if (err) {
                    return console.log(err);
                } else {
                    console.log(&quot;The file was saved!&quot;);

                    console.log(qsub_script_text);
                    fs.chmod(qsub_file_path,  &#039;0775&#039;,  function (err) {
                        if (err) {
                            return console.log(err);
                        } else {
                            var dwnld_process = spawn( qsub_file_path,  {},  {
                              env:{ &#039;PATH&#039;:req.CONFIG.PATH, &#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH },
                              detached: true,
                              stdio:[&#039;pipe&#039;,  &#039;pipe&#039;,  &#039;pipe&#039;]
                                //stdio: [ &#039;ignore&#039;,  null,  log ]
                            });  // stdin,  stdout,  stderr1


                        }
                    });
                 }
            });


    } else {
        console.log(&#039;No Cluster Available according to req.CONFIG.cluster_available&#039;);
        var cmd = path.join(export_cmd_options.scriptPath,  export_cmd)+&#039; &#039;+export_cmd_options.args.join(&#039; &#039;);
        console.log(&#039;RUNNING:&#039;, cmd);
        //var log = path.join(req.CONFIG.SYSTEM_FILES_BASE, &#039;tmp_log.log&#039;)
        var dwnld_process = spawn( path.join(export_cmd_options.scriptPath,  export_cmd),  export_cmd_options.args,  {
                              env:{ &#039;PATH&#039;:req.CONFIG.PATH, &#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH },
                              detached: true,
                              stdio: [&#039;pipe&#039;,  &#039;pipe&#039;,  &#039;pipe&#039;]  // stdin,  stdout,  stderr
        });
        stdout = &#039;&#039;;
        dwnld_process.stdout.on(&#039;data&#039;,  function (data) {
            stdout += data;
        });
        stderr = &#039;&#039;;
        dwnld_process.stderr.on(&#039;data&#039;,  function (data) {
            stderr += data;
        });
        dwnld_process.on(&#039;close&#039;,  function (code) {
            console.log(&#039;dwnld_process process exited with code &#039; + code);
            //console.log(&#039;stdout&#039;, stdout);
            //console.log(&#039;stderr&#039;, stderr);
            if (code === 0) {   // SUCCESS

            } else {
              console.log(&#039;ERROR&#039;, stderr);
              //res.send(&#039;Frequency Heatmap R Script Error:&#039;+stderr);
            }
        });
    }

    return;

}
// function create_metadata_file(req,  user_dir,  ts,  dids) {
//
//     var file_name,  out_file_path;
//     file_name = &#039;metadata-&#039;+ts+&#039;_custom.gz&#039;;
//     out_file_path = path.join(user_dir, file_name);
//     pids = []
//
//         if (req.CONFIG.cluster_available == true) {
//             qsub_script_text = get_qsub_script_text(log,  site,  code,  cmd_list)
//
//         } else {
//
//         }
//     return file_name;
// }
// function create_taxbytax_file(req,  user_dir,  ts,  dids) {
//
//     var file_name,  out_file_path;
//     file_name = &#039;taxbytax-&#039;+ts+&#039;_custom.gz&#039;;
//     out_file_path = path.join(user_dir, file_name);
//         if (req.CONFIG.cluster_available == true) {
//             qsub_script_text = get_qsub_script_text(log,  site,  code,  cmd_list)
//
//         } else {
//
//         }
//     return file_name;
// }
// function create_taxbyref_file(req,  user_dir,  ts,  dids) {
//
//     var file_name,  out_file_path;
//     file_name = &#039;taxbyref-&#039;+ts+&#039;_custom.gz&#039;;
//     out_file_path = path.join(user_dir, file_name);
//         if (req.CONFIG.cluster_available == true) {
//             qsub_script_text = get_qsub_script_text(log,  site,  code,  cmd_list)
//
//         } else {
//
//         }
//     return file_name;
// }
// function create_taxbyseq_file(req,  user_dir,  ts,  dids) {
//
//     var file_name,  out_file_path;
//     file_name = &#039;taxbyseq-&#039;+ts+&#039;_custom.gz&#039;;
//     out_file_path = path.join(user_dir, file_name);
//         if (req.CONFIG.cluster_available == true) {
//             qsub_script_text = get_qsub_script_text(log,  site,  code,  cmd_list)
//
//         } else {
//
//         }
//     return file_name;
// }
function create_fasta_file(req,  user_dir,  ts,  dids) {
    var db = req.db;
    file_name = &#039;fasta-&#039;+ts+&#039;_custom.fa.gz&#039;;
    var log = path.join(req.CONFIG.SYSTEM_FILES_BASE, &#039;export_log.txt&#039;);
    //var log = path.join(user_dir, &#039;export_log.txt&#039;);

    var site = req.CONFIG.site;
    var code = &#039;NVtest&#039;;
    export_cmd = &#039;vamps_export_data.py&#039;;

    dids = JSON.stringify(dids);

    var export_cmd_options = {
                         scriptPath : path.join(req.CONFIG.SYSTEM_FILES_BASE, &#039;scripts&#039;),
                         args :       [&#039;-s&#039;, site, &#039;-u&#039;, req.user.username, &#039;-r&#039;, ts, &#039;-base&#039;, user_dir, &#039;-dids&#039;, dids, &#039;--fasta_file&#039;, &#039;-compress&#039; ] // &#039;-compress&#039;
                     };
    var cmd_list = [];
    cmd_list.push(path.join(export_cmd_options.scriptPath,  export_cmd)+&#039; &#039;+export_cmd_options.args.join(&#039; &#039;));

    if (req.CONFIG.cluster_available === true) {
            qsub_script_text = get_qsub_script_text(log,  req.CONFIG.TMP,  site,  code,  cmd_list);
            qsub_file_name = req.user.username+&#039;_qsub_export_&#039;+ts+&#039;.sh&#039;;
            qsub_file_path = path.join(req.CONFIG.SYSTEM_FILES_BASE,  &#039;tmp&#039;,  qsub_file_name);

            fs.writeFile(qsub_file_path,  qsub_script_text,  function (err) {
                if (err) {
                    return console.log(err);
                } else {
                    console.log(&quot;The file was saved!&quot;);

                    console.log(qsub_script_text);
                    fs.chmod(qsub_file_path,  &#039;0775&#039;,  function (err) {
                        if (err) {
                            return console.log(err);
                        } else {
                            var pcoa_process = spawn( qsub_file_path,  {},  {
                              env:{ &#039;PATH&#039;:req.CONFIG.PATH, &#039;LD_LIBRARY_PATH&#039;:req.CONFIG.LD_LIBRARY_PATH },
                              detached: true,
                              stdio:[&#039;pipe&#039;,  &#039;pipe&#039;,  &#039;pipe&#039;]
                                //stdio: [ &#039;ignore&#039;,  null,  log ]
                            });  // stdin,  stdout,  stderr1


                        }
                    });
                 }
            });

        } else {
            console.log(&#039;No Cluster Available&#039;);
        }
    return file_name;

    // TODO: Unreachable &#039;var&#039; after &#039;return&#039;.
    var qSelect = &quot;SELECT UNCOMPRESS(sequence_comp) as seq,  sequence_id,  seq_count,  project,  dataset from sequence_pdr_info\n&quot;;
    //var qSelect = &quot;select sequence_comp as seq,  sequence_id,  seq_count,  dataset from sequence_pdr_info\n&quot;;
    qSelect += &quot; JOIN sequence using (sequence_id)\n&quot;;
    qSelect += &quot; JOIN dataset using (dataset_id)\n&quot;;
    qSelect += &quot; JOIN project using (project_id)\n&quot;;
    var seq,  seqid,  seq_count,  pjds;
    var file_name,  out_file_path;

    //var pids = JSON.parse(req.body.datasets).ids;

    out_file_path = path.join(user_dir, file_name);
    qSelect += &quot; where dataset_id in (&quot;+pids+&quot;)&quot;;

    var gzip = zlib.createGzip();
    console.log(qSelect);

    var wstream = fs.createWriteStream(out_file_path);
    var rs = new Readable();
    var collection = db.query(qSelect,  function (err,  rows,  fields) {
      if (err) {
          throw err;
      } else {
        for (var i in rows) {
          seq = rows[i].seq.toString();
          //var buffer = new Buffer(rows[i].seq,  &#039;base64&#039;);
          //console.log(seq);
          seq_id = rows[i].sequence_id.toString();
          seq_count = rows[i].seq_count.toString();
          //project = rows[i].project;
          pjds = rows[i].project+&#039;--&#039;+rows[i].dataset;
          entry = &#039;&gt;&#039;+seq_id+&#039;|&#039;+pjds+&#039;|&#039;+seq_count+&quot;\n&quot;+seq+&quot;\n&quot;;
          //console.log(entry);
          rs.push(entry);
        }

        rs.push(null);
      }
      rs
        .pipe(gzip)
        .pipe(wstream)
        .on(&#039;finish&#039;,  function () {  // finished
          console.log(&#039;done compressing and writing file&#039;);
          console.log(JSON.stringify(req.user));
          var info = {
                to : req.user.email,
                from : &quot;vamps@mbl.edu&quot;,
                subject : &quot;fasta file is ready&quot;,
                text : &quot;Your fasta file is ready here:https://vamps.mbl.edu:8124\n\nAfter you log in go to the &#039;Your Data/File Retrieval&#039; Page.&quot;
              };
          helpers.send_mail(info);


        });

    });

    return file_name;

}
/////////////////////////////////////////////////////////////////////////////////////////////////
function get_local_script_text(log,  site,  code,  cmd_list) {
      //### Create Cluster Script
    script_text = &quot;#!/bin/sh\n\n&quot;;
    script_text += &quot;# CODE:\t$code\n\n&quot;;
    //script_text += &quot;# source environment:\n&quot;;
    //script_text += &quot;source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh\n\n&quot;;
    script_text += &#039;TSTAMP=`date &quot;+%Y%m%d%H%M%S&quot;`&#039;+&quot;\n\n&quot;;

    script_text += &#039;echo -n &quot;Hostname: &quot;&#039;+&quot;\n&quot;;
    script_text += &quot;hostname\n&quot;;
    script_text += &#039;echo -n &quot;Current working directory: &quot;&#039;+&quot;\n&quot;;
    script_text += &quot;pwd\n\n&quot;;
    for (var i in cmd_list) {
        script_text += cmd_list[i]+&quot;\n&quot;;
    }
    //script_text += &quot;chmod 666 &quot;+log+&quot;\n&quot;;

    //##### END  create command

    return script_text;
}
//
//
//
function get_qsub_script_text(log,  pwd,  site,  name,  cmd_list) {
    /*
    #!/bin/sh
    # CODE:
    # source environment:\n&quot;;
    source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh
    TSTAMP=`date &quot;+%Y%m%d%H%M%S&quot;`&#039;
    # . /usr/share/Modules/init/sh
    # export MODULEPATH=/usr/local/www/vamps/software/modulefiles
    # module load clusters/vamps
    cd &quot;+pwd+&quot;
    function status() {
       qstat -f
    }
    function submit_job() {
    cat&lt;&lt;END | qsub
    #!/bin/bash
    #$ -j y
    #$ -o &quot;+log+&quot;
    #$ -N &quot;+name+&quot;
    #$ -cwd
    #$ -V
    echo -n &quot;Hostname: &quot;
    hostname
    echo -n &quot;Current working directory: &quot;
    pwd
    source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh
    for (i in cmd_list) {
        cmd_list[i]
    }
    END
    }
    status
    submit_job
    */
    //### Create Cluster Script
    script_text = &quot;#!/bin/bash\n\n&quot;;
    script_text += &quot;# CODE:\t&quot;+name+&quot;\n\n&quot;;
    script_text += &quot;# source environment:\n&quot;;
    script_text += &quot;source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh\n\n&quot;;
    script_text += &#039;TSTAMP=`date &quot;+%Y%m%d%H%M%S&quot;`&#039;+&quot;\n\n&quot;;
    script_text += &quot;# Loading Module didn&#039;t work when testing:\n&quot;;
    //$script_text .= &quot;LOGNAME=test-output-$TSTAMP.log\n&quot;;
    script_text += &quot;. /usr/share/Modules/init/sh\n&quot;;
    script_text += &quot;export MODULEPATH=/usr/local/www/vamps/software/modulefiles\n&quot;;
    script_text += &quot;module load clusters/vamps\n\n&quot;;
     script_text += &quot;cd /groups/vampsweb/tmp\n\n&quot;;
    //script_text += &quot;cd /groups/vampsweb/vampsdev_node_data/\n\n&quot;;
    //script_text += &quot;cd &quot;+pwd+&quot;\n\n&quot;;
    //script_text += &quot;mkdir &quot;+pwd+&quot;/gast\n\n&quot;;
    //script_text += &quot;mkdir gast\n\n&quot;;
 //    script_text += &quot;function status() {\n&quot;;
//     script_text += &quot;   qstat -f\n&quot;;
//     script_text += &quot;}\n\n&quot;;
     script_text += &quot;function submit_job() {\n&quot;;
     script_text += &quot;cat&lt;&lt;END | qsub\n&quot;;
     script_text += &quot;#!/bin/bash\n&quot;;
     script_text += &quot;#$ -j y\n&quot;;
     script_text += &quot;#$ -o &quot;+log+&quot;\n&quot;;
     script_text += &quot;#$ -N &quot;+name+&quot;\n&quot;;
     script_text += &quot;#$ -cwd\n&quot;;
     script_text += &quot;#$ -V\n&quot;;
     script_text += &#039;echo -n &quot;Hostname: &quot;&#039;+&quot;\n&quot;;
     script_text += &quot;hostname\n&quot;;
     script_text += &#039;echo -n &quot;qsub: Current working directory: &quot;&#039;+&quot;\n&quot;;
     script_text += &quot;pwd\n\n&quot;;
//     script_text += &quot;source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh\n\n&quot;;
     for (var i in cmd_list) {
         script_text += cmd_list[i]+&quot;\n&quot;;
     }
//
//     //script_text += &quot;chmod 666 &quot;+log+&quot;\n&quot;;
//     //$script_text .= &quot;sleep 120\n&quot;;   # for testing
     script_text += &quot;END\n&quot;;
     script_text += &quot;}\n&quot;;
//     script_text += &quot;status\n&quot;;  //#  status will show up in export.out
     script_text += &quot;submit_job\n&quot;;
    //##### END  create command

    return script_text;

}


function get_qsub_script_text2(log,  pwd,  site,  name,  cmd_list) {

    //### Create Cluster Script
    script_text = &quot;#!/bin/sh\n\n&quot;;
    script_text += &quot;# CODE:\t&quot;+name+&quot;\n\n&quot;;
    script_text += &quot;# source environment:\n&quot;;
    script_text += &quot;source /groups/vampsweb/&quot;+site+&quot;/seqinfobin/vamps_environment.sh\n\n&quot;;
    script_text += &#039;TSTAMP=`date &quot;+%Y%m%d%H%M%S&quot;`&#039;+&quot;\n\n&quot;;
    script_text += &quot;# Loading Module didn&#039;t work when testing:\n&quot;;
    //$script_text .= &quot;LOGNAME=test-output-$TSTAMP.log\n&quot;;
    script_text += &quot;export MODULEPATH=/usr/local/www/vamps/software/modulefiles\n&quot;;
    script_text += &quot;. /xraid/bioware/Modules/etc/profile.modules\n&quot;;
    script_text += &quot;# . /usr/share/Modules/init/sh\n&quot;;
    script_text += &quot;# export MODULEPATH=/usr/local/www/vamps/software/modulefiles\n&quot;;
    script_text += &quot;module load clusters/vamps\n\n&quot;;
    script_text += &quot;cd &quot;+pwd+&quot;\n\n&quot;;


    for (var i in cmd_list) {
        script_text += cmd_list[i]+&quot;\n&quot;;
    }
    //script_text += &quot;chmod 666 &quot;+log+&quot;\n&quot;;
    //$script_text .= &quot;sleep 120\n&quot;;   # for testing

    script_text += &quot;\n&quot;;


    //##### END  create command

    return script_text;

}
//
//
//

module.exports = router;</textarea>
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p>.</p>
  </div>
</footer>

<script type="text/html" id="complexity-popover-template">
  <div class="complexity-notice">
    Complexity : {{ complexity.cyclomatic }} <br>
    Length : {{ complexity.halstead.length }} <br>
    Difficulty : {{ complexity.halstead.difficulty.toFixed(2) }} <br>
    Est # bugs : {{ complexity.halstead.bugs.toFixed(2) }}<br>
  </div>
</script>

<script type="text/javascript" src="../../assets/scripts/bundles/core-bundle.js"></script>
<script type="text/javascript" src="../../assets/scripts/bundles/codemirror.js"></script>
<script type="text/javascript" src="../../assets/scripts/codemirror.markpopovertext.js"></script>
<script type="text/javascript" src="report.js"></script>
<script type="text/javascript" src="report.history.js"></script>
<script type="text/javascript" src="../../assets/scripts/plato-file.js"></script>
</body>
</html>
