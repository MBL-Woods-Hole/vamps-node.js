<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Plato - routes/routes_user_data.js</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link href="../../assets/css/vendor/morris.css" rel="stylesheet">
  <link href="../../assets/css/vendor/bootstrap.css" rel="stylesheet">
  <link href="../../assets/css/vendor/font-awesome.css" rel="stylesheet">
  <link href="../../assets/css/vendor/codemirror.css" rel="stylesheet">
  <link href="../../assets/css/plato.css" rel="stylesheet">
  <link href="../../assets/css/plato-file.css" rel="stylesheet">

</head>

<body>

<div class="navbar navbar-fixed-top">
  <div class="container">
    <a class="navbar-brand" href="http://github.com/es-analysis/plato">Plato on Github</a>
    <ul class="nav navbar-nav">
      <li>
        <a href="../../index.html">Report Home</a>
      </li>
    </ul>
  </div>
</div>

<div class="jumbotron">
  <div class="container">
    <h1>routes/routes_user_data.js</h1>
  </div>
</div>

<div class="container aggregate-stats">
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Maintainability <a href="http://blogs.msdn.com/b/codeanalysis/archive/2007/11/20/maintainability-index-range-and-meaning.aspx"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="A value between 0 and 100 that represents the relative ease of maintaining the code. A high value means better maintainability." data-original-title="Maintainability Index"  data-container="body"></i></a></h2>
      <p class="stat">53.52</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Lines of code <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h2>
      <p class="stat">2032</p>
    </div>
  </div>
  <div class="row historical">
    <div class="col-md-6">
      <p id="chart_historical_maint" class="chart"></p>
    </div>
    <div class="col-md-6">
      <p id="chart_historical_sloc" class="chart"></p>
    </div>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Difficulty  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="The difficulty measure is related to the difficulty of the program to write or understand." data-original-title="Difficulty" data-container="body"></i></a></h2>
      <p class="stat">105.46</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Estimated Errors  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Halstead's delivered bugs is an estimate for the number of errors in the implementation." data-original-title="Delivered Bugs" data-container="body"></i></a></h2>
      <p class="stat">30.00</p>
    </div>
  </div>
</div>

<div class="container charts">
  <div class="row">
    <h2 class="header">Function weight</h2>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h3 class="chart-header">By Complexity <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="This metric counts the number of distinct paths through a block of code. Lower values are better." data-original-title="Cyclomatic Complexity" data-container="body"></i></a></h3>
      <div id="fn-by-complexity" class="stat"></div>
    </div>
    <div class="col-md-6">
      <h3 class="chart-header">By SLOC  <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h3>
      <div id="fn-by-sloc" class="stat"></div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <textarea id="file-source" class="col-md-12">var express = require(&#039;express&#039;);
var router = express.Router();
var passport = require(&#039;passport&#039;);
var helpers = require(&#039;./helpers/helpers&#039;);
var path  = require(&#039;path&#039;);
var fs   = require(&#039;fs-extra&#039;);
var url  = require(&#039;url&#039;);
var ini = require(&#039;ini&#039;);
var queries = require(&#039;./queries&#039;);
var iniparser = require(&#039;iniparser&#039;);
//var PythonShell = require(&#039;python-shell&#039;);
var zlib = require(&#039;zlib&#039;);
var multer = require(&#039;multer&#039;);
var upload = multer(multer({ dest: path.join(&#039;user_data&#039;, NODE_DATABASE, &#039;tmp&#039;)}));
var Readable = require(&#039;readable-stream&#039;).Readable;
var COMMON  = require(&#039;./visuals/routes_common&#039;);


//
// YOUR DATA
//
router.get(&#039;/your_data&#039;,  function(req,res){
  console.log(&#039;in your data&#039;);
    res.render(&#039;user_data/your_data&#039;, {
      title: &#039;VAMPS:Data Administration&#039;,
      user: req.user, hostname: req.C.hostname,
      message: req.flash(&#039;message&#039;),

    });
});

//
// FILE RETRIEVAL
//
/* GET Export Data page. */
router.get(&#039;/file_retrieval&#039;, helpers.isLoggedIn, function(req, res) {

    var export_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
    var mtime = {};
    var size = {};
    var file_info = {};
    file_info.mtime ={};
    file_info.size = {};
    file_info.files = [];
    fs.readdir(export_dir, function(err, files){
      for (var f in files){
        var pts = files[f].split(&#039;:&#039;);
        if(pts[0] === &#039;metadata&#039; || pts[0] === &#039;fasta&#039; || pts[0] === &#039;matrix&#039;){
          file_info.files.push(files[f]);
          stat = fs.statSync(export_dir+&#039;/&#039;+files[f]);
          file_info.mtime[files[f]] = stat.mtime;  // modify time
          file_info.size[files[f]] = stat.size;
        }
      }
      //console.log(file_info)
      res.render(&#039;user_data/file_retrieval&#039;, { title: &#039;VAMPS:Export Data&#039;,
              user: req.user, hostname: req.C.hostname,
              finfo: JSON.stringify(file_info),
							message : req.flash(&#039;message&#039;),
            });
    });
});

//
//  EXPORT CONFIRM
//
router.post(&#039;/export_confirm&#039;, helpers.isLoggedIn, function(req, res) {
		console.log(&#039;req.body: export_confirm--&gt;&gt;&#039;);
		console.log(req.body);
		console.log(&#039;req.body: &lt;&lt;--export_confirm&#039;);
		if(req.body.fasta === undefined
				&amp;&amp; req.body.taxbyseq === undefined
				&amp;&amp; req.body.taxbyref === undefined
				&amp;&amp; req.body.taxbytax === undefined
				&amp;&amp; req.body.metadata === undefined ){
				req.flash(&#039;failMessage&#039;, &#039;Select one or more file formats&#039;);
				res.render(&#039;user_data/export_selection&#039;, {
		      title: &#039;VAMPS: Export Choices&#039;,
		      referer: &#039;export_data&#039;,
		      chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
		      message: &#039;Select one or more file formats&#039;,
		      user: req.user, hostname: req.C.hostname
		    });
		    return;
		}
		var dids = req.body.dids;
		var requested_files = [];

		if(req.body.fasta){

		}
		for(fmt in req.body){
			if(fmt != &#039;dids&#039;){
				requested_files.push(fmt);
			}
		}
		console.log(requested_files);
		create_fasta_file(req,dids);

		res.render(&#039;user_data/export_selection&#039;, {
		      title: &#039;VAMPS: Export Choices&#039;,
		      referer: &#039;export_data&#039;,
		      chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
		      message: &quot;Your files are being created -- when ready they will be accessible &lt;a href=&#039;/user_data/file_retrieval&#039; &gt;here&lt;/a&gt;&quot;,
		      user: req.user, hostname: req.C.hostname
		});


});
//
//  EXPORT SELECTION
//
/* GET Import Choices page. */
router.post(&#039;/export_selection&#039;, helpers.isLoggedIn, function(req, res) {
  console.log(&#039;in routes_user_data.js /export_selection&#039;);
  console.log(&#039;req.body: export_selection--&gt;&gt;&#039;);
  console.log(req.body);
  console.log(&#039;req.body: &lt;&lt;--export_selection&#039;);
  if(req.body.retain_data === &#039;1&#039;){
    dataset_ids = JSON.parse(req.body.dataset_ids);
  }else{
    dataset_ids = req.body.dataset_ids;
  }
  console.log(&#039;dataset_ids &#039;+dataset_ids);
  if (dataset_ids === undefined || dataset_ids.length === 0){
      console.log(&#039;redirecting back -- no data selected&#039;);
   	 req.flash(&#039;nodataMessage&#039;, &#039;Select Some Datasets&#039;);
   	 res.redirect(&#039;export_data&#039;);
     return;
  }else{
   // GLOBAL Variable
	  chosen_id_name_hash           = COMMON.create_chosen_id_name_hash(dataset_ids);
    console.log(&#039;chosen_id_name_hash--&gt;&#039;);
	  console.log(chosen_id_name_hash);
	  console.log(chosen_id_name_hash.ids.length);
	  console.log(&#039;&lt;--chosen_id_name_hash&#039;);
    res.render(&#039;user_data/export_selection&#039;, {
          title: &#039;VAMPS: Export Choices&#039;,
          referer: &#039;export_data&#039;,
          chosen_id_name_hash: JSON.stringify(chosen_id_name_hash),
          message: req.flash(&#039;successMessage&#039;),
          failmessage: req.flash(&#039;failMessage&#039;),
          user: req.user, hostname: req.C.hostname
        });
  }
});
//
//  EXPORT DATA
//
router.get(&#039;/export_data&#039;, helpers.isLoggedIn, function(req, res) {
    res.render(&#039;user_data/export_data&#039;, { title: &#039;VAMPS:Import Data&#039;,
                rows     : JSON.stringify(ALL_DATASETS),
                proj_info: JSON.stringify(PROJECT_INFORMATION_BY_PID),
                constants: JSON.stringify(req.C),
								message  : req.flash(&#039;nodataMessage&#039;),
                user: req.user, hostname: req.C.hostname
          });
});
//
// IMPORT_CHOICES
//
/* GET Import Choices page. */
router.get(&#039;/import_choices&#039;, helpers.isLoggedIn, function(req, res) {
  console.log(&#039;import_choices&#039;);
   if(req.user.username == &#039;guest&#039;){
   		req.flash(&#039;message&#039;, &quot;The &#039;guest&#039; user is not permitted to import data&quot;);
   		res.redirect(&#039;/user_data/your_data&#039;);
   }else{
    	res.render(&#039;user_data/import_choices&#039;, {
          title: &#039;VAMPS:Import Choices&#039;,
          message: req.flash(&#039;successMessage&#039;),
          failmessage: req.flash(&#039;failMessage&#039;),
          user: req.user, hostname: req.C.hostname
          });
  }
});
//
// IMPORT DATA
//
/* GET Import Data page. */
router.get(&#039;/import_data&#039;, helpers.isLoggedIn, function(req, res) {
  console.log(&#039;import_data&#039;);
  console.log(JSON.stringify(req.url));
  var myurl = url.parse(req.url, true);
  var user_projects_base_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
  var my_projects = [];
  var import_type    = myurl.query.import_type;

		fs.readdir(user_projects_base_dir, function(err, items){
				if(err){

					fs.ensureDir(user_projects_base_dir, function (err) {
		  			console.log(err); // =&gt; null
		  			// dir has now been created, including the directory it is to be placed in
					});


				}else{
				  for (var d in items){
		        var pts = items[d].split(&#039;:&#039;);
		        if(pts[0] === &#039;project&#039;){

							var project_name = pts[1];
							my_projects.push(project_name);

						}
					}

					res.render(&#039;user_data/import_data&#039;, {
				    title: &#039;VAMPS:Import Data&#039;,
			  		message: req.flash(&#039;successMessage&#039;),
				    failmessage: req.flash(&#039;failMessage&#039;),
			      import_type: import_type,
			      my_projects:my_projects,
			      user: req.user, hostname: req.C.hostname
			    });

				} // end else
			});


});
//
// VALIDATE FORMAT
//
/* GET Validate page. */
router.get(&#039;/validate_format&#039;, helpers.isLoggedIn, function(req, res) {
  console.log(&#039;validate_format&#039;);
  console.log(JSON.stringify(req.url));
  var myurl = url.parse(req.url, true);
  console.log(myurl.query);
  var file_type    = myurl.query.file_type;
  res.render(&#039;user_data/validate_format&#039;, {
    title: &#039;VAMPS:Import Data&#039;,
		message: req.flash(&#039;successMessage&#039;),
      file_type: file_type,
      file_style:&#039;&#039;,
      result:&#039;&#039;,
      original_fname:&#039;&#039;,
      user: req.user, hostname: req.C.hostname
                        });
});
//
//  VALIDATE FILE
//
router.post(&#039;/validate_file&#039;, [helpers.isLoggedIn, upload.single(&#039;upload_file&#039;, 12)], function(req, res) {
  console.log(&#039;POST validate_file&#039;);
    //console.log(JSON.stringify(req.url))
    //var myurl = url.parse(req.url, true);
    console.log(req.body);
    console.log(req.file);
    var file_type    = req.body.file_type;
    var file_style   = req.body.file_style;
    console.log(&#039;file_type &#039;+ file_type);
    console.log(&#039;file_style &#039;+ file_style);
    var file_path = path.join(process.env.PWD,req.file.path);
    console.log(&#039;file_path &#039;+ file_path);

		var options = { scriptPath : req.C.PATH_TO_SCRIPTS,
		        			args : [ &#039;-i&#039;, file_path, &#039;-ft&#039;,file_type,&#039;-s&#039;, file_style,&#039;-pdir&#039;,process.env.PWD,]
		    			};

		console.log(options.scriptPath+&#039;/vamps_script_validate.py &#039;+options.args.join(&#039; &#039;));
		var spawn = require(&#039;child_process&#039;).spawn;
		var log = fs.openSync(path.join(process.env.PWD,&#039;node.log&#039;), &#039;a&#039;);
		var validate_process = spawn( options.scriptPath+&#039;/vamps_script_validate.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr
		var output = &#039;&#039;;
		validate_process.stdout.on(&#039;data&#039;, function (data) {
		  //console.log(&#039;stdout: &#039; + data);
		  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
		  output += data;


		});
		validate_process.on(&#039;close&#039;, function (code) {
				console.log(&#039;validate_process exited with code &#039; + code);
				console.log(output);

				var ary = output.substring(2,output.length-2).split(&quot;&#039;, &#039;&quot;);
				var result = ary.shift();
				console.log(ary);
				//var last_line = ary[ary.length - 1];
				if(code === 0){
					//console.log(&#039;OK &#039;+code)
					console.log(typeof ary);

					if(result == &#039;OK&#039;){
						req.flash(&#039;message&#039;, &#039;Validates&#039;);
					}else{
						req.flash(&#039;message&#039;, &#039;Failed Validation&#039;);
					}
					res.render(&#039;user_data/validate_format&#039;, {
					     title: &#039;VAMPS:Import Data&#039;,
				  		 message: req.flash(&#039;message&#039;),

				       file_type: file_type,
				       //result:    JSON.stringify(ary),
				       file_style: file_style,
				       result_ary:    ary,
				       original_fname: req.file.originalname,
				       result : result,
				       user: req.user, hostname: req.C.hostname
             });

				}else{
					console.log(&#039;ERROR &#039;+code);
					req.flash(&#039;message&#039;, &#039;Failed Validation&#039;);
					res.render(&#039;user_data/validate_format&#039;, {
					    title: &#039;VAMPS:Import Data&#039;,
				  		message: req.flash(&#039;message&#039;),
				      file_type: file_type,
				      user: req.user, hostname: req.C.hostname
                          });
				}

	  });


});
//
// USER PROJECT INFO:ID
//
router.get(&#039;/user_project_info/:id&#039;, helpers.isLoggedIn, function(req, res) {
    console.log(req.params.id);
	var project = req.params.id;
    var config_file = path.join(&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project,&#039;config.ini&#039;);
	var config = ini.parse(fs.readFileSync(config_file, &#039;utf-8&#039;));
	console.log(config);
	res.render(&#039;user_data/profile&#039;, {
			project : project,
			pinfo   : JSON.stringify(config),
			title   : project,
	    user: req.user, hostname: req.C.hostname
         });
});
//
//  DELETE PROJECT:PROJECT:KIND
//
router.get(&#039;/delete_project/:project/:kind&#039;, helpers.isLoggedIn,  function(req,res){

	var delete_kind = req.params.kind;
	var project = req.params.project;
	var timestamp = +new Date();  // millisecs since the epoch!
	console.log(&#039;in delete_project1: &#039;+project+&#039; - &#039;+delete_kind);
	//console.log(JSON.stringify(PROJECT_INFORMATION_BY_PNAME));

	if(project in PROJECT_INFORMATION_BY_PNAME){
		var pid = PROJECT_INFORMATION_BY_PNAME[project].pid;
	  helpers.update_global_variables(pid,&#039;del&#039;);
	}else{
		// project not in db?
		console.log(&#039;project was not found in db: PROJECT_INFORMATION_BY_PNAME&#039;);
    var pid = 0;

	}

    console.log(&#039;in delete_project2: &#039;+project+&#039; - &#039;+pid);
		var options = {
	      scriptPath : req.C.PATH_TO_SCRIPTS,
	      args :       [ &#039;-pid&#039;, pid, &#039;-db&#039;, NODE_DATABASE, &#039;--user&#039;,req.user.username,&#039;--project&#039;,project,&#039;-pdir&#039;,process.env.PWD ],
        };
		if(delete_kind == &#039;all&#039;){
			// must delete pid data from mysql ()
			// and all datasets files
			options.args = options.args.concat([&#039;--action&#039;, &#039;delete_whole_project&#039;]);
		}else if(delete_kind == &#039;tax&#039; &amp;&amp; pid != 0){
			options.args = options.args.concat([&#039;--action&#039;, &#039;delete_tax_only&#039; ]);

		}else if(delete_kind == &#039;meta&#039; &amp;&amp; pid != 0){
			options.args = options.args.concat([&#039;--action&#039;,  &#039;delete_metadata_only&#039; ]);

		}else{
			req.flash(&#039;message&#039;, &#039;ERROR nothing deleted&#039;);
	    res.redirect(&quot;/user_data/your_projects&quot;);
	    return;
		}
    console.log(options.args.join(&#039; &#039;));
			var spawn = require(&#039;child_process&#039;).spawn;
			var log = fs.openSync(path.join(process.env.PWD,&#039;logs&#039;,&#039;node.log&#039;), &#039;a&#039;);
			// script will remove data from mysql and datset taxfile


			console.log(options.scriptPath+&#039;/vamps_script_utils.py &#039;+options.args.join(&#039; &#039;));
      var delete_process = spawn( options.scriptPath+&#039;/vamps_script_utils.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr


			var output = &#039;&#039;;
			delete_process.stdout.on(&#039;data&#039;, function (data) {
			  //console.log(&#039;stdout: &#039; + data);
			  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
			  output += data;
			  var lines = data.split(&#039;\n&#039;);
			  for(var n in lines){
			  	//console.log(&#039;line: &#039; + lines[n]);
				if(lines[n].substring(0,4) == &#039;PID=&#039;){
					console.log(&#039;pid line &#039;+lines[n]);
				}
			  }
			});

			delete_process.on(&#039;close&#039;, function (code) {
			    console.log(&#039;delete_process process exited with code &#039; + code);
			    var ary = output.split(&quot;\n&quot;);
			    var last_line = ary[ary.length - 1];
			    if(code == 0){
				   //console.log(&#039;PID last line: &#039;+last_line)
              status_params = {&#039;type&#039;:&#039;delete&#039;, &#039;user&#039;:req.user.username,
                                &#039;project&#039;:project, &#039;status&#039;:&#039;delete&#039;,	&#039;msg&#039;:&#039;delete&#039; };
              helpers.update_status(status_params );                            
			    }else{
			   	  // python script error
			    }
	    });
  		// called imediately
      var msg = &quot;&quot;;
  		if(delete_kind == &#039;all&#039;){    
  			msg = &quot;Deletion in progress: &#039;&quot;+project+&quot;&#039;&quot;
  		}else if(delete_kind == &#039;tax&#039;){
  			msg = &quot;Deletion in progress: taxonomy from &#039;&quot;+project+&quot;&#039;&quot;;
  		}else if(delete_kind == &#039;meta&#039;){
  			msg = &quot;Deletion in progress: metadata from &#039;&quot;+project+&quot;&#039;&quot;;
  		}else{
  			req.flash(&#039;message&#039;, &#039;ERROR nothing deleted&#039;);
  	    res.redirect(&quot;/user_data/your_projects&quot;);
  	    return;
  		}
  		if(delete_kind == &#039;all&#039;){
  				// MOVE file dir to DELETED path (so it won&#039;t show in &#039;your_projects&#039; list)
					var data_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);
					var deleted_data_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;DELETED_project&#039;+timestamp+&#039;:&#039;+project);
					fs.move(data_dir, deleted_data_dir, function(err){
						if(err){
							console.log(err);
							res.send(err);
						}else{
							console.log(&#039;moved project_dir to DELETED_project_dir&#039;);
							req.flash(&#039;successMessage&#039;, msg);
    					res.redirect(&quot;/user_data/your_projects&quot;);
    					return;
						}

					})

			}else{
				req.flash(&#039;successMessage&#039;, msg);
      	res.redirect(&quot;/user_data/your_projects&quot;);
			}
    

});
//
// DUPLICATE_PROJECT
//
router.get(&#039;/duplicate_project/:project&#039;, helpers.isLoggedIn,  function(req,res){
		var project = req.params.project;
		var data_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);
		var new_data_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project+&#039;_dupe&#039;);
		try{
			stats = fs.lstatSync(new_data_dir);
			if (stats.isDirectory()) {
	      console.log(&#039;dir exists - returning&#039;);
	      req.flash(&#039;failMessage&#039;, &quot;Error: Could not duplicate: &#039;&quot;+project+&quot;&#039; to &#039;&quot;+project+&quot;_dupe&#039;. Does it already exist?&quot;);
	    	res.redirect(&quot;/user_data/your_projects&quot;);
	    	return;
	    }
	  }catch(err){
	  	console.log(&#039;dir doesnt exist -good- continuing on&#039;);
	  }

		fs.copy(data_dir, new_data_dir, function (err) {
  		if (err) {
  			console.log(err);
  		}else{
  			// need to change config file of new project to include new name:
  			console.log(&#039;duplicate copy success!&#039;);
  			var config_file = path.join(new_data_dir,&#039;config.ini&#039;);
  			var project_info = {};
  			project_info.config = iniparser.parseSync(config_file);
				var config_info = project_info.config.GENERAL
				config_info.project = project+&#039;_dupe&#039;;
				config_info.baseoutputdir = new_data_dir;
				config_info.configPath = path.join(new_data_dir,&#039;config.ini&#039;);
				config_info.fasta_file = path.join(new_data_dir,&#039;fasta.fa&#039;);
				config_info.datasets = [];
				for(ds in project_info.config.DATASETS){
					config_info.datasets.push({ &quot;dsname&quot;:ds, &quot;count&quot;:project_info.config.DATASETS[ds], &quot;oldname&quot;:ds });
				}
				update_config(res,req, config_file, config_info, false, &#039;Duplicated &#039;+project+&#039; to: &#039;+config_info.project);
    	}
		}) // copies directory, even if it has subdirectories or files

});

//
// START_ASSIGNMENT
//
router.get(&#039;/start_assignment/:project/:classifier/:ref_db&#039;, helpers.isLoggedIn,  function(req,res){




	console.log(req.params.project);
	var project = req.params.project;


	var classifier = req.params.classifier;
	var ref_db_dir = req.params.ref_db;
	console.log(&#039;start: &#039;+project+&#039; - &#039;+classifier+&#039; - &#039;+ref_db_dir);


	//var base_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);
	var data_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);

	var data = &#039;&#039;

	//console.log(&#039;PROJECT_INFORMATION_BY_PID0: &#039;+JSON.stringify(PROJECT_INFORMATION_BY_PID));

	var config_file = path.join(data_dir,&#039;config.ini&#039;);


	if(classifier == &#039;GAST&#039; || classifier == &#039;gast&#039;){
		status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
                                &#039;project&#039;:project, &#039;status&#039;:&#039;OK-GAST&#039;,	&#039;msg&#039;:&#039;Starting GAST&#039; }
		helpers.update_status(status_params);
		var gast_options = {
	      scriptPath : req.C.PATH_TO_SCRIPTS,


	      args :       [ &#039;--classifier&#039;,classifier, &#039;--config&#039;, config_file, &#039;--process_dir&#039;,process.env.PWD, &#039;--data_dir&#039;, data_dir, &#039;-db&#039;, NODE_DATABASE, &#039;-ref_db_dir&#039;, ref_db_dir ],


	    };
	    console.log(&#039;CMD&gt; &#039;+gast_options.scriptPath+&#039;/vamps_script_assign_taxonomy.py &#039;+gast_options.args.join(&#039; &#039;));

		var spawn = require(&#039;child_process&#039;).spawn;
		var log = fs.openSync(path.join(data_dir,&#039;node.log&#039;), &#039;a&#039;);


		var gast_process = spawn( gast_options.scriptPath+&#039;/vamps_script_assign_taxonomy.py&#039;, gast_options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr



		var output = &#039;&#039;
		// communicating with an external python process
		// all the print statements in the py script are printed to stdout
		// so you can grab the projectID here at the end of the process.
		// use looging in the script to log to a file.
		gast_process.stdout.on(&#039;data&#039;, function (data) {
		  //console.log(&#039;stdout: &#039; + data);
		  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
		  output += data;
		  var lines = data.split(&#039;\n&#039;)
		  for(var n in lines){
		  	//console.log(&#039;line: &#039; + lines[n]);
			if(lines[n].substring(0,4) == &#039;PID=&#039;){
				console.log(&#039;pid line &#039;+lines[n]);
			}
		  }
		});

		gast_process.on(&#039;close&#039;, function (code) {
		   console.log(&#039;gast_process process exited with code &#039; + code);
		   var ary = output.split(&quot;\n&quot;);
		   var last_line = ary[ary.length - 1];
		   if(code == 0){
			   console.log(&#039;GAST Success&#039;);
			   //console.log(&#039;PID last line: &#039;+last_line)
			   var ll = last_line.split(&#039;=&#039;);
			   var pid = ll[1];
			   console.log(&#039;NEW PID=: &#039;+pid);
			   console.log(&#039;ALL_DATASETS: &#039;+JSON.stringify(ALL_DATASETS));
			   if(helpers.isInt(pid)){

            connection.query(queries.get_select_datasets_queryPID(pid), function(err, rows1, fields){
					    if (err)  {
				 		  	console.log(&#039;1-GAST-Query error: &#039; + err);				 		  			 
				      } else {
        				   	connection.query(queries.get_select_sequences_queryPID(pid), function(err, rows2, fields){  
        				   		if (err)  {
        				 		  	console.log(&#039;2-GAST-Query error: &#039; + err);        				 		  
        				    	} else {
                      	status_params = {&#039;type&#039;:&#039;update&#039;,  &#039;user&#039;:req.user.username,
                                        &#039;project&#039;:project, &#039;status&#039;:&#039;GAST-SUCCESS&#039;,&#039;msg&#039;:&#039;GAST -Tax assignments&#039; }
								   
												helpers.assignment_finish_request(res,rows1,rows2,status_params);
												helpers.update_status(status_params);

												ALL_CLASSIFIERS_BY_PID[pid] = classifier+&#039;_&#039;+ref_db_dir;


        				    	}

        				   	});
					   	} // end else

				   });

	           }else{ // end if int
                   console.log(&#039;ERROR pid is not an integer: &#039;+pid.toString());
			   }
		   }else{
		   		// ERROR
			   console.log(&#039;ERROR last line: &#039;+last_line);
	   	  		//req.flash(&#039;message&#039;, &#039;Script Error&#039;);
	         	//res.redirect(&quot;/user_data/your_projects&quot;);
		   }
		});  // end gast_process ON Close


	  
		// called imediately
		req.flash(&#039;successMessage&#039;, &quot;GAST has been started for project: &#039;&quot;+project+&quot;&#039;&quot;);
      	res.redirect(&quot;/user_data/your_projects&quot;);




	}else if(classifier == &#039;RDP&#039; || classifier == &#039;rdp&#039;){
		status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
                     &#039;project&#039;:project,     &#039;status&#039;:&#039;OK-RDP&#039;,	&#039;msg&#039;:&#039;Starting RDP&#039; }
		helpers.update_status(status_params);

		var rdp_options = {
	      scriptPath : req.C.PATH_TO_SCRIPTS,
	      args :       [ &#039;--classifier&#039;,classifier, &#039;--config&#039;, config_file, &#039;--process_dir&#039;,process.env.PWD, &#039;--data_dir&#039;, data_dir, &#039;-db&#039;, NODE_DATABASE, &#039;-ref_db_dir&#039;, ref_db_dir,&#039;-script_dir&#039;, req.C.PATH_TO_RDP ],
	    };


	  console.log(&#039;CMD&gt; &#039;+rdp_options.scriptPath+&#039;/vamps_script_assign_taxonomy.py &#039;+rdp_options.args.join(&#039; &#039;));

		var spawn = require(&#039;child_process&#039;).spawn;
		var log = fs.openSync(path.join(data_dir,&#039;node.log&#039;), &#039;a&#039;);
		var rdp_process = spawn( rdp_options.scriptPath+&#039;/vamps_script_assign_taxonomy.py&#039;, rdp_options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr



		var output = &#039;&#039;
		// communicating with an external python process
		// all the print statements in the py script are printed to stdout
		// so you can grab the projectID here at the end of the process.
		// use looging in the script to log to a file.
		rdp_process.stdout.on(&#039;data&#039;, function (data) {
		  //console.log(&#039;stdout: &#039; + data);
		  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
		  output += data;
		  var lines = data.split(&#039;\n&#039;)
		  for(var n in lines){
		  	console.log(&#039;line: &#039; + lines[n]);
			if(lines[n].substring(0,4) == &#039;PID=&#039;){
				console.log(&#039;pid line &#039;+lines[n]);
			}
		  }
		});

		rdp_process.on(&#039;close&#039;, function (code) {
		   console.log(&#039;rdp_process process exited with code &#039; + code);
		   var ary = output.split(&quot;\n&quot;);
		   var last_line = ary[ary.length - 1];
		   if(code == 0){
			   console.log(&#039;RDP Success&#039;);
			   //console.log(&#039;PID last line: &#039;+last_line)
			   var ll = last_line.split(&#039;=&#039;);
			   var pid = ll[1];
			   console.log(&#039;NEW PID=: &#039;+pid);
			   //console.log(&#039;ALL_DATASETS: &#039;+JSON.stringify(ALL_DATASETS));
			   if(helpers.isInt(pid)){

           connection.query(queries.get_select_datasets_queryPID(pid), function(err, rows1){
					   if (err)  {
				 		  console.log(&#039;1-RDP-Query error: &#039; + err);				 		  				 
				       } else {
        				   connection.query(queries.get_select_sequences_queryPID(pid), function(err, rows2){  
        				      if (err)  {
        				 		  		console.log(&#039;2-RDP-Query error: &#039; + err);        				 		  
        				      } else {
													status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
													               &#039;project&#039;:project, &#039;status&#039;:&#039;OK-RDP&#039;,	&#039;msg&#039;:&#039;Finished RDP&#039;  }

													helpers.assignment_finish_request(res,rows1,rows2,status_params);
													helpers.update_status(status_params);

													ALL_CLASSIFIERS_BY_PID[pid] = classifier+&#039;_&#039;+ref_db_dir;

											}

        				   });

					   } // end else

				   });

	           }else{ // end if int
                   console.log(&#039;ERROR pid is not an integer: &#039;+pid.toString());
			   }
		   }else{
		   		// ERROR
			   console.log(&#039;ERROR last line: &#039;+last_line);
	   	  		//req.flash(&#039;message&#039;, &#039;Script Error&#039;);
	         	//res.redirect(&quot;/user_data/your_projects&quot;);
		   }
		});  // end gast_process ON Close


		req.flash(&#039;successMessage&#039;, &quot;RDP has been started for project: &#039;&quot;+project+&quot;&#039;&quot;);
		res.redirect(&quot;/user_data/your_projects&quot;);

	}else{

	}


});
//
// YOUR PROJECTS
//
router.get(&#039;/your_projects&#039;, helpers.isLoggedIn,  function(req,res){

  var user_projects_base_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);

	project_info = {};
	pnames = [];
    fs.readdir(user_projects_base_dir, function(err, items){
		if(err){

			fs.ensureDir(user_projects_base_dir, function (err) {
  			console.log(err) // =&gt; null
  			// dir has now been created, including the directory it is to be placed in
			})


		}else{
		  for (var d in items){
        var pts = items[d].split(&#039;:&#039;);
        if(pts[0] === &#039;project&#039;){

					var project_name = pts[1];
					var stat_dir = fs.statSync(path.join(user_projects_base_dir,items[d]));

			  	if(stat_dir.isDirectory()){
				  	// stat.mtime.getTime() is for sorting to list in oreder

				  	// need to read config file
				  	// check status?? dir strcture: analisis/gast/&lt;ds&gt;
				  	var config_file = path.join(user_projects_base_dir,items[d],&#039;config.ini&#039;);

			  		try{
				  		var stat_config = fs.statSync(config_file);
  				 		// console.log(&#039;1 &#039;,config_file)
		 		 			var config = iniparser.parseSync(config_file)

		      
  				  	project_info[project_name] = {};
  				  
  				  	pnames.push(project_name);

  				  	//new_status = helpers.get_status(req.user.username,project_name);
  				  	//console.log(new_status); // Async only -- doesn&#039;t work
console.log(ALL_CLASSIFIERS_BY_PID)
				 			// console.log(&#039;2 &#039;,config_file)
							if(project_name in PROJECT_INFORMATION_BY_PNAME){
								project_info[project_name].pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
								project_info[project_name].tax_status = &#039;Taxonomic Data Available&#039;;
								project_info[project_name].classified_by = ALL_CLASSIFIERS_BY_PID[PROJECT_INFORMATION_BY_PNAME[project_name].pid];
							}else{
					  		project_info[project_name].pid = 0;
					  		project_info[project_name].tax_status = &#039;No Taxonomic Assignments Yet&#039;;
					  		project_info[project_name].classified_by = &#039;none&#039;;
							}
				  	  project_info[project_name].config = config;
				  	  project_info[project_name].directory = items[d];
				  	  project_info[project_name].mtime = stat_dir.mtime;

			  		}
			  		catch (err) {
			  			console.log(&#039;nofile &#039;,err)
			  		}
			  
			  	}

        }
	    }

		  pnames.sort();
		  //console.log(pnames);
		  //console.log(JSON.stringify(project_info));

		}  // readdir/err

			res.render(&#039;user_data/your_projects&#039;,
			    { title: &#039;User Projects&#039;,
			      pinfo: JSON.stringify(project_info),
			      pnames: pnames,
			  	  env_sources :   JSON.stringify(req.C.ENV_SOURCE),
			  	  failmessage : req.flash(&#039;failMessage&#039;),
			  	  successmessage : req.flash(&#039;successMessage&#039;),
			      user: req.user, hostname: req.C.hostname
		    });

    });  // readdir

});
//
//   GET -- EDIT_PROJECT: When first enter the page.
//
router.get(&#039;/edit_project/:project&#039;, helpers.isLoggedIn, function(req,res){
	console.log(&#039;in edit project:GET&#039;);
	var project_name = req.params.project;
	var user_projects_base_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
	var config_file = path.join(user_projects_base_dir,&#039;project:&#039;+project_name,&#039;config.ini&#039;);

	//console.log(config_file);

	var project_info = {};
  	//var stat_config = fs.statSync(config_file);
 	project_info.config = iniparser.parseSync(config_file);

	if(project_name in PROJECT_INFORMATION_BY_PNAME){   // these projects have tax assignments
		console.log(PROJECT_INFORMATION_BY_PNAME[project_name])
		project_info.pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
		project_info.status = &#039;Taxonomic Data Available&#039;;
		project_info.tax = &#039;GAST&#039;;
		project_info.title = PROJECT_INFORMATION_BY_PNAME[project_name].title;
		project_info.pdesc = PROJECT_INFORMATION_BY_PNAME[project_name].description;
		project_info.public = PROJECT_INFORMATION_BY_PNAME[project_name].public;


		//console.log(&#039;datasets with dids&#039;)
		//project_info.dids = DATASET_IDS_BY_PID[project_info.pid]
		//console.log(PROJECT_INFORMATION_BY_PID[project_info.pid]);
		//console.log(DATASET_IDS_BY_PID[project_info.pid]);

		project_info.dsets = [];
		for(var i = 0; i &lt; ALL_DATASETS.projects.length; i++) {
			if(ALL_DATASETS.projects[i].pid == project_info.pid){
				for(var d = 0; d &lt; ALL_DATASETS.projects[i].datasets.length; d++) {
					var did = ALL_DATASETS.projects[i].datasets[d].did;
					var ds  = ALL_DATASETS.projects[i].datasets[d].dname;
					var ddesc = ALL_DATASETS.projects[i].datasets[d].ddesc;

					project_info.dsets.push({ &quot;did&quot;:did, &quot;name&quot;:ds, &quot;ddesc&quot;:ddesc });
				}
			}
		}


	}else{
		project_info.pid =0;
		project_info.status = &#039;No Taxonomic Assignments Yet&#039;;
		project_info.tax = 0;
		project_info.dsets = [];
		project_info.title = project_info.config.GENERAL.project_title
		project_info.pdesc = project_info.config.GENERAL.project_description;
		if(project_info.config.GENERAL.public == &#039;True&#039; || project_info.config.GENERAL.public == 1){
			project_info.public = 1;
		}else{
			project_info.public = 0;
		}

		for(var ds in project_info.config.DATASETS) {
			project_info.dsets.push({ &quot;did&quot;:&#039;&#039;, &quot;name&quot;:ds, &quot;ddesc&quot;:&#039;&#039; });
		}

	}

	res.render(&#039;user_data/edit_project&#039;, {
				title       : &#039;Edit Project&#039;,
				project     : project_name,
				pinfo       : JSON.stringify(project_info),
				env_sources : JSON.stringify(req.C.ENV_SOURCE),
				message     : req.flash(&#039;message&#039;),
	    	user: req.user, hostname: req.C.hostname,
	  });
});

//
//   POST -- EDIT_PROJECT:  for accepting changes and re-showing the page
//

router.post(&#039;/edit_project&#039;, helpers.isLoggedIn, function(req,res){
	console.log(&#039;in edit project:POST&#039;);
	console.log(req.body);


	if(req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name){
		if(req.body.new_project_name in PROJECT_INFORMATION_BY_PNAME){
			console.log(&#039;ERROR&#039;);
			req.flash(&#039;message&#039;, &#039;That project name is taken -- choose another.&#039;);
			res.redirect(&#039;/user_data/edit_project/&#039;+req.body.old_project_name);
			return;
		}
	}


	// UPDATE DB if TAX ASSIGNMENTS PRESENT
	if(req.body.project_pid != 0){
		//sql call to projects, datasets
		var p_sql = &quot;UPDATE project set project=&#039;&quot;+req.body.new_project_name+&quot;&#039;,\n&quot;;
		p_sql += &quot; title=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_project_title)+&quot;&#039;,\n&quot;;
		p_sql += &quot; rev_project_name=&#039;&quot;+helpers.reverse(req.body.new_project_name)+&quot;&#039;,\n&quot;;
		p_sql += &quot; project_description=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_project_description)+&quot;&#039;,\n&quot;;
		if(req.body.new_privacy == &#039;False&#039;){
			p_sql += &quot; public=&#039;0&#039;\n&quot;;
		}else{
			p_sql += &quot; public=&#039;1&#039;\n&quot;;
		}
		p_sql += &quot; WHERE project_id=&#039;&quot;+req.body.project_pid+&quot;&#039; &quot;
		console.log(p_sql);
    connection.query(p_sql, function(err, rows, fields){
       if(err){
          console.log(&#039;ERROR-in project update: &#039;+err)
       }else{
        	console.log(&#039;OK- project info updated: &#039;+req.body.project_pid)
       }
    });

    // TODO  needed updates to data objects:
    //1- PROJECT_INFORMATION_BY_PNAME
    //console.log(&#039;PROJECT_INFORMATION_BY_PNAME&#039;)
    //console.log(PROJECT_INFORMATION_BY_PNAME);
    var tmp = PROJECT_INFORMATION_BY_PNAME[req.body.old_project_name];
    delete PROJECT_INFORMATION_BY_PNAME[req.body.old_project_name];
    PROJECT_INFORMATION_BY_PNAME[req.body.new_project_name] = tmp;
    //console.log(PROJECT_INFORMATION_BY_PNAME);

    //2- PROJECT_INFORMATION_BY_PID
    //console.log(&#039;PROJECT_INFORMATION_BY_PID&#039;)
		//console.log(PROJECT_INFORMATION_BY_PID[req.body.project_pid]);
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].project         = req.body.new_project_name;
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].env_source_name = req.C.ENV_SOURCE[req.body.new_env_source_id];
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].title           = req.body.new_project_title;
    PROJECT_INFORMATION_BY_PID[req.body.project_pid].description     = req.body.new_project_description;
    if(req.body.new_privacy == &#039;False&#039;){
    	PROJECT_INFORMATION_BY_PID[req.body.project_pid].public = 0;
    }else{
    	PROJECT_INFORMATION_BY_PID[req.body.project_pid].public = 1;
    }

		//console.log(PROJECT_INFORMATION_BY_PID[req.body.project_pid]);

    for(d in req.body.new_dataset_names){
    
    	var d_sql = &quot;UPDATE dataset set dataset=&#039;&quot;+req.body.new_dataset_names[d]+&quot;&#039;,\n&quot;;
			d_sql += &quot; env_sample_source_id=&#039;&quot;+req.body.new_env_source_id+&quot;&#039;,\n&quot;;
			d_sql += &quot; dataset_description=&#039;&quot;+helpers.mysql_real_escape_string(req.body.new_dataset_descriptions[d])+&quot;&#039;\n&quot;;
			d_sql += &quot; WHERE dataset_id=&#039;&quot;+req.body.dataset_ids[d]+&quot;&#039; &quot;
			d_sql += &quot; AND project_id=&#039;&quot;+req.body.project_pid+&quot;&#039; &quot;
			console.log(d_sql);
			connection.query(d_sql, function(err, rows, fields){
        if(err){
          console.log(&#039;ERROR - in dataset update: &#039;+err);
        }else{
        	console.log(&#039;OK - dataset info updated: &#039;+req.body.dataset_ids[d]);
        }
      });
      //3- DATASET_NAME_BY_DID
    	//console.log(&#039;DATASET_NAME_BY_DID&#039;)
    	//console.log(DATASET_NAME_BY_DID[req.body.dataset_ids[d]]);
			DATASET_NAME_BY_DID[req.body.dataset_ids[d]] = req.body.new_dataset_names[d];
			//console.log(DATASET_NAME_BY_DID[req.body.dataset_ids[d]]);
    }



    //4- ALL_DATASETS
    //console.log(&#039;ALL_DATASETS&#039;)
    //console.log(ALL_DATASETS.projects[0]);
    for(var i = 0; i &lt; ALL_DATASETS.projects.length; i++) {
			if(ALL_DATASETS.projects[i].pid == req.body.project_pid) {
				ALL_DATASETS.projects[i].name = req.body.new_project_name;
				ALL_DATASETS.projects[i].title = req.body.new_project_title;


				for(var d = 0; d &lt; ALL_DATASETS.projects[i].datasets.length; d++) {
					var did = ALL_DATASETS.projects[i].datasets[d].did;
					var idx = req.body.dataset_ids.indexOf(did.toString());
					ALL_DATASETS.projects[i].datasets[d].dname = req.body.new_dataset_names[idx];
					ALL_DATASETS.projects[i].datasets[d].ddesc = req.body.new_dataset_descriptions[idx];

				}
			}
		}

	}


	var project_info = {};
	var project_name = req.body.old_project_name;
	var user_projects_base_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
	var project_dir = path.join(user_projects_base_dir,&#039;project\:&#039;+project_name);
	var config_file = path.join(project_dir,&#039;config.ini&#039;);
  var timestamp = +new Date();  // millisecs since the epoch!
	var config_file_bu = path.join(project_dir,&#039;config&#039;+timestamp+&#039;.ini&#039;);
	fs.copy(config_file, config_file_bu, function (err) {
  	  	if (err){
  	  		console.log(err);
  	  	}else{
  	  		console.log(&quot;copy success!&quot;);
  	  	}
	}) // copies fi
	//console.log(config_file);


	project_info.config = iniparser.parseSync(config_file);



	//console.log(&#039;config:&#039;);
	//console.log(JSON.stringify(project_info.config));
	// HAS NO ASSIGNMENTS: NEED CHANGE FILES ONLY
	// changing data on the system must take this into account:
	// if the project has no assignments yet then it has no data in the database (ie no pid).
	// So just (1)alter the config.ini and the (2)directory name where it is located in user_data/NODE_DATABASE/&lt;user&gt;/project:*
	// Also the dataset (3)directories need to be updated.

	config_info = {}

	if(req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name){
		console.log(&#039;updating project name&#039;);
		var new_project_name = req.body.new_project_name.replace(/[\s+,;:]/g,&#039;_&#039;)
		config_info.project = new_project_name;
		project_info.config.GENERAL.project=new_project_name;
		new_base_dir = path.join(user_projects_base_dir,&#039;project\:&#039;+new_project_name);
		new_config_file = path.join(new_base_dir,&#039;config.ini&#039;);
		new_fasta_file = path.join(new_base_dir,&#039;fasta.fa&#039;);
		config_info.baseoutputdir = new_base_dir;
		config_info.configPath = new_config_file;
		config_info.fasta_file = new_fasta_file;
		project_name = new_project_name;

	}else{
		config_info.project = project_name;
		config_info.baseoutputdir = project_info.config.GENERAL.baseoutputdir;
		config_info.configPath = project_info.config.GENERAL.configPath;
		config_info.fasta_file = project_info.config.GENERAL.fasta_file;
	}

	if(req.body.new_project_title){
		console.log(&#039;updating project title&#039;);

		config_info.project_title = req.body.new_project_title;
		project_info.config.GENERAL.project_title = req.body.new_project_title
	}else{
		config_info.project_title = project_info.config.GENERAL.project_title;
	}
	if(req.body.new_project_description){
		console.log(&#039;updating project description&#039;);
		config_info.project_description = req.body.new_project_description;
		project_info.config.GENERAL.project_description = req.body.new_project_description
	}else{
		config_info.project_description = project_info.config.GENERAL.project_description;
	}

	config_info.platform = project_info.config.GENERAL.platform
	config_info.owner = project_info.config.GENERAL.owner
	config_info.config_file_type = project_info.config.GENERAL.config_file_type
	if(req.body.new_privacy != project_info.config.GENERAL.public){
		console.log(&#039;updating privacy&#039;);
		config_info.public = req.body.new_privacy
		project_info.config.GENERAL.public =req.body.new_privacy
	}else{
		config_info.public = project_info.config.GENERAL.public
	}

	config_info.fasta_type = project_info.config.GENERAL.fasta_type
	config_info.dna_region = project_info.config.GENERAL.dna_region
	config_info.project_sequence_count = project_info.config.GENERAL.project_sequence_count
	config_info.domain = project_info.config.GENERAL.domain
	config_info.number_of_datasets = project_info.config.GENERAL.number_of_datasets
	config_info.sequence_counts = project_info.config.GENERAL.sequence_counts

	if(req.body.new_env_source_id != project_info.config.GENERAL.env_source_id){
		console.log(&#039;updating env id&#039;);
		config_info.env_source_id = req.body.new_env_source_id
		project_info.config.GENERAL.env_source_id = req.body.new_env_source_id
	}else{
		config_info.env_source_id = project_info.config.GENERAL.env_source_id
	}

	config_info.has_tax = project_info.config.GENERAL.has_tax

	var old_dataset_array = Object.keys(project_info.config.DATASETS).map(function(k) { return k });
	var counts_array = Object.keys(project_info.config.DATASETS).map(function(k) { return project_info.config.DATASETS[k] });
	console.log(old_dataset_array);
	project_info.config.DATASETS={}
	config_info.datasets = []
	for(n in req.body.dataset_ids){
		new_dataset_name = req.body.new_dataset_names[n].replace(/[\s+,;:]/g,&#039;_&#039;)
		config_info.datasets.push({&quot;oldname&quot;:old_dataset_array[n],&quot;dsname&quot;:new_dataset_name,&quot;did&quot;:req.body.dataset_ids[n],&quot;count&quot;:counts_array[n]})
	}

	//console.log(config_info.datasets);
	if(req.body.project_pid &gt; 0){
		// TODO: HAS ASSIGNMENTS: NEED CHANGE DB &amp; FILES
		// If the project has assignments:
		// change the three places on the file system as above but also:
		// the project_name,title,description and public in NODE_DATABASE.project
		// and the dataset_name,description and env_id in NODE_DATABASE.dataset
		// Also need to update PROJECT_INFORMATION_BY_PNAME
	}

 
	if(project_name in PROJECT_INFORMATION_BY_PNAME){
		project_info.pid = PROJECT_INFORMATION_BY_PNAME[project_name].pid;
		project_info.status = &#039;Taxonomic Data Available&#039;;
		project_info.tax = &#039;GAST&#039;;
	}else{
		project_info.pid = 0;
		project_info.status = &#039;No Taxonomic Assignments Yet&#039;;
		project_info.tax = 0;
	}


	if(req.body.new_project_name &amp;&amp; req.body.new_project_name != req.body.old_project_name){
		config_info.old_base_name = project_info.config.GENERAL.baseoutputdir
		update_config(res,req, config_file, config_info, true, &#039;Updated project: &#039;+config_info.project);
	}else{
		update_config(res,req, config_file, config_info,  false, &#039;Updated project: &#039;+config_info.project);
	}


});
//
//  UPLOAD  METADATA
//
router.post(&#039;/upload_metadata&#039;, [helpers.isLoggedIn, upload.single(&#039;upload_file&#039;, 12)], function(req,res){
	var project = req.body.project_name;
	var file_format = req.body.metadata_file_format;
	var original_metafile = path.join(process.env.PWD,req.file.path);
	var username = req.user.username;
	console.log(&#039;1-req.body upload_metadata&#039;);
  console.log(req.body);
  console.log(req.file);
  console.log(&#039;2-req.body upload_metadata&#039;);
  var has_tax = false
  if(project in PROJECT_INFORMATION_BY_PNAME){
  	has_tax = true
  
  }

  var timestamp = +new Date();  // millisecs since the epoch!
  var data_repository = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);
  //var new_metafile = path.join(data_repository,&#039;metadata_&#039;+timestamp+&#039;.csv&#039;);
  // fs.move(original_metafile, new_metafile, function (err) {
		//     	if (err) {
		// 				req.flash(&#039;failMessage&#039;, &#039;1-File move failure  &#039;+err);
		// 				status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
		// 									&#039;project&#039;:project, &#039;status&#039;:&#039;FAIL-1&#039;,	&#039;msg&#039;:&#039;1-File move failure&#039;  }
		// 				helpers.update_status(status_params);
		// 				res.redirect(&quot;/user_data/import_data&quot;);
		// 				return;
		// 			}
					var options = { scriptPath : req.C.PATH_TO_SCRIPTS,
		        			args : [ &#039;-i&#039;, original_metafile, &#039;-t&#039;,file_format,&#039;-o&#039;, username, &#039;-p&#039;, project, &#039;-db&#039;, NODE_DATABASE, &#039;-add&#039;,&#039;-pdir&#039;,process.env.PWD,]
		    			};
					if(has_tax){
						options.args = options.args.concat([&#039;--has_tax&#039;]);
					}
					console.log(options.scriptPath+&#039;/metadata_utils.py &#039;+options.args.join(&#039; &#039;));
					var spawn = require(&#039;child_process&#039;).spawn;
					var log = fs.openSync(path.join(process.env.PWD,&#039;node.log&#039;), &#039;a&#039;);
					var upload_metadata_process = spawn( options.scriptPath+&#039;/metadata_utils.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr
					var output = &#039;&#039;
					upload_metadata_process.stdout.on(&#039;data&#039;, function (data) {
					  console.log(&#039;stdout: &#039; + data);
					  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
					  output += data;

					  // var lines = data.split(&#039;\n&#039;)
					  // for(var n in lines){
					  // 	//console.log(&#039;line: &#039; + lines[n]);
							// if(lines[n].substring(0,4) == &#039;PID=&#039;){
							// 	console.log(&#039;pid line &#039;+lines[n]);
							// }
					  // }
					});
					upload_metadata_process.on(&#039;close&#039;, function (code) {
				   console.log(&#039;upload_metadata_process exited with code &#039; + code);
				   var ary = output.split(&quot;\n&quot;);
				   var last_line = ary[ary.length - 1];
				   if(code == 0){
					   		console.log(&#039;Upload METADATA Success&#039;);
					   		//console.log(&#039;PID last line: &#039;+last_line)
					   		//var ll = last_line.split(&#039;=&#039;);
					   		// possible multiple pids
					    	if(has_tax){
					   			console.log(PROJECT_INFORMATION_BY_PNAME[project])
					   			pid = PROJECT_INFORMATION_BY_PNAME[project].pid
									connection.query(queries.get_select_datasets_queryPID(pid), function(err, rows1, fields){
								    if (err)  {
							 		  	console.log(&#039;1-Upload METADATA-Query error: &#039; + err);				 		  			 
							      } else {
			        				   	connection.query(queries.get_select_sequences_queryPID(pid), function(err, rows2, fields){  
			        				   		if (err)  {
			        				 		  	console.log(&#039;2-Upload METADATA-Query error: &#039; + err);        				 		  
			        				    	} else {
			                      												   
															helpers.update_metadata_from_file();
															req.flash(&#039;successMessage&#039;, &#039;Metadata Upload in Progress&#039;);
			       									res.redirect(&quot;/user_data/import_choices&quot;);
			        				    	}

			        				   	});
								   	} // end else

							   	});
								}else{  // end if(has_tax)
									req.flash(&#039;successMessage&#039;, &#039;Metadata Upload in Progress&#039;);
			       			res.redirect(&quot;/user_data/import_choices&quot;);
								}

				   }else{
				   		// ERROR
				   		//console.log(last_line);
					    console.log(&#039;ERROR last line: &#039;+last_line);

			   	  	// NO REDIRECT here
			   	  	req.flash(&#039;failMessage&#039;, &#039;Script Error: &#039;+last_line);
			        res.redirect(&quot;/user_data/import_choices&quot;);
				   }
				});  // end upload_metadata_process ON Close

//	});

});

//
//  UPLOAD DATA
//
router.post(&#039;/upload_data&#039;, [helpers.isLoggedIn, upload.array(&#039;upload_files&#039;, 12)], function(req,res){

  var project = req.body.project;
  var username = req.user.username;
  console.log(&#039;1-req.body upload_data&#039;);
  console.log(req.body);
  console.log(req.files);
  console.log(&#039;2-req.body upload_data&#039;);
  console.log(project);
  //console.log(PROJECT_INFORMATION_BY_PNAME);

  if(project == &#039;&#039; || req.body.project == undefined){
		req.flash(&#039;failMessage&#039;, &#039;A project name is required.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else if(project in PROJECT_INFORMATION_BY_PNAME){
		req.flash(&#039;failMessage&#039;, &#039;That project name is already taken.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else if(req.files[0].filename==undefined || req.files[0].size==0){
  	req.flash(&#039;failMessage&#039;, &#039;A fasta file is required.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else if(req.files[1].filename==undefined || req.files[1].size==0){
  	req.flash(&#039;failMessage&#039;, &#039;A metadata csv file is required.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else{
			var data_repository = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username,&#039;project:&#039;+project);
		   console.log(data_repository);
			status_params = {&#039;type&#039;:&#039;new&#039;, &#039;user&#039;:req.user.username,
											&#039;project&#039;:project, &#039;status&#039;:&#039;OK&#039;,	&#039;msg&#039;:&#039;Upload Started&#039;  }
			helpers.update_status(status_params);
			var options = { scriptPath : req.C.PATH_TO_SCRIPTS,
		        			args :       [ &#039;-dir&#039;, data_repository, &#039;-o&#039;, username, &#039;-p&#039;, project]
		    			};
			if(req.body.type == &#039;simple_fasta&#039;){
			    if(req.body.dataset == &#039;&#039; || req.body.dataset == undefined){
				  	req.flash(&#039;failMessage&#039;, &#039;A dataset name is required.&#039;);
				  	res.redirect(&quot;/user_data/import_data&quot;);
				  	return;
					}
					options.args = options.args.concat([&#039;-t&#039;, &#039;single&#039;, &#039;-d&#039;, req.body.dataset ]);
		  }else if(req.body.type == &#039;multi_fasta&#039;) {
					options.args = options.args.concat([&#039;-t&#039;, &#039;multi&#039; ]);
		  }else{
					req.flash(&#039;failMessage&#039;, &#039;No file type info found&#039;);
					res.redirect(&quot;/user_data/import_data&quot;);
					return;
		  }
			var original_fastafile = path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[0].filename);
			var original_metafile  = path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[1].filename);
			//console.log(original_fastafile);
			//console.log(original_metafile);
		 	// move files to user_data/&lt;username&gt;/ and rename
			var LoadDataFinishRequest = function() {
					// START STATUS //
					req.flash(&#039;successMessage&#039;, &quot;Upload in Progress: &#039;&quot;+ project+&quot;&#039;&quot;);

					// type, user, project, status, msg

					res.render(&#039;success&#039;, {  title   : &#039;VAMPS: Import Success&#039;,
								          message : req.flash(&#039;successMessage&#039;),
					                display : &quot;Import_Success&quot;,
						              user    : req.user
						        });
			}
			fs.move(original_fastafile, path.join(data_repository,&#039;fasta.fa&#039;), function (err) {
		    	if (err) {
						req.flash(&#039;failMessage&#039;, &#039;1-File move failure  &#039;+err);
						status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
											&#039;project&#039;:project, &#039;status&#039;:&#039;FAIL-1&#039;,	&#039;msg&#039;:&#039;1-File move failure&#039;  }
						helpers.update_status(status_params);
						res.redirect(&quot;/user_data/import_data&quot;);
						return;
					}
			  	fs.move(original_metafile,  path.join(data_repository,&#039;meta_original.csv&#039;), function (err) {
			    	if (err) {
							req.flash(&#039;failMessage&#039;, &#039;2-File move failure &#039;+err);
							status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
											&#039;project&#039;:project, &#039;status&#039;:&#039;FAIL-2&#039;,	&#039;msg&#039;:&#039;2-File move failure&#039;  }
							helpers.update_status(status_params);
							res.redirect(&quot;/user_data/import_data&quot;);
							return;
						}


				    console.log(options.scriptPath+&#039;/vamps_load_trimmed_data.py &#039;+options.args.join(&#039; &#039;));

				    var spawn = require(&#039;child_process&#039;).spawn;
						var log = fs.openSync(path.join(data_repository,&#039;node.log&#039;), &#039;a&#039;);
						var load_trim_process = spawn( options.scriptPath+&#039;/vamps_load_trimmed_data.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr
						var output = &#039;&#039;

						load_trim_process.stdout.on(&#039;data&#039;, function (data) {
						  //console.log(&#039;stdout: &#039; + data);
						  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
						  output += data;
						  var lines = data.split(&#039;\n&#039;);
						});
						load_trim_process.on(&#039;close&#039;, function (code) {
						   console.log(&#039;load_trim_process process exited with code &#039; + code);
						   var ary = output.split(&quot;\n&quot;);
						   var last_line = ary[ary.length - 1];
						   if(code == 0){
							   	console.log(&#039;Load Success&#039;);
							   	status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
								 			&#039;project&#039;:project, &#039;status&#039;:&#039;LOADED&#039;,	&#039;msg&#039;:&#039;Project is loaded --without tax assignments&#039;  }
						   		helpers.update_status(status_params);
						   		console.log(&#039;Finished loading &#039;+project);
							 }else{
								 	req.flash(&#039;failMessage&#039;, &#039;Script Failure &#039;+err);
								  status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
												&#039;project&#039;:project, &#039;status&#039;:&#039;Script Failure&#039;,	&#039;msg&#039;:&#039;Script Failure&#039;  }
								  helpers.update_status(status_params);
								  res.redirect(&quot;/user_data/import_data&quot;);  // for now we&#039;ll send errors to the browser
								  return;
							 }
						});


				    // PythonShell.run(&#039;vamps_load_trimmed_data.py&#039;, options, function (err, output) {
				    //   if (err) {
							 //  req.flash(&#039;failMessage&#039;, &#039;Script Failure &#039;+err);
							 //  status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
								// 			&#039;proj&#039;:project, &#039;status&#039;:&#039;Script Failure&#039;,	&#039;msg&#039;:&#039;Script Failure&#039;  }
							 //  helpers.update_status(status_params);
							 //  res.redirect(&quot;/user_data/import_data&quot;);  // for now we&#039;ll send errors to the browser
							 //  return;
						  // }
						  // status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
								// 			&#039;proj&#039;:project, &#039;status&#039;:&#039;LOADED&#039;,	&#039;msg&#039;:&#039;Project is loaded --without tax assignments&#039;  }
						  // helpers.update_status(status_params);
						  // console.log(&#039;Finished loading &#039;+project);


				    // });




			  	}); // END move 2
			}); // END move 1

  }
  LoadDataFinishRequest();

});

//
// UPLOAD DATA TAX-BY-SEQ
//
router.post(&#039;/upload_data_tax_by_seq&#039;,  [helpers.isLoggedIn, upload.array(&#039;upload_files&#039;, 12)], function(req,res){

	console.log(&#039;upload_data_tax_by_seq&#039;);
	var project = req.body.project || &#039;&#039;;
	var use_original_names = req.body.use_original_names || &#039;off&#039;
  var username = req.user.username;
  var use_file_taxonomy = req.body.use_tax_from_file;
  console.log(&#039;1req.body upload_data_tax_by_seq&#039;);
  console.log(req.body);
  console.log(req.files);  // array
  console.log(&#039;project: &#039;+project);
  console.log(&#039;use_original_names: &#039;+use_original_names);
  console.log(&#039;2req.body upload_data_tax_by_seq&#039;);
  //console.log(project);
  //console.log(PROJECT_INFORMATION_BY_PNAME);

  if((project == &#039;&#039; || req.body.project == undefined) &amp;&amp; req.body.use_original_names != &#039;on&#039;){
		req.flash(&#039;failMessage&#039;, &#039;A project name is required.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else if(project in PROJECT_INFORMATION_BY_PNAME){
		req.flash(&#039;failMessage&#039;, &#039;That project name is already taken.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else if(req.files[0].filename==undefined || req.files[0].size==0){
  	req.flash(&#039;failMessage&#039;, &#039;A tax_by_seq file is required.&#039;);
		res.redirect(&quot;/user_data/import_data&quot;);
		return;
  }else{

			console.log(&#039;working&#039;)
			//var file_path = path.join(process.env.PWD,req.file.path);
			//var original_taxbyseqfile = path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[0].filename);
			//var original_metafile  = path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[1].filename);
			var original_taxbyseqfile = path.join(process.env.PWD,&#039;user_data&#039;, NODE_DATABASE, &#039;tmp&#039;,req.files[0].filename); //path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[0].filename);
			console.log(original_taxbyseqfile)
			var original_metafile  = &#039;&#039;;
			try{
				original_metafile  = path.join(process.env.PWD,&#039;user_data&#039;, NODE_DATABASE, &#039;tmp&#039;,req.files[1].filename); //path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.files[1].filename);
			}
			catch(err){
				console.log(err)
			}

			console.log(original_metafile);


			var options = { scriptPath : req.C.PATH_TO_SCRIPTS,
		        			args :       [ &#039;-file&#039;, original_taxbyseqfile, &#039;-o&#039;, username, &#039;-pdir&#039;,process.env.PWD,&#039;-db&#039;, NODE_DATABASE ]
		    			};
			if(original_metafile){
				options.args = options.args.concat([&#039;-md_file&#039;,original_metafile]);
			}
			if(req.body.use_tax_from_file === 1){
				options.args = options.args.concat([&#039;-use_tax&#039;]);
			}
			if(use_original_names == &#039;on&#039;){
					options.args = options.args.concat([&#039;-orig_names&#039;]);
		  }else if(use_original_names == &#039;off&#039;){
					options.args = options.args.concat([&#039;-p&#039;, project]);
		  }else{
					req.flash(&#039;failMessage&#039;, &#039;No file type info found:  &#039;);
					res.redirect(&quot;/user_data/import_data&quot;);
					return;
		  }
			//var original_tax_by_seq = path.join(&#039;./user_data&#039;, NODE_DATABASE, &#039;tmp&#039;, req.file.filename);

			//console.log(original_fastafile);
			//console.log(original_metafile);
		 	// move files to user_data/&lt;username&gt;/ and rename
			var LoadDataFinishRequest = function() {
					// START STATUS //
					req.flash(&#039;successMessage&#039;, &quot;Upload in Progress: &#039;TaxBySeq File&#039;&quot;);

					// type, user, project, status, msg

					res.render(&#039;success&#039;, {  title   : &#039;VAMPS: Import Success&#039;,
								          message : req.flash(&#039;successMessage&#039;),
					                display : &quot;Import_Success&quot;,
						              user    : req.user
						  });
			}

	  
				//console.log(&#039;Moved file &#039;+req.file.filename+ &#039; to &#039;+path.join(data_dir,&#039;tax_by_seq.txt&#039;))

		    console.log(options.scriptPath+&#039;/vamps_load_tax_by_seq.py &#039;+options.args.join(&#039; &#039;));
		    return;
		    var spawn = require(&#039;child_process&#039;).spawn;
				var log = fs.openSync(path.join(process.env.PWD,&#039;node.log&#039;), &#039;a&#039;);
				var tax_by_seq_process = spawn( options.scriptPath+&#039;/vamps_load_tax_by_seq.py&#039;, options.args, {detached: true, stdio: [ &#039;ignore&#039;, null, log ]} );  // stdin, stdout, stderr
				var output = &#039;&#039;
				// communicating with an external python process
				// all the print statements in the py script are printed to stdout
				// so you can grab the projectID here at the end of the process.
				// use looging in the script to log to a file.
				tax_by_seq_process.stdout.on(&#039;data&#039;, function (data) {
					  //console.log(&#039;stdout: &#039; + data);
					  data = data.toString().replace(/^\s+|\s+$/g, &#039;&#039;);
					  output += data;
					  var lines = data.split(&#039;\n&#039;)
					  for(var n in lines){
					  	//console.log(&#039;line: &#039; + lines[n]);
							if(lines[n].substring(0,4) == &#039;PID=&#039;){
								console.log(&#039;pid line &#039;+lines[n]);
							}
					  }
				});
				tax_by_seq_process.on(&#039;close&#039;, function (code) {
				   console.log(&#039;tax_by_seq_process process exited with code &#039; + code);
				   var ary = output.split(&quot;\n&quot;);
				   var last_line = ary[ary.length - 1];
				   if(code == 0){
					   console.log(&#039;TAXBYSEQ Success&#039;);
					   //console.log(&#039;PID last line: &#039;+last_line)
					   var ll = last_line.split(&#039;=&#039;);
					   // possible multiple pids
					   pid_list = ll[1].split(&#039;-&#039;)
					   for(var i in pid_list){
						   //var pid = ll[1];
						   var pid = pid_list[i];
						   console.log(&#039;NEW PID=: &#039;+pid);
						   console.log(&#039;ALL_DATASETS: &#039;+JSON.stringify(ALL_DATASETS));
						   if(helpers.isInt(pid)){

			            connection.query(queries.get_select_datasets_queryPID(pid), function(err, rows1, fields){
								    if (err)  {
							 		  	console.log(&#039;1-TAXBYSEQ-Query error: &#039; + err);				 		  			 
							      } else {
			        				   	connection.query(queries.get_select_sequences_queryPID(pid), function(err, rows2, fields){  
			        				   		if (err)  {
			        				 		  	console.log(&#039;2-TAXBYSEQ-Query error: &#039; + err);        				 		  
			        				    	} else {
			                      	status_params = {&#039;type&#039;:&#039;update&#039;, &#039;user&#039;:req.user.username,
			                                        &#039;pid&#039;:pid,&#039;status&#039;:&#039;TAXBYSEQ-SUCCESS&#039;,&#039;msg&#039;:&#039;TAXBYSEQ -Tax assignments&#039; }
											   
															helpers.assignment_finish_request(res,rows1,rows2,status_params);
															helpers.update_status(status_params);
															ALL_CLASSIFIERS_BY_PID[pid] = &#039;unknown&#039;


			        				    	}

			        				   	});
								   	} // end else

							   });

				           }else{ // end if int
			                   console.log(&#039;ERROR pid is not an integer: &#039;+pid.toString());
						   }
						 } // end for pid in pid_list
				   }else{
				   		// ERROR
				   		console.log(output);
					    console.log(&#039;ERROR last line: &#039;+code);
			   	  	// NO REDIRECT here
			   	  	//req.flash(&#039;message&#039;, &#039;Script Error&#039;+last_line);
			        //res.redirect(&quot;/user_data/your_projects&quot;);
				   }
				});  // end tax_by_seq_process ON Close



  }
  LoadDataFinishRequest();


});

//
//  FILE UTILS
//
router.get(&#039;/file_utils&#039;, helpers.isLoggedIn, function(req, res){

	console.log(&#039;in file_utils&#039;);
	//console.log(req.query.filename);
	var user = req.query.user;

	console.log(file);
	//// DOWNLOAD //////
	if(req.query.fxn == &#039;download&#039; &amp;&amp; req.query.template == &#039;1&#039;){
      var file = path.join(process.env.PWD,req.query.filename);
      res.setHeader(&#039;Content-Type&#039;, &#039;text&#039;);
      res.download(file); // Set disposition and send it.
  }else if(req.query.fxn == &#039;download&#039; &amp;&amp;  req.query.type==&#039;pcoa&#039;){
	    var file = path.join(process.env.PWD,&#039;tmp&#039;,req.query.filename);
		  res.setHeader(&#039;Content-Type&#039;, &#039;text&#039;);
		  res.download(file); // Set disposition and send it.
	}else if(req.query.fxn == &#039;download&#039;){
	    var file = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,user,req.query.filename);
		  res.setHeader(&#039;Content-Type&#039;, &#039;text&#039;);
		  res.download(file); // Set disposition and send it.
	///// DELETE /////
	}else if(req.query.fxn == &#039;delete&#039;){
	    var file = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,user,req.query.filename);
		if(req.query.type == &#039;datasets&#039;){
			fs.unlink(file, function(err){
				if(err){
					console.log(err);
				}else{
					req.flash(&#039;message&#039;, &#039;Deleted: &#039;+req.query.filename);
					res.redirect(&quot;/visuals/saved_datasets&quot;);
				}
			}); //
		}else{
			fs.unlink(file, function(err){
				if(err){
					console.log(err);
				}else{
					req.flash(&#039;message&#039;, &#039;Deleted: &#039;+req.query.filename);
					res.redirect(&quot;/user_data/file_retrieval&quot;);
				}
			});
		}

	}

});

//
// DOWNLOAD SEQUENCES
//
router.post(&#039;/download_selected_seqs&#039;, helpers.isLoggedIn, function(req, res) {
  var db = req.db;
  console.log(&#039;seqs req.body--&gt;&gt;&#039;);
  console.log(req.body);
  console.log(&#039;&lt;&lt;--req.body&#039;);
  console.log(&#039;in DOWNLOAD SELECTED SEQS&#039;);

  var qSelect = &quot;SELECT UNCOMPRESS(sequence_comp) as seq, sequence_id, seq_count, project, dataset from sequence_pdr_info\n&quot;;
  //var qSelect = &quot;select sequence_comp as seq, sequence_id, seq_count, dataset from sequence_pdr_info\n&quot;;
  qSelect += &quot; JOIN sequence using (sequence_id)\n&quot;;
  qSelect += &quot; JOIN dataset using (dataset_id)\n&quot;;
  qSelect += &quot; JOIN project using (project_id)\n&quot;;
  var seq, seqid, seq_count, pjds;
  var timestamp = +new Date();  // millisecs since the epoch!

  var user_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
  helpers.mkdirSync(path.join(&#039;user_data&#039;,NODE_DATABASE));
  helpers.mkdirSync(user_dir);  // create dir if not exists
  var file_name;
  var out_file_path;

  if(req.body.download_type == &#039;whole_project&#039;){

		var pid = req.body.project_id;
		var project = req.body.project;
		file_name = &#039;fasta:&#039;+timestamp+&#039;_&#039;+project+&#039;.fa.gz&#039;;
  	out_file_path = path.join(user_dir,file_name);
  	qSelect += &quot; where project_id = &#039;&quot;+pid+&quot;&#039;&quot;;

  }else if(req.body.download_type == &#039;partial_project&#039;){

    var pids = JSON.parse(req.body.datasets).ids;
		file_name = &#039;fasta:&#039;+timestamp+&#039;_&#039;+&#039;_custom.fa.gz&#039;;
    out_file_path = path.join(user_dir,file_name);
    qSelect += &quot; where dataset_id in (&quot;+pids+&quot;)&quot;;
    console.log(pids);

  }else if(req.body.download_type == &#039;custom_taxonomy&#039;){
			console.log(&#039;in DOWNLOAD SEQS&#039;);
			req.flash(&#039;tax_message&#039;, &#039;Fasta being created&#039;);
			file_name = &#039;fasta:&#039;+timestamp+&#039;_custom_taxonomy.fa.gz&#039;;
  		out_file_path = path.join(user_dir,file_name);
			var tax_string = req.body.tax_string;
			tax_items = tax_string.split(&#039;;&#039;);
			qSelect += &quot; JOIN silva_taxonomy_info_per_seq using (sequence_id)\n&quot;;
			qSelect += &quot; JOIN silva_taxonomy using (silva_taxonomy_id)\n&quot;;
			add_where = &#039; WHERE &#039;
			for(n in tax_items){
				rank = req.C.RANKS[n]
				qSelect += &#039; JOIN `&#039;+rank+ &#039;` using (&#039;+rank+&#039;_id)\n&#039;
				add_where += &#039;`&#039;+rank+&quot;`=&#039;&quot;+tax_items[n]+&quot;&#039; and &quot;
			}
			qSelect = qSelect + add_where.substring(0, add_where.length - 5)

  }
  //qSelect += &quot; limit 100 &quot;;                     // &lt;&lt;&lt;&lt;-----  for testing

  var gzip = zlib.createGzip();
  console.log(qSelect);

  var wstream = fs.createWriteStream(out_file_path);
  var rs = new Readable();
  var collection = db.query(qSelect, function (err, rows, fields){
    if (err) {
        throw err;
    } else {
      for (var i in rows){
        seq = rows[i].seq.toString();
        //var buffer = new Buffer(rows[i].seq, &#039;base64&#039;);
        //console.log(seq);
        seq_id = rows[i].sequence_id.toString();
        seq_count = rows[i].seq_count.toString();
        //project = rows[i].project;
        pjds = rows[i].project+&#039;--&#039;+rows[i].dataset;
        entry = &#039;&gt;&#039;+seq_id+&#039;|&#039;+pjds+&#039;|&#039;+seq_count+&quot;\n&quot;+seq+&quot;\n&quot;;
        //console.log(entry);
        rs.push(entry);
      }

      rs.push(null);
    }
    rs
      .pipe(gzip)
      .pipe(wstream)
      .on(&#039;finish&#039;, function () {  // finished
        console.log(&#039;done compressing and writing file&#039;);
        console.log(JSON.stringify(req.user))
        var info = {
              to : req.user.email,
              from : &quot;vamps@mbl.edu&quot;,
              subject : &quot;fasta file is ready&quot;,
              text : &quot;Your fasta file is ready here:\n\nhttp://localhost:3000/&quot;+&quot;export_data/&quot;
            };
        helpers.send_mail(info);


      });

  });

  res.send(file_name);

});

//
// DOWNLOAD METADATA
//
router.post(&#039;/download_selected_metadata&#039;, helpers.isLoggedIn, function(req, res) {
  var db = req.db;
  console.log(&#039;meta req.body--&gt;&gt;&#039;);
  console.log(req.body);
  var timestamp = +new Date();  // millisecs since the epoch!


var user_dir = path.join(&#039;user_data&#039;,NODE_DATABASE,req.user.username);
helpers.mkdirSync(path.join(&#039;user_data&#039;,NODE_DATABASE));
helpers.mkdirSync(user_dir);  // create dir if not exists
var dids;
var project;
var file_name;
var out_file_path;

if(req.body.download_type == &#039;whole_project&#039;){
  var pid  = req.body.project_id;
  dids = DATASET_IDS_BY_PID[pid];
  project = req.body.project;
  file_name = &#039;metadata:&#039;+timestamp+&#039;_&#039;+project+&#039;.csv.gz&#039;;
  out_file_path = path.join(user_dir,file_name);
}else{
  dids = JSON.parse(req.body.datasets).ids;
  file_name = &#039;metadata:&#039;+timestamp+&#039;.csv.gz&#039;;
  out_file_path = path.join(user_dir, file_name);
}
  console.log(&#039;dids&#039;);
  console.log(dids);


  // check if custom metadata table exists
  //var qSelect = &quot;SHOW tables like &#039;custom_metadata_&quot;+pid+&quot;&#039;&quot;;

  // get the fields from required_metadata_info as they may vary
  //var qSelect = &quot;SHOW columns from required_metadata_info&quot;;
  //console.log(&#039;in projects--&gt;&#039;);
  //console.log(MetadataValues);
  //console.log(&#039;&lt;--in projects&#039;);
  // we have all the metadata in MetadataValues by did

  var gzip = zlib.createGzip();
  var myrows = {}; // myrows[mdname] == [] list of values
  var header = &#039;Project: &#039;+project+&quot;\n\t&quot;;

  var wstream = fs.createWriteStream(out_file_path);
  var rs = new Readable();
  var filetxt;

      for (var i in dids){
        did = dids[i];
        dname = DATASET_NAME_BY_DID[did];
        header += dname+&quot;\t&quot;;
        for (var k in METADATA[did]){
          nm = k;
          val = METADATA[did][k];
          if(nm in myrows){
            myrows[nm].push(val);
          }else{
            myrows[nm] = [];
            myrows[nm].push(val);
          }
        }
      }

    // print
    header += &quot;\n&quot;;
    rs.push(header);
    if(Object.keys(myrows).length === 0){
      rs.push(&quot;NO METADATA FOUND\n&quot;);
    }else{
      for (var mdname in myrows){
        filetxt = mdname+&quot;\t&quot;;  // restart sting
        for(i in myrows[mdname]){
          filetxt += myrows[mdname][i]+&quot;\t&quot;;
        }
        filetxt += &quot;\n&quot;;
        rs.push(filetxt);
      }
    }
    rs.push(null);
    rs
      .pipe(gzip)
      .pipe(wstream)
      .on(&#039;finish&#039;, function () {  // finished
        console.log(&#039;done compressing and writing file&#039;);
        //console.log(JSON.stringify(req.user))
        var info = {
              to : req.user.email,
              from : &quot;vamps@mbl.edu&quot;,
              subject : &quot;metadata is ready&quot;,
              text : &quot;Your metadata file is ready here:\n\nhttp://localhost:3000/&quot;+&quot;export_data/&quot;
        };
        helpers.send_mail(info);
        //req.flash(&#039;Done&#039;)



      });

  	res.send(file_name);
});

//
// DOWNLOAD MATRIX
//
router.post(&#039;/download_selected_matrix&#039;, helpers.isLoggedIn, function(req, res) {
  	var db = req.db;
  	console.log(&#039;matrix req.body--&gt;&gt;&#039;);
  	console.log(req.body);
  	//var timestamp = +new Date();  // millisecs since the epoch!
		for (var i in biom_matrix.rows){
 			row_txt = &#039;&#039;;
 			row_txt += biom_matrix.rows[i].name;
 			console.log(row_txt)
 		}

		var user_dir = path.join(&#039;user_data&#039;,NODE_DATABASE,req.user.username);
		helpers.mkdirSync(path.join(&#039;user_data&#039;,NODE_DATABASE));
		helpers.mkdirSync(user_dir);  // create dir if not exists


		dids = JSON.parse(req.body.datasets).ids;
		var timestamp = req.body.ts;
		var file_name = &#039;matrix:&#039;+timestamp+&#039;.csv&#039;;
		//out_file_path = path.join(user_dir, file_name);


		var out_file = path.join(&#039;user_data&#039;,NODE_DATABASE,req.user.username,file_name);
		var wstream = fs.createWriteStream(out_file);
		var gzip = zlib.createGzip();
		var rs = new Readable();

		header_txt = &quot;Taxonomy (&quot;+visual_post_items.tax_depth+&quot; level)&quot;;
		for (var y in biom_matrix.columns){
		header_txt += &#039;,&#039;+biom_matrix.columns[y].name;
		}
		header_txt += &#039;\n\r&#039;;
		rs.push(header_txt);
		for (var i in biom_matrix.rows){
			row_txt = &#039;&#039;;
			row_txt += biom_matrix.rows[i].name;
			for (var k in biom_matrix.data[i]){
				row_txt += &#039;,&#039;+biom_matrix.data[i][k];
			}
			row_txt += &#039;\n\r&#039;;
			rs.push(row_txt);
		}
		rs.push(&#039;\n\r&#039;);
		rs.push(null);
		rs
		//.pipe(gzip)
		.pipe(wstream)
		.on(&#039;finish&#039;, function () {  // finished
		  console.log(&#039;done compressing and writing file&#039;);
		});


		console.log(&#039;dids&#039;);
		console.log(dids);
		res.send(file_name);

});
//
// &lt;&lt;&lt;&lt; FUNCTIONS &gt;&gt;&gt;&gt;
//
function update_config(res,req, config_file, config_info, has_new_pname, msg){
	console.log(config_info)
	var new_config_txt = &quot;[GENERAL]\n&quot;;
	new_config_txt += &quot;project=&quot;+config_info.project+&quot;\n&quot;;
	new_config_txt += &quot;baseoutputdir=&quot;+config_info.baseoutputdir+&quot;\n&quot;;
	new_config_txt += &quot;configPath=&quot;+config_info.configPath+&quot;\n&quot;;
	new_config_txt += &quot;fasta_file=&quot;+config_info.fasta_file+&quot;\n&quot;;


	new_config_txt += &quot;project_title=&quot;+helpers.mysql_real_escape_string(config_info.project_title)+&quot;\n&quot;;
	new_config_txt += &quot;project_description=&quot;+helpers.mysql_real_escape_string(config_info.project_description)+&quot;\n&quot;;


	new_config_txt += &quot;platform=&quot;+config_info.platform+&quot;\n&quot;;
	new_config_txt += &quot;owner=&quot;+config_info.owner+&quot;\n&quot;;
	new_config_txt += &quot;config_file_type=&quot;+config_info.config_file_type+&quot;\n&quot;;
	new_config_txt += &quot;public=&quot;+config_info.public+&quot;\n&quot;;
	new_config_txt += &quot;fasta_type=&quot;+config_info.fasta_type+&quot;\n&quot;;
	new_config_txt += &quot;dna_region=&quot;+config_info.dna_region+&quot;\n&quot;;
	new_config_txt += &quot;project_sequence_count=&quot;+config_info.project_sequence_count+&quot;\n&quot;;
	new_config_txt += &quot;domain=&quot;+config_info.domain+&quot;\n&quot;;
	new_config_txt += &quot;number_of_datasets=&quot;+config_info.number_of_datasets+&quot;\n&quot;;
	new_config_txt += &quot;sequence_counts=&quot;+config_info.sequence_counts+&quot;\n&quot;;
	new_config_txt += &quot;env_source_id=&quot;+config_info.env_source_id+&quot;\n&quot;;
	new_config_txt += &quot;has_tax=&quot;+config_info.has_tax+&quot;\n\n&quot;;
	new_config_txt += &quot;[DATASETS]\n&quot;;

	for(n in config_info.datasets){
			new_config_txt += config_info.datasets[n].dsname+&quot;=&quot;+config_info.datasets[n].count+&quot;\n&quot;;
	}

	console.log(new_config_txt)

	fs.writeFile(config_file, new_config_txt, function(err){
        if(err){
					console.log(err);
					res.send(err);
        }else{
           	console.log(&#039;write new config file success&#039;)
				  	if(has_new_pname){
						// now change the directory name if the project_name is being updated
							old_base_dir = config_info.old_base_name
							new_base_name = config_info.baseoutputdir
							fs.move(old_base_dir, new_base_dir, function(err){
								if(err){
									console.log(err);
									res.send(err);
								}else{
						  
									update_dataset_names(config_info)
									req.flash(&#039;successMessage&#039;, msg);
									res.redirect(&#039;/user_data/your_projects&#039;);

								}

							})
					}else{

						update_dataset_names(config_info)
						req.flash(&#039;successMessage&#039;, msg);
						res.redirect(&#039;/user_data/your_projects&#039;);

					}

        }
    })


}
function update_dataset_names(config_info){

		for(n in config_info.datasets){

					old_name_path = path.join(config_info.baseoutputdir,&#039;analysis&#039;,config_info.datasets[n].oldname);
					new_name_path =path.join(config_info.baseoutputdir,&#039;analysis&#039;,config_info.datasets[n].dsname);
					console.log(old_name_path)
					console.log(new_name_path)
					fs.move(old_name_path, new_name_path, function(err){
						if(err){
							console.log(&#039;WARNING failed to move dataset name &#039;+err.toString())
						}else{
							console.log(&#039;moving &#039;+config_info.datasets[n].oldname+&#039; to &#039;+config_info.datasets[n].dsname);
						}
					})


		}
}
function create_fasta_file(req, pids){
		var qSelect = &quot;SELECT UNCOMPRESS(sequence_comp) as seq, sequence_id, seq_count, project, dataset from sequence_pdr_info\n&quot;;
		//var qSelect = &quot;select sequence_comp as seq, sequence_id, seq_count, dataset from sequence_pdr_info\n&quot;;
		qSelect += &quot; JOIN sequence using (sequence_id)\n&quot;;
		qSelect += &quot; JOIN dataset using (dataset_id)\n&quot;;
		qSelect += &quot; JOIN project using (project_id)\n&quot;;
		var seq, seqid, seq_count, pjds;
		var timestamp = +new Date();  // millisecs since the epoch!

		var user_dir = path.join(process.env.PWD,&#039;user_data&#039;,NODE_DATABASE,req.user.username);
		helpers.mkdirSync(path.join(&#039;user_data&#039;,NODE_DATABASE));
		helpers.mkdirSync(user_dir);  // create dir if not exists
		var file_name;
		var out_file_path;

		//var pids = JSON.parse(req.body.datasets).ids;
		file_name = &#039;fasta:&#039;+timestamp+&#039;_&#039;+&#039;_custom.fa.gz&#039;;
		out_file_path = path.join(user_dir,file_name);
		qSelect += &quot; where dataset_id in (&quot;+pids+&quot;)&quot;;

		var gzip = zlib.createGzip();
		console.log(qSelect);

		var wstream = fs.createWriteStream(out_file_path);
		var rs = new Readable();
		var collection = db.query(qSelect, function (err, rows, fields){
		  if (err) {
		      throw err;
		  } else {
		    for (var i in rows){
		      seq = rows[i].seq.toString();
		      //var buffer = new Buffer(rows[i].seq, &#039;base64&#039;);
		      //console.log(seq);
		      seq_id = rows[i].sequence_id.toString();
		      seq_count = rows[i].seq_count.toString();
		      //project = rows[i].project;
		      pjds = rows[i].project+&#039;--&#039;+rows[i].dataset;
		      entry = &#039;&gt;&#039;+seq_id+&#039;|&#039;+pjds+&#039;|&#039;+seq_count+&quot;\n&quot;+seq+&quot;\n&quot;;
		      //console.log(entry);
		      rs.push(entry);
		    }

		    rs.push(null);
		  }
		  rs
		    .pipe(gzip)
		    .pipe(wstream)
		    .on(&#039;finish&#039;, function () {  // finished
		      console.log(&#039;done compressing and writing file&#039;);
		      console.log(JSON.stringify(req.user))
		      var info = {
		            to : req.user.email,
		            from : &quot;vamps@mbl.edu&quot;,
		            subject : &quot;fasta file is ready&quot;,
		            text : &quot;Your fasta file is ready here:\n\nhttp://localhost:3000/&quot;+&quot;export_data/&quot;
		          };
		      helpers.send_mail(info);


		    });

		});

		res.send(file_name);

}


module.exports = router;</textarea>
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p>.</p>
  </div>
</footer>

<script type="text/html" id="complexity-popover-template">
  <div class="complexity-notice">
    Complexity : {{ complexity.cyclomatic }} <br>
    Length : {{ complexity.halstead.length }} <br>
    Difficulty : {{ complexity.halstead.difficulty.toFixed(2) }} <br>
    Est # bugs : {{ complexity.halstead.bugs.toFixed(2) }}<br>
  </div>
</script>

<script type="text/javascript" src="../../assets/scripts/bundles/core-bundle.js"></script>
<script type="text/javascript" src="../../assets/scripts/bundles/codemirror.js"></script>
<script type="text/javascript" src="../../assets/scripts/codemirror.markpopovertext.js"></script>
<script type="text/javascript" src="report.js"></script>
<script type="text/javascript" src="report.history.js"></script>
<script type="text/javascript" src="../../assets/scripts/plato-file.js"></script>
</body>
</html>
